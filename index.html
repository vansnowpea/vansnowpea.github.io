<!doctype html>



  


<html class="theme-next muse use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta property="og:type" content="website">
<meta property="og:title" content="A Song of Python and Anaconda">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="A Song of Python and Anaconda">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Song of Python and Anaconda">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: 'Author'
    }
  };
</script>




  <link rel="canonical" href="http://yoursite.com/"/>

  <title> A Song of Python and Anaconda </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">A Song of Python and Anaconda</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archiv
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/25/Atom 一款编辑神器/" itemprop="url">
                  Atom 一款编辑神器
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-25T10:59:28+08:00" content="2016-10-25">
              2016-10-25
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Atom-一款编辑神器"><a href="#Atom-一款编辑神器" class="headerlink" title="Atom 一款编辑神器"></a>Atom 一款编辑神器</h1><p>1、今天偶然看到一个atom的动图打字效果，好流弊，所以研究了下。<br>Atom就已经集齐了所有优势于一身，<br>免费 + 高颜值 + 简单易学 + 功能强大 + 可以调教 + 可以整容 + 轻量级 + 性能卓越 … …</p>
<p>上手简单，让Atom能够成为了一款优雅而低门槛的神器，深度可定制的特性，让Atom在你的打磨之下，变得越来越符合你的心意。因此，无论你是用来写作，还是用来写代码，这都是一款你值得拥有的神器。</p>
<p>2、极客学院已经提供了较好的教程：</p>
<p><a href="http://wiki.jikexueyuan.com/project/atom/" target="_blank" rel="external">http://wiki.jikexueyuan.com/project/atom/</a></p>
<p>3、 插件表：</p>
<ul>
<li>activate-power-mode　／叼炸天的特效</li>
<li>autocomplete-clang／　ｃ＆ｃ＋＋代码补全</li>
<li>autocomplete-python／ｐｙｔｈｏｎ代码补全</li>
<li>emmet／前端神器</li>
<li>git-plus/用于做ｇｉｔ的，但是我觉得还是命令行轻松点</li>
<li>python-tools／先装着</li>
<li>script-runner/好东西，用于执行脚本如ｐｙｔｈｏｎ的</li>
<li>terminal-plus/特别的好东西，可以使用控制台，基本能用这个那就可以直接运行ｃ和ｐｙｔｈｏｎ等代码了</li>
<li>vim-mode　　/ｖｉｍ最好的插件．</li>
</ul>
<p>4、其他参考：</p>
<ul>
<li><p><a href="http://www.jianshu.com/p/b4c8479cfaa5" target="_blank" rel="external">Atom：优雅迷人的编辑神器</a></p>
</li>
<li><p><a href="https://www.urlteam.org/2016/04/%e5%86%99%e4%bb%a3%e7%a0%81%e6%b2%a1%e6%bf%80%e6%83%85%e6%80%8e%e4%b9%88%e5%8a%9e%ef%bc%9fatom%e6%95%99%e4%bd%a0%e9%85%b7%e7%82%ab%e6%8e%89%e5%92%8b%e5%a4%a9/" target="_blank" rel="external">写代码没激情怎么办？atom教你酷炫掉咋天</a></p>
</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/22/如何优雅的在Win系统建立自己的SS5实现轻松快速翻墙-24小时运行-自动更新密码【2】/" itemprop="url">
                  如何优雅的在Win系统建立自己的SS5实现轻松快速翻墙【2】-24小时运行-自动更新密码
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-22T20:59:28+08:00" content="2016-10-22">
              2016-10-22
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://ocg7i7pt6.bkt.clouddn.com//blog/20161023/224709467.png" alt=""></p>
<h1 id="神之力量击穿叹息之墙"><a href="#神之力量击穿叹息之墙" class="headerlink" title="神之力量击穿叹息之墙"></a><strong>神之力量击穿叹息之墙</strong></h1><p>1、首先，<a href="https://vansnowpea.github.io/2016/10/22/%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E7%9A%84%E5%BB%BA%E7%AB%8B%E8%87%AA%E5%B7%B1%E7%9A%84SS5%E5%AE%9E%E7%8E%B0%E8%BD%BB%E6%9D%BE%E5%BF%AB%E9%80%9F%E7%BF%BB%E5%A2%99/" target="_blank" rel="external">请参考我的上一个帖子</a>，实现了Win下的SS【快速】翻墙，如果没有SS，要翻墙都要忍受蜗牛速度。为SS的原版牛逼作者十万个赞，也要为翻版作者以及iss网站一万个赞。但是有个小问题，因为源头的SS账号每隔6小时变更，因此总是需要人工更新密码，那么如何把他做成自动更新？</p>
<p>2、方案，爬虫捕捉新密码+重写json加载。</p>
<p>3、细节分析：</p>
<p>用lxml代替了bs4，数据部分也变更修改，可能原作者写的时候网站数据模式和如今的不同，另增加了一些函数。</p>
<p>如下图，因为iss变更的是密码，因此爬虫也抓密码就好，比较简单</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com//blog/20161023/230709584.png" alt=""></p>
<p>4、代码,关于json部分请看参考资料部分：</p>
<pre><code># -*- coding: utf-8 -*-
# python 3.5.2
# 测试系统，Win10
# Author:Van
# 实现SS5本机自动更新密码，争取24小时保持连接
# 实际做不到24小时，因为iss网站的密码的变更有一定时间的延迟
# 所以最好能有其他的SS源头网站
# V1.0
# 欢迎各种改进意见
# 请把对应的帐号密码修改成自己的
# 请把SS软件的路径改成自己的


import requests, json, os, copy, time
from lxml import etree
import smtplib
from email.mime.text import MIMEText
from email.header import Header

TIME_GAP = 300
CONFIG_DIR = &apos;E:\\迅雷下载\\ShadowsocksR-win-3.7.4.1\\gui-config.json&apos;

oldPwdList = []

def modify_json(pwd):
    with open(CONFIG_DIR,&apos;r&apos;) as f:
        data = json.loads(f.read())
        for index, rawPwd in enumerate(pwd):
            data[&apos;configs&apos;][index][&apos;password&apos;] = rawPwd.split(&apos;:&apos;)[-1]
    data = json.dumps(data)
    print(data)
    with open(CONFIG_DIR,&apos;w&apos;) as f:
        f.write(data)

def check_update():
    url = &apos;http://www.ishadowsocks.org&apos;
    html = requests.get(url).content.decode(&apos;utf-8&apos;, &apos;replace&apos;)
    pwd = etree.HTML(html).xpath(&apos;//*[@id=&quot;free&quot;]/div/div[2]//h4[3]/text()&apos;)
    print(&apos;实时密码是：&apos;, pwd)

    if not pwd or oldPwdList == pwd:
        return pwd, False
    else:
        return pwd, True

def send_email(htm):
    # send email to notice new WestWorld is coming
    sender = &apos;xxxxxx@163.com&apos;
    receiver = &apos;xxxxxx@qq.com,xxxxxx@163.com&apos;
    subject = &apos;SS5密码有更新！&apos;
    smtpserver = &apos;smtp.163.com&apos;
    username = &apos;xxxxxx@163.com&apos;
    password = &apos;xxxxxx&apos;
    msg = MIMEText(htm, &apos;html&apos;, &apos;utf-8&apos;)
    msg[&apos;Subject&apos;] = Header(subject, &apos;UTF-8&apos;)
    msg[&apos;From&apos;] = sender
    msg[&apos;To&apos;] = &apos;,&apos;.join(receiver)
    smtp = smtplib.SMTP()
    smtp.connect(smtpserver)
    smtp.login(username, password)
    smtp.sendmail(sender, receiver, msg.as_string())
    smtp.quit()

if __name__ == &apos;__main__&apos;:
    pwd, update = check_update()
    while 1:
        if update:
            print(&apos;password changed, will update!&apos;)
            modify_json(pwd)
            oldPwdList = pwd
            print(&apos;新的临时密码是：&apos;, oldPwdList)
            try:
                send_email(str(pwd))
            except Exception as e:
                print(&quot;email failed:&quot;, e)
        pwd, update = check_update()
        time.sleep(TIME_GAP)
</code></pre><p>5、测试结果：<br>   通过5分钟一次取密码，重点观察iss站在更换密码的时候，有以下特点：</p>
<ul>
<li>比如18点换密码，老密码回马上失效，但新密码不是马上更新到网站，导致有一段时间的真空期</li>
<li>同时，这段时间，读取的密码出现了波动，不过总体影响不算太大。</li>
</ul>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com//blog/20161024/190737721.png" alt=""></p>
<p>6、SS 资源站点列表：</p>
<ul>
<li><a href="http://www.ishadowsocks.org/" target="_blank" rel="external">http://www.ishadowsocks.org/</a></li>
<li><a href="http://freevpnss.cc/" target="_blank" rel="external">http://freevpnss.cc/</a></li>
</ul>
<p>7、参考资料：</p>
<ul>
<li><a href="http://www.gaococ.com/2016/03/06/%E7%94%A8python%E5%AE%9E%E7%8E%B0shadowsocks%E5%AF%86%E7%A0%81%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0/" target="_blank" rel="external">用python实现shadowsocks密码自动更新</a></li>
<li><a href="http://python3-cookbook.readthedocs.io/zh_CN/latest/c06/p02_read-write_json_data.html" target="_blank" rel="external">python3 cookbook</a></li>
<li><a href="http://www.cnblogs.com/coser/archive/2011/12/14/2287739.html" target="_blank" rel="external">JSON概述以及PYTHON对JSON的相关操作</a></li>
</ul>
<p>8、安卓手机测试了类似方案，也是通过的，其实更简单，都不需要设置浏览器。</p>
<p>9、特别感谢</p>
<p>LittleCoder 帮忙修正了bug，美化了代码。</p>
<p>10、github库：</p>
<p><a href="https://github.com/vansnowpea/shadowsocks-24hr-atuo-by-python" target="_blank" rel="external">https://github.com/vansnowpea/shadowsocks-24hr-atuo-by-python</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/22/如何优雅的建立自己的SS5实现轻松快速翻墙/" itemprop="url">
                  如何优雅的在Win系统建立自己的SS5实现轻松快速翻墙【1】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-22T11:59:28+08:00" content="2016-10-22">
              2016-10-22
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://ocg7i7pt6.bkt.clouddn.com//blog/20161024/021409781.png" alt=""></p>
<h1 id="叹息之墙"><a href="#叹息之墙" class="headerlink" title="叹息之墙"></a>叹息之墙</h1><p>1、写这个帖子实在是无奈导致，以前都是用的其他翻墙工具，毕竟win下一点EXE就实现了，但是最近速度越来越慢有的失效，导致在安装itchatmp的时候，一开始搞了2个小时都没完全安装上所有的包。每当因为这些墙导致的时间浪费，想想一生中，被ZF莫名消耗了那么多的时间，真的是悲剧,所以总结此贴。</p>
<p>2、首先方案是： ss+ chrome+ switchyomega </p>
<p>3、什么是ss？ shadowsock,中文名影梭,SS有多牛，相对市面绝大多数vpn，速度快，github的star数量超过一万！由于太流弊，最近几天原始代码，作者被迫删除，至于为何，你懂的。</p>
<p>4、switchyomega 是开源的一个代理切换工具。可以在谷歌的扩展商店搜索得到，也可以通过其github的官方连接得到。</p>
<p>5、总体教程，由于原始SS代码已经删除，此文引用另一版本：</p>
<p>电脑端下载 shadowscoks(<a href="https://github.com/breakwa11/shadowsocks-csharp/releases" target="_blank" rel="external">最新版下载链接</a>)，打开后开始配置，第一步选择 “编辑服务器”</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com//blog/20161023/095626690.png" alt=""></p>
<p>6、使用以下网址的免费SS，右上角免费ss，注意，帐号信息6小时更新：如果你有其他更好的SS资源，欢迎分享。</p>
<p><a href="http://www.ishadowsocks.org/" target="_blank" rel="external">http://www.ishadowsocks.org/</a></p>
<p>7、把服务器信息对应填写：<br><img src="http://ocg7i7pt6.bkt.clouddn.com//blog/20161023/095906759.png" alt=""></p>
<p>8、选择PAC，点击更新本地PAC为GFWList，如下图，并启用系统代理，会出现打勾：</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com//blog/20161023/100017940.png" alt=""></p>
<p>9、此时应该能访问谷歌应用商店了，搜索：switchyomega，第一个就是，作者 FelisCatus，此作品github的star数量5K+，同时给出其地址： <a href="https://github.com/FelisCatus/SwitchyOmega/releases" target="_blank" rel="external">https://github.com/FelisCatus/SwitchyOmega/releases</a>。</p>
<p>10、配置switchyomega,代理协议Sock5，代理服务器：127.0.0.1，代理端口1080:</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com//blog/20161023/100305004.png" alt=""></p>
<p>11、测试，打开youtube，ok！星爷的《逃学威龙》，加载的时候略有卡，但总体速度不错哦。</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com//blog/20161023/100635406.png" alt=""></p>
<p>12、Linux下的配置可参考老高的博客：</p>
<p><a href="https://blog.phpgao.com/shadowsocks_on_linux.html" target="_blank" rel="external">https://blog.phpgao.com/shadowsocks_on_linux.html</a></p>
<p>13、本文方案同样可延伸到QQ浏览器，但如果你使用的是Firexfox，则插件可用AutoProxy，亲测可用。</p>
<p>14、免责申明：</p>
<p>此方法请用于个人科学查阅资料和个人娱乐所用，请遵相关法律，本文不承担任何因此造成的事故影响。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/21/阿里云建立微信公众号的相关资料/" itemprop="url">
                  阿里云ECS建立微信公众号----以itchatmp为例【python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-21T11:59:28+08:00" content="2016-10-21">
              2016-10-21
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="阿里云ECS建立微信公众号—-以itchatmp为例"><a href="#阿里云ECS建立微信公众号—-以itchatmp为例" class="headerlink" title="阿里云ECS建立微信公众号—-以itchatmp为例"></a>阿里云ECS建立微信公众号—-以itchatmp为例</h1><p>1、由于近期发现itchat开源项目要升级到itchatmp , 所以考虑下把自己的阿里云ECS利用起来，不然有点浪费了。</p>
<p>2、首先熟悉下flask的hello world实现,把这段代码放到ECS上：</p>
<pre><code>#encoding:utf8
from flask import Flask, render_template

app = Flask(__name__)
@app.route(&apos;/&apos;)
def hello_world():
    content = &apos;Hello World!&apos;
    return render_template(&apos;hello.html&apos;, content = content)

if __name__ == &apos;__main__&apos;:
    app.run(&apos;0.0.0.0&apos;)
</code></pre><p>其中：@app.route(‘/‘) 是定义的路由，表示对应网址的根目录。<br>然后在本机输入ECS的ip加上端口5000，应该就能看到hello world了。</p>
<p>3、 </p>
<p>flask的 中文文档资料： <a href="http://dormousehole.readthedocs.io/en/latest/" target="_blank" rel="external">http://dormousehole.readthedocs.io/en/latest/</a></p>
<p> flask的基础视频参考： <a href="http://www.jikexueyuan.com/course/943.html" target="_blank" rel="external">http://www.jikexueyuan.com/course/943.html</a></p>
<p>4、 以itchatmp为例：</p>
<p>首先根据itchatmp的github网址： <a href="https://github.com/littlecodersh/itchatmp" target="_blank" rel="external">https://github.com/littlecodersh/itchatmp</a></p>
<p>下载到本地，然后</p>
<pre><code>pip install itchatmp
</code></pre><p>在这个过程中，很可能安装失败，是因为墙的因素，建议开启翻墙工具</p>
<p>在安装好之后，把对应的示范脚本，根据你的微信订阅号的相关参数进行修改：</p>
<pre><code>import itchatmp

itchatmp.update_config(itchatmp.WechatConfig(
    token=&apos;xxxxxxxxxx&apos;,
    appId = &apos;xxxxxxxxxx&apos;,
    appSecret = &apos;xxxxxxxxxx&apos;))

@itchatmp.msg_register(itchatmp.content.TEXT)
def text_reply(msg):
    return msg[&apos;content&apos;]

itchatmp.run()
</code></pre><p>5、然后到微信订阅号的后台，把url部分，修改成你的ECS的ip。</p>
<p>6、运行一个形如weixinchat.py的脚本，把上述代码复制，并运行。一切顺利的话，你的订阅号就工作了，此时，他的默认功能是，当你输入信息后，订阅号自动回复相同内容。</p>
<p>7、本文案例是在Win10，Win NT 2008下都测试通过，</p>
<p>8、如果你需要一些Linux相关的参考资料，如下：</p>
<ul>
<li><a href="https://shanguangyu.com/articles/wechat-ECS/" target="_blank" rel="external">阿里云ECS搭建微信公众平台</a></li>
<li><a href="http://jayveehe.github.io/2015/01/26/nginx-flask/" target="_blank" rel="external">微信公众平台接入初探</a></li>
<li><a href="http://www.oschina.net/translate/serving-flask-with-nginx-on-ubuntu?cmp" target="_blank" rel="external">在 Ubuntu 上使用 Nginx 部署 Flask 应用</a></li>
<li><a href="http://www.cnblogs.com/weishun/p/weixin-publish-developing.html" target="_blank" rel="external">微信公众平台开发(免费云BAE+高效优雅的Python+网站开放的API)</a></li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/20/测试Daocloud/" itemprop="url">
                  测试Daocloud
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-20T16:59:28+08:00" content="2016-10-20">
              2016-10-20
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="测试Daocloud"><a href="#测试Daocloud" class="headerlink" title="测试Daocloud"></a>测试Daocloud</h1><p>1、话说现在新浪SAE每天开始收10个豆，加上他主推SVN管理，且不支持同时SVN+Git的管理方法。<br>这使得带来一定的不方便，所以决定找一个代替SAE的。正好看到别人的帖子，所以决定测试下Daocloud</p>
<p>2、案例： </p>
<p><a href="http://vansnowpea-van-2048.daoapp.io/" target="_blank" rel="external">http://vansnowpea-van-2048.daoapp.io/</a></p>
<p>3、代码,转自：<a href="https://my.oschina.net/u/923087/blog/286050" target="_blank" rel="external">https://my.oschina.net/u/923087/blog/286050</a>：</p>
<pre><code># -*- coding: utf-8 -*-
&quot;&quot;&quot;
Created on Tue Jul  1 14:15:39 2014

@author: kelvin
&quot;&quot;&quot;

import random

class game2048:
    totalScore = 0
    v = [[2, 8, 8, 2],
         [4, 2, 4, 8],
         [2, 4, 2, 0],
         [4, 2, 4, 0]]
    &apos;&apos;&apos;
    v = [[0, 0, 0, 0],
         [0, 0, 0, 0],
         [0, 0, 0, 0],
         [0, 0, 0, 0]]
    &apos;&apos;&apos;
    def __init__(self):
        for i in range(4):
            self.v[i] = [random.choice([0,0,0,2,2,4]) for x in range(4)]


    def display(self):
        print(&apos;{0:4} {1:4} {2:4} {3:4}&apos;.format(self.v[0][0], self.v[0][1], self.v[0][2], self.v[0][3]))
        print(&apos;{0:4} {1:4} {2:4} {3:4}&apos;.format(self.v[1][0], self.v[1][1], self.v[1][2], self.v[1][3]))
        print(&apos;{0:4} {1:4} {2:4} {3:4}&apos;.format(self.v[2][0], self.v[2][1], self.v[2][2], self.v[2][3]))
        print(&apos;{0:4} {1:4} {2:4} {3:4}&apos;.format(self.v[3][0], self.v[3][1], self.v[3][2], self.v[3][3]))
        print(&apos;得分为:{0:4}&apos;.format(self.totalScore))
        print(&apos;游戏是否结束:{0:4}&apos;.format(self.isOver()))
    #重新排列
    def align(self,vList, direction):
        for i in range(vList.count(0)):
            vList.remove(0)
        zeros = [0 for x in range(4-len(vList))]
        if direction == &apos;left&apos;:
            vList.extend(zeros)
        else:
            vList[:0] = zeros
    #将相同的元素相加，返回新增积分
    def addSame(self,vList, direction):
        increment=0
        if direction == &apos;left&apos;:
            for i in [0,1,2]:
                if vList[i]==vList[i+1] and vList[i+1]!=0:
                    vList[i] *= 2
                    vList[i+1] = 0
                    increment += vList[i]
        else:
            for i in [3,2,1]:
                if vList[i]==vList[i-1] and vList[i-1]!=0:
                    vList[i] *= 2
                    vList[i-1] = 0
                    increment += vList[i]
        return increment
    #处理行和方向,返回新增积分
    def handle(self, vList, direction):
        self.align(vList, direction)
        increment = self.addSame(vList, direction)
        self.align(vList, direction)
        self.totalScore += increment #直接加到总值
        return increment
    #判断游戏是否结束
    def judge(self):

        if self.isOver():
            print(&apos;你输了，游戏结束!&apos;)
            return False
        else:
            if self.totalScore &gt;= 2048:
                print(&apos;你赢了，游戏结束！但是你还可以继续玩。&apos;)
            return True
    #判断游戏是否真正结束
    def isOver(self):
        N = self.calcCharNumber(0)
        if N!=0:
            return False
        else:
            for row in range(4):
                flag = self.isListOver(self.v[row])
                if flag==False:
                    return False    
            for col in range(4):
                # 将矩阵中一列复制到一个列表中然后处理
                vList = [self.v[row][col] for row in range(4)]
                flag = self.isListOver(vList)
                if flag==False:
                    return False
        return True

    #判断一个列表是否还可以合并
    def isListOver(self, vList):
        for i in [0,1,2]:
            if vList[i]==vList[i+1] and vList[i+1]!=0:
                return False
        return True
    def calcCharNumber(self, char):
        n = 0
        for q in self.v:
            n += q.count(char)
        return n
    def addElement(self):
        # 统计空白区域数目 N
        N = self.calcCharNumber(0)
        if N!=0:
            # 按2和4出现的几率为3/1来产生随机数2和4
            num = random.choice([2, 2, 2, 4]) 
            # 产生随机数k，上一步产生的2或4将被填到第k个空白区域
            k = random.randrange(1, N+1)    #k的范围为[1,N]
            n = 0
            for i in range(4):
                for j in range(4):
                    if self.v[i][j] == 0:
                        n += 1
                        if n == k:
                            self.v[i][j] = num
                            return


    def moveLeft(self):
        self.moveHorizontal(&apos;left&apos;)
    def moveRight(self):
        self.moveHorizontal(&apos;right&apos;)
    def moveHorizontal(self, direction):
        for row in range(4):
            self.handle(self.v[row], direction)

    def moveUp(self):
        self.moveVertical(&apos;left&apos;)
    def moveDown(self):
        self.moveVertical(&apos;right&apos;)
    def moveVertical(self, direction):
        for col in range(4):
            # 将矩阵中一列复制到一个列表中然后处理
            vList = [self.v[row][col] for row in range(4)]
            self.handle(vList, direction)
            # 从处理后的列表中的数字覆盖原来矩阵中的值
            for row in range(4):
                self.v[row][col] = vList[row]

    #主要的处理函数
    def operation(self):
        op = input(&apos;operator:&apos;)
        if op in [&apos;a&apos;, &apos;A&apos;]:    # 向左移动
            self.moveLeft()
            self.addElement()
        elif op in [&apos;d&apos;, &apos;D&apos;]:  # 向右移动
            self.moveRight()
            self.addElement()
        elif op in [&apos;w&apos;, &apos;W&apos;]:  # 向上移动
            self.moveUp()
            self.addElement()
        elif op in [&apos;s&apos;, &apos;S&apos;]:  # 向下移动
            self.moveDown()
            self.addElement()
        else:
            print(&apos;错误的输入。请输入 [W, S, A, D] 或者是其小写&apos;)    

#开始
print(&apos;输入：W(上移) S(下移) A(左移) D(右移), press &lt;CR&gt;.&apos;)
g =game2048()
flag = True
while True:
    g.display()
    flag = g.judge()
    g.operation()
    flag = g.judge()
</code></pre>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/20/从零开始 Python 微信公众号开发【转帖】/" itemprop="url">
                  从零开始 Python 微信公众号开发【转帖】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-20T14:59:28+08:00" content="2016-10-20">
              2016-10-20
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="从零开始-Python-微信公众号开发【转帖】"><a href="#从零开始-Python-微信公众号开发【转帖】" class="headerlink" title="从零开始 Python 微信公众号开发【转帖】"></a>从零开始 Python 微信公众号开发【转帖】</h1><p>1、虽然在8月底的时候我也有总结一篇基于SAE的订阅号的实现的日志。不过也就是简单实现而已。</p>
<p>2、今天偶然看到小段的总结文档，写的比较详细，忍不住转发下，以下是原文地址：</p>
<p><a href="https://zhuanlan.zhihu.com/p/21354943" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/21354943
</a></p>
<p>3、要强调下，如果使用SAE新浪云，是需要实名认证的。</p>
<p>4、最近也从github或搜索发现了一些不错的微信的sdk，包括但不限于：</p>
<ul>
<li><a href="https://github.com/littlecodersh/ItChat" target="_blank" rel="external">https://github.com/littlecodersh/ItChat</a></li>
<li><a href="http://wechat-python-sdk.com/" target="_blank" rel="external">http://wechat-python-sdk.com/</a></li>
</ul>
<p>5、然后今天发生了喜感的一幕，当和little聊起之前曾给他发过email请教过细节等，他回复说，当时正好有人写了email，才想起做一个这样的sdk。  </p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/17/数据分析和一个工具OpenRefine/" itemprop="url">
                  数据分析和一个工具OpenRefine【Python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-17T12:59:28+08:00" content="2016-10-17">
              2016-10-17
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="数据分析和一个工具OpenRefine"><a href="#数据分析和一个工具OpenRefine" class="headerlink" title="数据分析和一个工具OpenRefine"></a>数据分析和一个工具OpenRefine</h1><p>1、在阅读《Python网络数据采集》第七章的时候看到的案例，记录细节分析。</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com//blog/20161017/232231872.png" alt=""></p>
<p>2、来简单体会下他的作用，根据书上的例子，我选定了之前程序得到的csv文件，导入后，的界面如下图： </p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com//blog/20161018/001139678.png" alt=""></p>
<p>可以看到Programming language，的栏目，这里要从77行中，筛选出同时有3种语言技能的，先在上面的下拉三角点开，使用text filter，然后配合RE表达式：  .+,.+,.+  输入到左侧，即可：</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com//blog/20161018/001523164.png" alt=""></p>
<p>3、此软件关于正则表达式的使用，可参考此网址：</p>
<p><a href="https://github.com/OpenRefine/OpenRefine/wiki/General-Refine-Expression-Language" target="_blank" rel="external">https://github.com/OpenRefine/OpenRefine/wiki/General-Refine-Expression-Language</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/15/维基百科某网页表格的csv保存的分析/" itemprop="url">
                  维基百科某网页表格的csv保存的分析【Python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-15T12:59:28+08:00" content="2016-10-15">
              2016-10-15
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="维基百科某网页表格的csv保存的分析"><a href="#维基百科某网页表格的csv保存的分析" class="headerlink" title="维基百科某网页表格的csv保存的分析"></a>维基百科某网页表格的csv保存的分析</h1><p>1、在阅读《Python网络数据采集》第五章的时候看到的案例，记录细节分析。</p>
<p>目标网址：<br><a href="http://en.wikipedia.org/wiki/Comparison_of_text_editors" target="_blank" rel="external">http://en.wikipedia.org/wiki/Comparison_of_text_editors</a></p>
<p>中的一个表格，</p>
<p>这是结果图：</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-15/131101232.png" alt=""></p>
<p>2、代码：</p>
<pre><code>import csv
from urllib.request import urlopen
from bs4 import BeautifulSoup

html = urlopen(&quot;http://en.wikipedia.org/wiki/Comparison_of_text_editors&quot;)
bsObj = BeautifulSoup(html, &quot;html.parser&quot;)
#The main comparison table is currently the first table on the page
table = bsObj.findAll(&quot;table&quot;,{&quot;class&quot;:&quot;wikitable&quot;})[0]
# print(table)
rows = table.findAll(&quot;tr&quot;)
# print(rows)

csvFile = open(&quot;c:\\van\\editors.csv&quot;, &apos;wt&apos;, newline=&apos;&apos;, encoding=&apos;utf-8&apos;)
writer = csv.writer(csvFile)
try:
    for row in rows:
        csvRow = []
        for cell in row.findAll([&apos;td&apos;, &apos;th&apos;]):
            csvRow.append(cell.get_text())
        writer.writerow(csvRow)
finally:
    csvFile.close()
</code></pre><p>3、上述代码的主要目的，是把对应url的表格的文字信息，提取出来，保存到csv。那么他是怎么一步步做到的？</p>
<p>首先，我们来打开url看下网站的目标内容，如下图是一个色彩鲜艳的表格：</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-15/115841809.png" alt=""></p>
<p>其次，我们查看下网页源代码，格式清晰的很，并且代码很长一共7910行的html，可这只是维基百科的一页而已！并且从这么多的html代码中快速的提取出我们需要的数据信息，应该怎么做呢？</p>
<p>一般来说，提取数据有2个比较通用的方法，<br>第一、无视他的源代码，我就查看目标内容的路径，可通过浏览器自带的copy xpath配合lxml提取，或者如果你习惯bs4的话，用类似方法。</p>
<p>第二，根据F12找到目标区域，比如一个表格的所在大的路径，然后由大往小的逐步提取。显然本文使用的是这个方法。当鼠标移动到</p>
<pre><code>&lt;table class=&quot;wikitable sortable jquery-tablesorter&quot; style=&quot;text-align: center; font-size: 85%; width: auto; table-layout: fixed;&quot;&gt;
</code></pre><p>这一行代码的时候，整个目标表格的颜色就变了。如下图，</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-15/122808452.png" alt=""></p>
<p>4、现在重点分析下这行代码：</p>
<p>table = bsObj.findAll(“table”,{“class”:”wikitable”})[0]</p>
<p>根据第三条中的分析，已经知道把对应表格中所有含有wikitable的class找出来，那么为什么要这么写？<br>此时，对照下本例python代码中，按照class搜索{“class”:”wikitable”}，实际上得到的是搜索class=”wikitable sortable”，如下的html代码（其中一条）：</p>
<pre><code>&lt;table class=&quot;wikitable sortable&quot; style=&quot;text-align: center; font-size: 85%; width: auto; table-layout: fixed;&quot;&gt;
</code></pre><p>也就是说，bs4的findall是找到了类名带有”wikitable”，就自动把”wikitable sortable”也找出来，但对照lxml的xpath来说，如果class=”wikitable”，则搜索结果为空，要写完整的class=“wikitable sortable“，另外要注意这里有一个大坑，因为F12下的class是”wikitable sortable jquery-tablesorter”,和源代码是不对应的，这会导致python里用xpath找不到内容！</p>
<p>那么为何要在代码的后面加上[0] ? 如果只用下面的代码：</p>
<pre><code>bsObj.findAll(&quot;table&quot;,{&quot;class&quot;:&quot;wikitable&quot;})
</code></pre><p>就本例使用bs4分析来说， 其实得到的是bs4.element.ResultSet ，从字面翻译，可理解成bs4的结果集，不过应该是一个列表， 而要提取里面的内容，就加上[0]，此时从bs4的角度来说，得到了一个bs4.element.Tag ， 从列表的内容提取来说，得到了列表里第一个元素的内容。</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-15/121538652.png" alt=""></p>
<p>5、接下来分析这一句：</p>
<pre><code>rows = table.findAll(&quot;tr&quot;)
</code></pre><p>这一行是得到表格中所有按行的内容，这包含了表格头的黑色字体。如下图： （顺便请翻到此贴底部的参考资料，学习下tr，th，td的区别。</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-15/125711054.png" alt=""></p>
<p>6、接下来，当开始写入csv的时候，是按行写的，包含了表格头的内容，看下代码：</p>
<pre><code>try:
        for row in rows:
            csvRow = []
            for cell in row.findAll([&apos;td&apos;, &apos;th&apos;]):
                csvRow.append(cell.get_text())
            writer.writerow(csvRow)
</code></pre><p>其中 ‘th’ 是表格头，‘td’是表格内容。</p>
<p>7、相对与上述第二种提取方法，这里详细说下第一种提取方法：</p>
<p>检测表格中黑体的表格头（以name为例）和表格内容（以’acme’为例）：</p>
<p>//*[@id=”mw-content-text”]/table[2]/thead/tr/th[1]</p>
<p>//*[@id=”mw-content-text”]/table[2]/tbody/tr[1]/th/a</p>
<p>分别得到他们的xpath地址，但格式并不统一，出现了thead和tbody。</p>
<p>不过好在表格内容的xpath都是有规律的，<br>千万要注意的是：用xpath提取表格的内容要千万小心，这是因为按照上述路径，测试结果，得到的text()返回值为空，</p>
<p>所以要修正下xpath路径，lxml的解析和网页源代码是有出入的，尤其遇到tboday和thead的时候，经过测试，在很多时候，python要把/thead和/tbody才能显示出内容，但这不是绝对的，因为我也遇到保留tbody才能提取成功的案例。</p>
<p>但还有额外的问题，因为这个表格同时有表头和表内容，而这个案例需要同时提取。而表格还有一个captain = “List of text editors”（表格的标题），也就是说，如果我们要通过直接全部提取整个表格的内容，会多出来captain的内容.</p>
<p>而如果把表头和表内容分开提取的话，他们的xpath在去掉/thead和/tbody之后的形式是这样的： 这里由于情况复杂，我先分析表头部分：</p>
<p>A)表头：</p>
<pre><code>string(//*[@id=&quot;mw-content-text&quot;]/table[2]/tr)
</code></pre><p>为何要这么写，而不用直接的text()模式呢？我们来看下</p>
<pre><code>//*[@id=&quot;mw-content-text&quot;]/table[2]/tr//text()
</code></pre><p>如果这么写，得到的结果是带有空格的，如图：</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-16/012705629.png" alt=""></p>
<p>可以发现，不仅多出了空格，在Cost(US$)的栏目，还分了3行，而我们需要连续的，<br>综上，我们只有通过string功能来实现把空格去掉，同时把Cost(US$)合并在一起，得到的结果将是这样的：</p>
<pre><code>Name
Creator
First public release
Latest stable version
Programming language
Cost (US$)
Software license
Open source
</code></pre><p>貌似thead部分的提取还比较顺利，可接下来tbody部分呢？ </p>
<p>B)表内容：<br>我们先看开头的2行对应的xapth地址：</p>
<pre><code># tbody
# Acme xpath:  //*[@id=&quot;mw-content-text&quot;]/table[2]/tbody/tr[1]/th/a
# AkelPad xpath: //*[@id=&quot;mw-content-text&quot;]/table[2]/tbody/tr[2]/th/a
</code></pre><p>如果去掉/tbody后， 又要把表格内容全部提取，又要去掉tbody，发现只能这么写：</p>
<pre><code>string(//*[@id=&quot;mw-content-text&quot;]/table[2])
</code></pre><p>可这样是不行的，因为他不仅把表头的内容也算进去了，还把标题captain的内容也一起搞进去了。</p>
<p>此时，又根据表内容的序号格式，尝试这么写：</p>
<pre><code>string(//*[@id=&quot;mw-content-text&quot;]/table[2]//th/a)
</code></pre><p>期望的是，得到统一的表内容，可实际返回的却是：</p>
<pre><code>Programming language
</code></pre><p>这又是什么鬼呢？<br>原来，代码识别的是满足上述格式条件的<strong>第一个</strong>/a 路径下的文字，而在表头里，从Programming language开始，他有a属性。</p>
<p>此时，又发现，既然string返回的是第一个满足条件的，那么刚修正过的表头的string表达式，其实也适合表内容的表达式啊。看来，我们只好先再提高一个层级，用：</p>
<pre><code>string(//*[@id=&quot;mw-content-text&quot;]/table[2])
</code></pre><p>貌似进入了xpath分析的死循环，做下数据清理应该也是一个路子。</p>
<p>8、上面分析了一大堆，结果不满意，那么lxml的有没有类似bs4的findall功能呢？</p>
<pre><code>∙ iterfind() iterates over all Elements that match the path expression
∙ findall() returns a list of matching Elements
∙ find() efficiently returns only the first match
∙ findtext() returns the .text content of the first match
</code></pre><p>不过当用：</p>
<pre><code>table = selector.findall(&apos;.//*[@id=&quot;mw-content-text&quot;]/table[2]/tr&apos;)
</code></pre><p>得到的结果显示的都是element的list，不显示里面的文字，提取的命令貌似在官网上也没找到，并且尝试：print(each.text) 完全空结果，这就有点坑了。</p>
<p>9、从第8点的分析来看，使用bs4在提取表格的时候，优势还是较大的，因为其返回的是列表形式的html内容，使得具体的提取方便，而lxml的返回的是一个看不到内容的<element table="" at="" 0x3933fa8="">，并且官网上的案例似乎也不太明了。以下是尝试的lxml提取脚本：</element></p>
<pre><code>import requests
from lxml import etree    

html = urlopen(&quot;http://en.wikipedia.org/wiki/Comparison_of_text_editors&quot;)Comparison_of_text_editors&quot;)
selector = etree.HTML(html)
#The main comparison table is currently the first table on the page
table = selector.findall(&apos;.//*[@id=&quot;mw-content-text&quot;]/table[2]/tr&apos;)
content = []
for i in range(len(table)):
    text = selector.xpath(&apos;string(//*[@id=&quot;mw-content-text&quot;]/table[2]/tr[%d + 1])&apos;%i)
    print(text)
    print(len(text))
    content.append(text)
print(content)
</code></pre><p>虽然通过lxml.etree 的findall 以及 xpath配合得到了表格里的需要的文字，但是，这样的格式，要再插入csv却非常的麻烦，这是因为我们要按行插入，而返回的列表如下面的格式（下面显示的是列表第一项）：</p>
<pre><code>[&apos;\nName\nCreator\nFirst public release\nLatest stable version\nProgramming language\nCost (US$)\nSoftware license\nOpen source\n&apos;, 
</code></pre><p>如果打印出来则是一行行的文字形式，则形如：</p>
<pre><code>Name
Creator
First public release
Latest stable version
Programming language
Cost (US$)
Software license
Open source


Acme
Rob Pike
1993
Plan 9 and Inferno
C
Free
LPL (OSI approved)
Yes
</code></pre><p>要想得到bs4的那种csv的表格形式 ，还需要额外增加很多的数据清洗代码，看上去简单，实际很复杂，比如当你想通过len()的时候计算第一项有几个单词，按我们需求是从Name到Open source 的8个单词对应csv的8个列，但python是按照字符串去统计的，返回的每个列表元素的长度肯定不同的。而如果想把\n都替换掉，则前后所需单词后紧挨在一起了。总之最后反而得不偿失，尤其是如果希望使用wt的csv写入格式的话。希望以后能找到更好的办法来解决lxml这样的表格提取问题。</p>
<pre><code>In [4]: a
Out[4]: &apos;\nName\nCreator\nFirst public release\nLatest stable version\nProgramming language\nCost (US$)\nSoftware license\nOpen source\n&apos;

In [5]: a.replace(&apos;\n&apos;, &apos;&apos;)
Out[5]: &apos;NameCreatorFirst public releaseLatest stable versionProgramming languageCost (US$)Software licenseOpen source&apos;

In [6]: length = len(a)

In [7]: length
Out[7]: 118
</code></pre><p>10、参考：</p>
<p><a href="http://jingyan.baidu.com/article/636f38bb1eb1aad6b8461088.html" target="_blank" rel="external">http://jingyan.baidu.com/article/636f38bb1eb1aad6b8461088.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/13/西部世界 1080P高清下载和自动提醒后续新出的/" itemprop="url">
                  西部世界 1080P高清下载和自动提醒后续新出的【Python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-13T20:59:28+08:00" content="2016-10-13">
              2016-10-13
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="西部世界-1080P高清下载和自动提醒后续新出的"><a href="#西部世界-1080P高清下载和自动提醒后续新出的" class="headerlink" title="西部世界 1080P高清下载和自动提醒后续新出的"></a>西部世界 1080P高清下载和自动提醒后续新出的</h1><p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-14/005536645.jpg" alt=""></p>
<p>1、主要思路是，通过高清源头的网站提供的资源，爬取后，通过迅雷实现自动下载，<br>然后后续新出的，比如下周1更新后，脚本会自动捕捉后发邮件通知，并自动下载。</p>
<p>2、代码：</p>
<pre><code># -*- coding: utf-8 -*-
# python 3.5.2
# 测试系统，Win10
# Author:Van
# 实现《西部世界》有更新后自动下载，以及邮件通知
# V1.0
# 欢迎各种改进意见
# 请把对应的帐号密码修改成自己的


# from selenium import webdriver
import requests
from lxml import etree
import time
import os
from win32com.client import Dispatch
import smtplib
from email.mime.text import MIMEText
from email.header import Header
import copy

# hints
print(&apos;请确保电脑安装了迅雷&apos;)
print(&apos;如果你用的是破解版的迅雷，请先开启再运行程序&apos;)
print()
# requests
url = &apos;http://www.btbtdy.com/btdy/dy7280.html&apos;
html = requests.get(url).content.decode(&apos;utf-8&apos;)

# lxml
selector = etree.HTML(html)
real_link = []

# to be easy, try &apos;starts-with&apos; , very useful in this case :)
HDTV = selector.xpath(&apos;//a[starts-with(@title, &quot;HDTV-1080P&quot;)]/text()&apos;)
for each in HDTV:
    print(each)


href = selector.xpath(&apos;//a[starts-with(@title, &quot;HDTV-1080P&quot;)]/@href&apos;)
print()
print(&apos;目前有 %d 集西部世界&apos; %len(href))
print()

for each in href:
    # split to get the right magnet link
    each = &apos;magnet&apos; + each.split(&apos;magnet&apos;)[-1]
    # print(each)
    real_link.append(each)

print(&apos;他们的磁链接是 :\n&apos;, real_link)
# define a temp_link in deepcopy to compare for new series
temp_link = copy.deepcopy(real_link)
print(&apos;temp_link is :&apos;, temp_link)




def addTasktoXunlei(down_url,course_infos):
    flag = False
    o = Dispatch(&quot;ThunderAgent.Agent.1&quot;)
    if down_url:
        course_path = os.getcwd()
        try:
            #AddTask(&quot;下载地址&quot;, &quot;另存文件名&quot;, &quot;保存目录&quot;,&quot;任务注释&quot;,&quot;引用地址&quot;,&quot;开始模式&quot;, &quot;只从原始地址下载&quot;,&quot;从原始地址下载线程数&quot;)
            o.AddTask(down_url, &apos;&apos;, course_path, &quot;&quot;, &quot;&quot;, -1, 0, 5)
            o.CommitTasks()
            flag = True
        except Exception:

            print(Exception.message)
            print(&quot; AddTask is fail!&quot;)
    return flag

def new_href():
    # to judge if there is a new series of WestWorld
    time.sleep(2)
    if len(real_link) &gt; len(temp_link):
        print(&apos;西部世界1080P有更新!&apos;)
        print(&apos;现在一共有 %d 集了。&apos; %len(real_link))
        return True
    else:
        return False

def send_email(htm):
    # send email to notice new WestWorld is coming
    sender = &apos;xxxxxxxx@163.com&apos;
    receiver = &apos;xxxxxxxx@qq.com,xxxxxxxx@163.com&apos;
    subject = &apos;西部世界 1080P有更新！&apos;
    smtpserver = &apos;smtp.163.com&apos;
    username = &apos;xxxxxxxx@163.com&apos;
    password = &apos;xxxxxxxx&apos;
    msg = MIMEText(htm, &apos;html&apos;, &apos;utf-8&apos;)
    msg[&apos;Subject&apos;] = Header(subject, &apos;UTF-8&apos;)
    msg[&apos;From&apos;] = sender
    msg[&apos;To&apos;] = &apos;,&apos;.join(receiver)
    smtp = smtplib.SMTP()
    smtp.connect(smtpserver)
    smtp.login(username, password)
    smtp.sendmail(sender, receiver, msg.as_string())
    smtp.quit()

def new_download():
    # only download the new WestWorld series
    if len(real_link) &gt; len(temp_link):
        # 2个地址数据的差集
        new_link = list(set(real_link).difference(set(temp_link)))
        for i in new_link:
            addTasktoXunlei(i, course_infos=None)



if __name__ == &apos;__main__&apos;:
    # download the exiting series of WestWorld
    # send_email(&apos;最新更新磁链接：&apos;+ str(real_link))
    for i in real_link:
        addTasktoXunlei(i, course_infos=None)

    # to get the later WestWorld for each hour
    while 1:
        if new_href():
            send_email(&apos;所有的下载地址（磁链接）：&apos;+ str(real_link))
            new_download()
            time.sleep(15)
            # wait for an hour
            temp_link = real_link
            print(temp_link)
            print(&apos;神剧很好看吧，亲，耐心等下一集！~！&apos;)
</code></pre><p>3、代码分析，其中用到了deepcopy，这个功能很有用，并配合了2个数组的差集，使得可以规避定时器，而让脚本直接比较temp_link的内容，而扑捉到网站有新的更新了。另外，在地址识别的时候，一开始用.xpath 没显示内容，有点奇怪，后来根据特性，使用了strats_with识别了内容。另外，原始的邮件发送函数，是一个接收人，如果要多发，则receiver的格式为list，并修改 msg[‘To’] = ‘,’.join(receiver)</p>
<p>4、邮件的作用是可以利用微信绑定来推送，相对短信，更觉方便。</p>
<p>5、感谢：<br> @陌 提供了163发送email的代码<br> @何方 提供了高清网站源<br> @其他人，交流了细节</p>
<p>6、可改进点：<br>邮件的地址内容显示的是一个列表，有待改进。</p>
<p>7、github对应仓库:</p>
<p><a href="https://github.com/vansnowpea/WestWorld-auto-download-email-xunlei-" target="_blank" rel="external">https://github.com/vansnowpea/WestWorld-auto-download-email-xunlei-</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/11/下载国外最新高清pdf的程序测试/" itemprop="url">
                  国外最新高清pdf寻找以及实现迅雷自动下载【Python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-11T20:59:28+08:00" content="2016-10-11">
              2016-10-11
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="国外最新高清pdf寻找以及实现迅雷自动下载"><a href="#国外最新高清pdf寻找以及实现迅雷自动下载" class="headerlink" title="国外最新高清pdf寻找以及实现迅雷自动下载"></a>国外最新高清pdf寻找以及实现迅雷自动下载</h1><p>1、今天意外发现国外某站，提供非常近期，甚至国内亚马逊还没上市的最新高清pdf，所以测试爬虫，看是否能自动下载。</p>
<p>2、</p>
<p>《OReilly.Introduction.to.Machine.Learning.with.Python.A.Guide.for.Data.Scientists.1449369413》  </p>
<p>一开始人工下载成功， 国内要月底才上线呢。</p>
<p>3、 随后测试程序是否可自动下载，第二本书的下载遇到了问题：总提示服务器维护，但更换了ip也这样的结果，后发现是对应网盘异常了。</p>
<p>4、代码：</p>
<pre><code># -*- coding: utf-8 -*-
# python 3.5.2
# 测试系统，Win10，Firefox V46
# Author:Van
# 实现自动下载高清最新pdf的实现
# V1.0 当前只针对效果还可以的国外zippyshare网盘
# 其他的网盘还没添加进判断语句，先共享如何迅雷下载等
# 如果您有经验优化，改进此脚本，请不吝指教
# QQ群： 206241755
# 简介：因下载最新高清pdf，正好发现www.foxebook.net提供
# 但是很多的广告，特烦人，所以尝试脚本，最后因下载需求，
# 加载了迅雷，这功能的实现小牛，不过也是网络别人共享的。。

from selenium import webdriver
import requests
from lxml import etree
import re
import os
from win32com.client import Dispatch



#test name of book : SciPy and NumPy
# book_name = input(&apos;Please input the book name in English:\n&apos;)
book_name = &apos;Introduction to Machine Learning with Python&apos;
print (&apos;begin to search book(s)...&apos;)
print (&apos;---------------------------------&apos;)
# search link is :http://www.foxebook.nethttp://www.foxebook.net/search/SciPy%20and%20NumPySciPy%20and%20NumPy
PostUrl = &quot;http://www.foxebook.net/search/&quot; + book_name
# print(PostUrl)
# get the content of html
html = requests.get(PostUrl).content

# use etree selector
selector = etree.HTML(html)

# /html/body/div/div/main/div[2]/div[2]/h3/a
# /html/body/div/div/main/div[3]/div[2]/h3/a
# above is two books&apos; xpath, so the right xpath for all book is :
# /html/body/div/div/main//div[2]/h3/a
# it can be confirmed by &apos;xpath checker&apos;
total_books = selector.xpath(&quot;/html/body/div/div/main//div[2]/h3/a/text()&quot;)
# print(&apos;total books from searching are:&apos;, total_books)

num1 = 0
link_address = []
real_address = []
def find_link():
    global num1
    # find the right book, put all links in a list of : link_address

    for i in total_books:
        num1 += 1
        if re.search(book_name,i):

            print(&apos;Congrdulations, we find the book(s):\n&apos;)
            print (&apos;**********************************&apos;)
            print(i)
            print (&apos;**********************************\n&apos;)
            href = &apos;http://www.foxebook.net&apos; + selector.xpath(&apos;//*[@id=&quot;content&quot;]/div/main/div[%d]/div[2]/h3/a/@href&apos;%num1)[0]
            # print(&apos;the book link is :&apos;, href)
            # print(&apos;will downloading...&apos;)
            html_new = requests.get(href).content
            selector_new = etree.HTML(html_new)
            link_new = selector_new.xpath(&apos;//*[@id=&quot;download&quot;]/div[2]/table/tbody/tr[1]/td[2]/a/@href&apos;)[0]
            # split the next link
            link_new = &apos;http:&apos;+link_new.split(&apos;:&apos;)[-1]
            link_address.append(link_new)
    print(&apos;download link is :&apos;, link_address)
    print(&apos;\n\n&apos;)

def real_book_link():
    # print(&apos;link_address is :&apos;, link_address)
    # dynamic on zippyshare
    for j in link_address:
        # 用浏览器实现访问

        driver = webdriver.Firefox()
        driver.maximize_window()
        driver.get(j)


        try:

            # find the download button
            title_list = driver.find_element_by_xpath(&apos;//*[@id=&quot;dlbutton&quot;]&apos;)
            film_link = title_list.get_attribute(&apos;href&apos;)
            real_address.append(film_link)

        except:
            print(&apos;can not download the book&apos;)

    print(&apos;real_book_link:&apos;, real_address)
    return real_address

def addTasktoXunlei(down_url,course_infos):
    flag = False
    o = Dispatch(&quot;ThunderAgent.Agent.1&quot;)
    if down_url:
        course_path = os.getcwd()
        try:
            #AddTask(&quot;下载地址&quot;, &quot;另存文件名&quot;, &quot;保存目录&quot;,&quot;任务注释&quot;,&quot;引用地址&quot;,&quot;开始模式&quot;, &quot;只从原始地址下载&quot;,&quot;从原始地址下载线程数&quot;)
            o.AddTask(down_url, &apos;&apos;, course_path, &quot;&quot;, &quot;&quot;, -1, 0, 5)
            o.CommitTasks()
            flag = True
        except Exception:

            print(Exception.message)
            print(&quot; AddTask is fail!&quot;)
    return flag

if __name__ == &apos;__main__&apos;:
    find_link()
    real_link = real_book_link()
    for i in real_link:
        addTasktoXunlei(i, course_infos=None)
</code></pre><p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-12/022803439.png" alt=""></p>
<p>5、第二天分析：<br>更换下载的书名为：《Introduction to Machine Learning with Python》</p>
<p>得到了2个有效的书籍目录，对比昨天的书籍名，发现提供的下载源是不同的国外网盘，而昨天的那个到今天一直打不开，而这本书的网址很快就打开了，网盘名字为： zippyshare.com </p>
<p>然后研究了下，此foxebook.net站点提供的一些网盘下载使用了多家国外网盘，并且各家的广告显示不尽相同，可靠性更是差别较大。</p>
<p>另外，发现，就SciPy and NumPy一书来说，他最后得到的地址有2个http，这应该是广告模式，而后者的http的内容是我们真实需要的，所以通过冒号：来切分a.split(‘:’)[-1]。</p>
<pre><code>In [10]: a = &apos;http://sh.st/st/7a45e8ed9f73a6a10e9a22b2d8783c44/http://www65.zippyshare.com/v/oFSWQWDk/file.html&apos;

In [11]: a
Out[11]: &apos;http://sh.st/st/7a45e8ed9f73a6a10e9a22b2d8783c44/http://www65.zippyshare.com/v/oFSWQWDk/file.html&apos;

In [12]: a.split(&apos;:&apos;)[-1]
Out[12]: &apos;//www65.zippyshare.com/v/oFSWQWDk/file.html&apos;
</code></pre><p>6、忘记说明下昨天的代码为何要用re.match （或者re.research）, 这是因为网站的关键词搜索引擎所使用的算法，我们是不知道的，但从搜索结果看，某关键词下，可能有不同的书籍，而我们是需要精确搜索，下图中实际出现了16本书，但针对SciPy and NumPy，我们要找的是第三个图对应的。因此，我们可以把显示的书名做一个match对照的循环，来实现精确匹配。而另外一方面，网站提供的书名还可能多了冒号，后面附加书名，这样的也符合我们的要求。后来发现用关键词 if xxx in yyy的方式更简便。</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-12/093157994.png" alt=""></p>
<p>7、昨天的代码一开始没有考虑到国外网盘下载异常失败的问题，并且有的搜索结果可能有多个网盘地址，而我只取了默认的第一个，考虑到下载的失败可能性，最好把所有下载地址都获取。所以代码需要修改。<br>由于：SciPy and NumPy 对应的网盘当机，选用：《Introduction to Machine Learning with Python》为例</p>
<p>经过对照，在最后的下载界面，是动态的，因此调用selenium+Firefox组合。最后终于得到了完整pdf队中的链接，但速度明显比较慢了，在本例中，是rar后缀的压缩包格式，里面含有pdf。</p>
<pre><code>download link is : [&apos;http://www78.zippyshare.com/v/hBU7JYZp/file.html&apos;, &apos;http://www65.zippyshare.com/v/oFSWQWDk/file.html&apos;]



content: 
book link: http://www78.zippyshare.com/d/hBU7JYZp/2248094/OReilly.Introduction.to.Machine.Learning.with.Python.A.Guide.for.Data.Scientists.1449369413.rar
content: 
book link: http://www65.zippyshare.com/d/oFSWQWDk/1124867/OReilly.Introduction.to.Machine.Learning.with.Python.1449369413_Early.Release.rar

Process finished with exit code 0
</code></pre><p>8、接下来的一个问题，怎么让程序自动下载这2个链接？群里有人推荐了一些别的软件，但是我想来想去因为以后总要面对下载速度的问题，还是选定了迅雷破解版吧，除非将来有其他更好的方案，好在有人共享了一个方案，还特别简单，不过据说只能支持http格式，BT格式的以后再想办法。</p>
<p>9：补充说明，在正文代码的第2个下载地址，是有问题的，差别在于地址点击后，前者可在浏览器或者迅雷直接下载，而后者浏览器没反映，迅雷里下载的是一个html。尽管2个链接的提取方法完全一样，但一个好使，一个异常，由于是同一本书的前后2个小版本，我也不管他了，但为了验证迅雷是否能同时下载5个（代码里设定同时下载的最大值，也是一般默认值） 我用额外的测试脚本加载了一个新的链接，是证明可同时下载的，如图：</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-12/203618609.png" alt=""> </p>
<p>9、参考：</p>
<p><a href="http://neue.v2ex.com/t/275703" target="_blank" rel="external">http://neue.v2ex.com/t/275703</a></p>
<p>10、github对应仓库：</p>
<p><a href="https://github.com/vansnowpea/download-pdf-with-Xunlei" target="_blank" rel="external">https://github.com/vansnowpea/download-pdf-with-Xunlei</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Van" />
          <p class="site-author-name" itemprop="name">Van</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">65</span>
              <span class="site-state-item-name">Artikel</span>
            </a>
          </div>

          

          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Van</span>
</div>

<div class="powered-by">
  Erstellt mit  <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  




  
  

  

  

  

</body>
</html>
