<!doctype html>



  


<html class="theme-next muse use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta property="og:type" content="website">
<meta property="og:title" content="A Song of Python and Anaconda">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="A Song of Python and Anaconda">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Song of Python and Anaconda">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: 'Author'
    }
  };
</script>




  <link rel="canonical" href="http://yoursite.com/page/2/"/>

  <title> A Song of Python and Anaconda </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">A Song of Python and Anaconda</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/27/收到《Python for data analysis》作者的邮件回复/" itemprop="url">
                  收到《Python for data analysis》作者的邮件回复
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-09-27T14:20:28+08:00" content="2016-09-27">
              2016-09-27
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-27/150628293.jpg" alt=""></p>
<h1 id="简介：-收到《Python-for-data-analysis》作者的邮件回复-：）"><a href="#简介：-收到《Python-for-data-analysis》作者的邮件回复-：）" class="headerlink" title="简介： 收到《Python for data analysis》作者的邮件回复 ：）"></a>简介： 收到《Python for data analysis》作者的邮件回复 ：）</h1><p>1、上次给他写了一个邮件，建议用Anaconda来写下一版本，虽然过了几天还是收到了回复，看样子他也意识到Anaconda更好点，也表示第二版会采用：</p>
<pre><code>try

from matplotlib.pyplot import *

and running

%matplotlib

I am creating a 2nd edition of the book, and it will use Anaconda
instead of Canopy in the instructions.

Thanks!
</code></pre><p>2、然后我去Python中文社区问了几个人，表示有兴趣翻译，由于第一版是机械工业出版社搞的中译版，发了一个email咨询是否将来打算出第二版的中译，但是还没得到回复，想了下，如果他们不翻译，就召集社区的小伙伴们来翻译吧。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/27/matplotlib中文显示乱码的解决办法/" itemprop="url">
                  matplotlib中文显示乱码的解决办法
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-09-27T13:20:28+08:00" content="2016-09-27">
              2016-09-27
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介：-matplotlib中文显示乱码的解决办法-：）"><a href="#简介：-matplotlib中文显示乱码的解决办法-：）" class="headerlink" title="简介： matplotlib中文显示乱码的解决办法 ：）"></a>简介： matplotlib中文显示乱码的解决办法 ：）</h1><p>1、在源代码开头加入以下几行：</p>
<pre><code>from pylab import *
mpl.rcParams[&apos;font.sans-serif&apos;] = [&apos;SimHei&apos;] #指定默认字体

mpl.rcParams[&apos;axes.unicode_minus&apos;] = False #解决保存图像是负号&apos;-&apos;显示为方块的问题
</code></pre><p>2、上述就针对单个py文件，如果想全部的，可以这么操作：</p>
<ul>
<li>\Lib\site-packages\matplotlib\mpl-data\matplotlibrc    用任意文本编辑器打开。（最好先备份一下）<br>找到第129行：#font.family， 将其注释去掉，冒号后面的值改为Microsoft YaHei</li>
<li>找到第141行：#font.sans-serif， 将其注释去掉，并将Microsoft YaHei添加到冒号后面的最前面，注意还要再加一个英文逗号（,）</li>
<li>并设置axes.unicode_minus = False #解决保存图像是负号’-‘显示为方块的问题</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/25/《利用Python进行数据分析》如何把kindle的电子书转成pdf的教程/" itemprop="url">
                  如何把kindle的电子书转成word等格式的教程
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-09-25T23:20:28+08:00" content="2016-09-25">
              2016-09-25
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介：-如何把kindle的电子书转成word等格式的教程-：）"><a href="#简介：-如何把kindle的电子书转成word等格式的教程-：）" class="headerlink" title="简介： 如何把kindle的电子书转成word等格式的教程 ：）"></a>简介： 如何把kindle的电子书转成word等格式的教程 ：）</h1><p>1、参考知乎的步骤， <a href="http://www.zhihu.com/question/38451995" target="_blank" rel="external">http://www.zhihu.com/question/38451995</a></p>
<p>2、下载去除DRM的破解版本，不然只能破解3本书，参考此网址： <a href="http://www.d9soft.com/soft/102882.htm" target="_blank" rel="external">http://www.d9soft.com/soft/102882.htm</a></p>
<p>3、使用该网站，进行pdf转换： <a href="http://www.epubconverter.com/azw-to-pdf-converter/" target="_blank" rel="external">http://www.epubconverter.com/azw-to-pdf-converter/</a></p>
<p>4、成功把《利用Python进行数据分析》转成了pdf，当然我事先花销了巨额的0.1元注册了一个Kindle Unlimited  帐号</p>
<p>5、为了方便复制书中的代码实例，继续用calibre 软件进行转换成docx格式，不用对着那些网上的扫描版，或者纸质书，坑爹的挨个自己输入命令了有木有， </p>
<p>6、示范图： </p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-26/001138836.png" alt=""></p>
<p>7、我已经为偷懒的你，上传了本书，可以直接下载word版本啦。请点击<a href="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-26/001313882.docx" target="_blank" rel="external">【下载点我】</a></p>
<p>8、记得重命名，方便以后查找。</p>
<p>9、第八章spx指数的举例，代码我修正到pycharm里：</p>
<pre><code>import matplotlib.pyplot as plt
from datetime import datetime
import pandas as pd
fig = plt.figure()
ax = fig.add_subplot(1, 1, 1)
data = pd.read_csv(&apos;D:\mine\pydata-book-master\ch08/spx.csv&apos;, index_col=0, parse_dates=True)
spx = data[&apos;SPX&apos;]
spx.plot(ax=ax, style=&apos;k-&apos;)
crisis_data = [      (datetime(2007, 10, 11), &apos;Peak of bull market&apos;),      (datetime(2008, 3, 12), &apos;Bear Stearns Fails&apos;),      (datetime(2008, 9, 15), &apos;Lehman Bankruptcy&apos;) ]
for date, label in crisis_data:
    ax.annotate(label, xy=(date, spx.asof(date) + 50),                 xytext=(date, spx.asof(date) + 200),                 arrowprops=dict(facecolor=&apos;black&apos;),                 horizontalalignment=&apos;left&apos;, verticalalignment=&apos;top&apos;)
# 放大到2007-2010
    ax.set_xlim([&apos;1/1/2007&apos;, &apos;1/1/2011&apos;])
    ax.set_ylim([600, 1800])
    ax.set_title(&apos;Important dates in 2008-2009 financial crisis&apos;)

plt.show()
</code></pre><p>结果图，有木有一点专业的味道？<br> <img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-26/105503895.png" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/23/豆瓣电影TOP250的爬取和作图分析/" itemprop="url">
                  《利用Python进行数据分析》豆瓣电影TOP250的爬取和作图分析【python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-09-23T23:20:28+08:00" content="2016-09-23">
              2016-09-23
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介：-又回到豆瓣了，这是多适合爬虫的网站-：）"><a href="#简介：-又回到豆瓣了，这是多适合爬虫的网站-：）" class="headerlink" title="简介： 又回到豆瓣了，这是多适合爬虫的网站 ：）"></a>简介： 又回到豆瓣了，这是多适合爬虫的网站 ：）</h1><p>1、这次的对象是top 250 ， 网址：  <a href="https://movie.douban.com/top250" target="_blank" rel="external">https://movie.douban.com/top250</a> 目的是对这250部电影的分类做一个统计。</p>
<p>2、实际有其他人做了分析，正好看到，发现其代码比较漂亮，所以研读，顺便复习检阅自己学习成果。秉承一贯的作风，做一定的细节分析。先看下原文代码：</p>
<pre><code># -*- coding: utf-8 -*-
# !/usr/bin/env python

from lxml import etree
import requests
import pymysql
import matplotlib.pyplot as plt
from pylab import *
import numpy as np

# 连接mysql数据库
conn = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;, passwd = &apos;54545454&apos;, db = &apos;douban&apos;, charset = &apos;utf8&apos;)
cur = conn.cursor()
cur.execute(&apos;use douban&apos;)

def get_page(i):
    url = &apos;https://movie.douban.com/top250?start={}&amp;filter=&apos;.format(i)

    html = requests.get(url).content.decode(&apos;utf-8&apos;)

    selector = etree.HTML(html)
    # //*[@id=&quot;content&quot;]/div/div[1]/ol/li[1]/div/div[2]/div[2]/p[1]
    content = selector.xpath(&apos;//div[@class=&quot;info&quot;]/div[@class=&quot;bd&quot;]/p/text()&apos;)
    print(content)

    for i in content[1::2]:
        print(str(i).strip().replace(&apos;\n\r&apos;, &apos;&apos;))
        # print(str(i).split(&apos;/&apos;))
        i = str(i).split(&apos;/&apos;)
        i = i[len(i) - 1]
        # print(&apos;zhe&apos; +ｉ)
        # print(i.strip())
        # print(i.strip().split(&apos; &apos;))
        key = i.strip().replace(&apos;\n&apos;, &apos;&apos;).split(&apos; &apos;)
        print(key)
        for i in key:
            if i not in douban.keys():
                douban[i] = 1
            else:
                douban[i] += 1

def save_mysql():
    print(douban)
    for key in douban:
        print(key)
        print(douban[key])
        if key != &apos;&apos;:
            try:
                sql = &apos;insert douban(类别, 数量) value(&apos; + &quot;\&apos;&quot; + key + &quot;\&apos;,&quot; + &quot;\&apos;&quot; + str(douban[key]) + &quot;\&apos;&quot; + &apos;);&apos;
                cur.execute(sql)
                conn.commit()
            except:
                print(&apos;插入失败&apos;)
                conn.rollback()


def pylot_show():
    sql = &apos;select * from douban;&apos;
    cur.execute(sql)
    rows = cur.fetchall()
    count = []
    category = []

    for row in rows:
        count.append(int(row[2]))
        category.append(row[1])
    print(count)
    y_pos = np.arange(len(category))
    print(y_pos)
    print(category)
    colors = np.random.rand(len(count))
    plt.barh()
    plt.barh(y_pos, count, align=&apos;center&apos;, alpha=0.4)
    plt.yticks(y_pos, category)
    for count, y_pos in zip(count, y_pos):
        plt.text(count, y_pos, count,  horizontalalignment=&apos;center&apos;, verticalalignment=&apos;center&apos;, weight=&apos;bold&apos;)
    plt.ylim(+28.0, -1.0)
    plt.title(u&apos;豆瓣电影250&apos;)
    plt.ylabel(u&apos;电影分类&apos;)
    plt.subplots_adjust(bottom = 0.15)
    plt.xlabel(u&apos;分类出现次数&apos;)
    plt.savefig(&apos;douban.png&apos;)


if __name__ == &apos;__main__&apos;:
    douban = {}
    for i in range(0, 250, 25):
        get_page(i)
    save_mysql()
    pylot_show()
    cur.close()
    conn.close()
</code></pre><p>3、首先是他用了selector = etree.HTML(html)  而我用的比较多的是bs4，应该是殊途同归。他的xpath路径是：</p>
<pre><code>content = selector.xpath(&apos;//div[@class=&quot;info&quot;]/div[@class=&quot;bd&quot;]/p/text()&apos;) 
</code></pre><p>而我用的偷懒模式：直接浏览器找到的： </p>
<pre><code>selector.xpath(&apos;//*[@id=&quot;content&quot;]/div/div[1]/ol/li[1]/div/div[2]/div[2]/p[1]/text()&apos;)
</code></pre><p>注意，默认到P[1]的路径，因为是需要读取里面的文本部分，所以加入/text()</p>
<p>4、这样就得到了第一页的影视信息的文本，不过如果用ipthon分步操作查看， 那简直是逆天的格式，如图：</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-23/225057825.png" alt=""></p>
<p>5、必须进行文字提取处理了。 </p>
<p>首先，这一大坨的，为了简单，我们用单元测试的思想，先调试第一页第一个，这里之前已经设置从：</p>
<pre><code>url = &apos;https://movie.douban.com/top250?start={}&amp;filter=&apos;.format(i)
</code></pre><p>修改为：</p>
<pre><code>url = &apos;https://movie.douban.com/top250?start={1}&amp;filter=&apos;
</code></pre><p>同时，观察整个循环输出的格式是一个列表，每个元素是一个字符串，那么第一个电影的电影信息对应的字符串是：</p>
<pre><code>&apos;\n                            导演: 弗兰克·德拉邦特 Frank Darabont\xa0\xa0\xa0主演: 蒂姆·罗宾斯 Tim Robbins /...&apos;, &apos;\n                            1994\xa0/\xa0美国\xa0/\xa0犯罪 剧情\n                        &apos;
</code></pre><p>和原始网页的信息对照，实际就是第一部分包含导演主演信息，第二部分是年份国家和剧种， 就本文，我们需要的是第二部分的内容，也就是“1994 / 美国 / 犯罪 剧情”这部分内容。然后呢，因为整个content 包含了25部电影的文本， 这些都保存在列表里，并且我们需要进一步处理的，都在对应坐标1、3、5、、这样的奇数里。因为列表第一个是从0开始的。这就是第一个for循环的意义所在，用到了python的切片知识第二个冒号，表示从下表1的元素开始检索，并且隔开2个元素为下一次检索：</p>
<pre><code>for i in content[1::2]:
</code></pre><p>查看了循环内的第一句为，注意这只是print，没有运行具体的代码影响原来的字符串：</p>
<pre><code>print(str(i).strip().replace(&apos;\n\r&apos;, &apos;&apos;))
</code></pre><p>这句的意思就是得到整个content列表中，下标为1、3、5。。。。的元素，并通过strip（）来进行去掉首尾的多余的空格，,随后使用replace函数，把’\n\r’替换为空字符。我们可以在ipython中验证下：</p>
<p>记录：aa = conntent[1]：  </p>
<pre><code>aa =  &apos;\n                            1994\xa0/\xa0美国\xa0/\xa0犯罪 剧情\n                        &apos;
</code></pre><p>执行：aa.strip()，得到：</p>
<pre><code>In [19]: aa.strip()
Out[19]: &apos;1994\xa0/\xa0美国\xa0/\xa0犯罪 剧情&apos;

In [20]: aa.strip().replace(&apos;\n\r&apos;, &apos;&apos;)
Out[20]: &apos;1994\xa0/\xa0美国\xa0/\xa0犯罪 剧情&apos;
</code></pre><p>发现上述的replace函数似乎没起作用，那是这里正好没有’\n\r’，同时你可以发现，这里怎么有4个地方有\xa0 ？ 这是什么呢？ 原来是：转义字符，”\x”后接数字（两位）代表16进制数，这玩意牵涉编码的问题，打印的时候是一个空格。</p>
<p>然后循环里面的开始执行的命令都是为了去除\n和空格这些没有的东西，i = str(i).split(‘/‘)就是把去除空格和\n的字符串通过‘/’分隔在列表里。</p>
<pre><code>In [35]: aa =  &apos;\n                            1994\xa0/\xa0美国\xa0/\xa0犯罪 剧情\n                        &apos;

In [36]: aa = aa.split(&apos;/&apos;)

In [37]: aa = aa(len(aa)-1)
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-37-06f75198160a&gt; in &lt;module&gt;()
----&gt; 1 aa = aa(len(aa)-1)

TypeError: &apos;list&apos; object is not callable

In [38]: aa = aa[len(aa)-1]

In [39]: aa
Out[39]: &apos;\xa0犯罪 剧情\n
</code></pre><p>随后，通过</p>
<pre><code>In [40]: key = aa.strip().replace(&apos;\n&apos;, &apos;&apos;).split(&apos; &apos;)

In [41]: key
Out[41]: [&apos;犯罪&apos;, &apos;剧情&apos;]
</code></pre><p>发现，已经把\xa0当作左侧的空格给替换掉了，实际他显示出来就是一个空格的。然后通过中间的空格再劈开，得到了2个元素的字符串的列表。<br>这样就清洗出了所需要的数据。</p>
<p>下面的代码紧跟了一个针对key的for循环，是用来构建一个名为douban的字典dict，后续会把他的值再导入到数据库中。</p>
<pre><code>for i in key:
    if i not in douban.keys():
        douban[i] = 1
    else:
        douban[i] += 1
</code></pre><p>里面的含义是：如果一个电影的分类关键词，在douban字典中（此时数据还没导入到数据库）不存在，那么新建一个对应名字的键值（keys），数值为1.否则如果是已经存在的，那么累加1.</p>
<p>5、 第二个函数是def save_mysql():作用是把提取的数据加载到数据库中去。<br>其中insert的那一行命令写的有点个性，但因为用到了过多的引号，所以我不是很推荐，一般的写法是： %s + 变量名</p>
<p>6、最后一个函数是用来画图的， 这块后续要配合nunpy，pandas等一直在加强下学习。</p>
<p>统计结果显示，绝大部分的好电影都是通过剧情抓住人心的：</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-27/144837956.png" alt=""></p>
<p>7、 参考： <a href="http://www.jianshu.com/p/ef242e025cdf" target="_blank" rel="external">爬取豆瓣电影top250提取电影分类进行数据分析</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/23/数值分析和一个bug解决记录/" itemprop="url">
                  数值分析和一个bug解决记录【python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-09-23T23:20:28+08:00" content="2016-09-23">
              2016-09-23
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介：-数值分析和一个bug解决记录-：）"><a href="#简介：-数值分析和一个bug解决记录-：）" class="headerlink" title="简介： 数值分析和一个bug解决记录 ：）"></a>简介： 数值分析和一个bug解决记录 ：）</h1><p>1、这个bug是在使用python3.5.2的时候发生的，由于同时安装anaconda  有时候因为一些测试python2的代码 也安装卸载 最终出现了： Fatal error in launcher: Unable to create process using ‘“‘</p>
<p>2、解决方案，控制面板卸载后，再到python3 的安装路径把文件夹都删除，此时，保留anaconda版本，在cmder输入ipython就可以正常运行了。</p>
<p>3、说到数值分析，感觉还是要先阅读下相关书籍，虽然以前matlab接触过一些。首先看的就是评价还不错的《利用python进行数值分析》，但是发现了一个问题，所以马上给作者写了一个email如下图：</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-24/235703049.png" alt=""></p>
<p>4、</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/22/验证码识别的测试/" itemprop="url">
                  验证码识别的测试【python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-09-22T14:20:28+08:00" content="2016-09-22">
              2016-09-22
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-23/012758858.jpg" alt=""></p>
<h1 id="简介：-验证码识别的测试，因故需做一个自动的多用户注册的脚本"><a href="#简介：-验证码识别的测试，因故需做一个自动的多用户注册的脚本" class="headerlink" title="简介： 验证码识别的测试，因故需做一个自动的多用户注册的脚本"></a>简介： 验证码识别的测试，因故需做一个自动的多用户注册的脚本</h1><p>1、查阅相关博客，建议使用的是Python+Selenium+PIL+Tesseract ，又有人推荐了Pytesser，不过这个Pytesser的安装还挺坑的。</p>
<p>2、开始参考的是：<br><a href="http://www.th7.cn/Program/Python/201602/768304.shtml" target="_blank" rel="external">http://www.th7.cn/Program/Python/201602/768304.shtml</a></p>
<p>以及这个</p>
<p><a href="http://blog.csdn.net/lanfan_11/article/details/45558573" target="_blank" rel="external">http://blog.csdn.net/lanfan_11/article/details/45558573</a></p>
<p>3、但测试了半天，无论我按照哪个方法，最终我都不能import pytesser ， 一开始以为成功了，原来是我按照他的例子直接在pytesseract-v0.0.1的文件夹测试的脚本，那自然可以了。</p>
<p>4、毕竟第一次遇到需要这么折腾的第三方库，而且还是好几年前就停止更新了，干脆就直接把需要编写的py文件丢到这个pytesser文件夹来规避。 </p>
<p>5、后来又发现有的博客推荐了pytesseract ，看名字应该是继承了pytesser，但是保持更新的，果然顺利安装，那么就是他了。那么更新下使用的工具组合为：Python+Selenium+PIL+pytesseract+Tesseract </p>
<p>6、剩下就是如何识别验证码的问题，由于测试的网站使用的.aspx的动态图，导致每次输入url得到不同的验证码。<br>所以一不做二不休，使用了截屏计算其验证码方位后单独识别的方案。(另外一个可操作方案是使用cookie)</p>
<p>过程：</p>
<pre><code># coding:utf-8
# python 3.5.2


from selenium.webdriver.support import ui as ui
from selenium.webdriver.common.keys import Keys #需要引入keys 包
from selenium.webdriver.common.action_chains import ActionChains
from selenium import webdriver
import pytesseract
import time
from PIL import Image,ImageEnhance

num = 400
# wait = ui.WebDriverWait(browser, 10)
# 已经人工测试了一个，所以从第二2个开始
for i in range(2, num+1):

    name_cn = &apos;aaa&apos;        
    browser = webdriver.PhantomJS()
    browser.maximize_window()
    url = &quot;http://www.wangzhi.com&quot;
    browser.get(url)
    wait = ui.WebDriverWait(browser, 20)
    wait.until(lambda browser:browser.find_element_by_xpath(&quot;//*[@id=\&quot;ussheng\&quot;]&quot;))
    shs1 = browser.find_element_by_xpath(&quot;//*[@id=\&quot;ussheng\&quot;]&quot;).send_keys(&quot;shengfen&quot;)
    shs2 = browser.find_element_by_xpath(&quot;//*[@id=\&quot;uscity\&quot;]&quot;).send_keys(&quot;xxshi&quot;)
    mhq = browser.find_element_by_xpath(&quot;//*[@id=\&quot;usxian\&quot;]&quot;).send_keys(&quot;yyqu&quot;)
    nling = browser.find_element_by_xpath(&quot;//*[@id=\&quot;inscage\&quot;]&quot;).send_keys(&quot;nianling&quot;)
    dwei = browser.find_element_by_xpath(&quot;//*[@id=\&quot;worker\&quot;]&quot;).send_keys(&quot;dizhi&quot;)
    name_input = browser.find_element_by_xpath(&quot;//*[@id=\&quot;ustruename\&quot;]&quot;).send_keys(name_cn + &apos;%d&apos;%i)

    # 选择性别，下拉框操作
    sex = browser.find_element_by_xpath(&quot;//*[@id=\&quot;DropDownList1\&quot;]&quot;)
    sex.find_element_by_xpath(&quot;//*[@id=\&quot;DropDownList1\&quot;]/option[2]&quot;).click()

    # 验证码识别，思路，右键保存验证码图片，识别数字或者字母。但是保存不能执行，失败
    ###############################################################################
    # # xpath： //*[@id=&quot;ValidImage&quot;]
    # shi_bie_ma = browser.find_element_by_xpath(&quot;//*[@id=\&quot;ValidImage\&quot;]&quot;)
    # action = ActionChains(browser).move_to_element(shi_bie_ma)
    # action.context_click(shi_bie_ma)
    # action.send_keys(Keys.ARROW_DOWN)
    # action.send_keys(&apos;v&apos;)
    # action.perform()
    ###############################################################################



    # 通过下载图片后识别，发现是aspx 每次打开url都更新识别码，所以失败。看来只好一开始就截屏啦。

    # 截屏
    browser.get_screenshot_as_file(&apos;C:\\van\\image1.jpg&apos;)#比较好理解

    # 检测识别码坐标
    imgelement = browser.find_element_by_xpath(&apos;//*[@id=&quot;ValidImage&quot;]&apos;) #定位验证码
    location = imgelement.location #获取验证码x,y轴坐标

    size=imgelement.size #获取验证码的长宽
    range=(int(location[&apos;x&apos;]),int(location[&apos;y&apos;]),int(location[&apos;x&apos;]+size[&apos;width&apos;]),int(location[&apos;y&apos;]+size[&apos;height&apos;])) #写成我们需要截取的位置坐标

    im =Image.open(&apos;C:\\van\\image1.jpg&apos;)
    # 设置要裁剪的区域
    region = im.crop(range)     #此时，region是一个新的图像对象。
    #region.show()#显示的话就会被占用，所以要注释掉
    region.save(&quot;C:\\van\\image2.jpg&quot;)


     #--------------------图片增强+自动识别简单验证码-----------------------------
    #time.sleep(3)防止由于网速，可能图片还没保存好，就开始识别

    im=Image.open(&quot;C:\\van\\image2.jpg&quot;)
    imgry = im.convert(&apos;L&apos;)#图像加强，二值化
    sharpness =ImageEnhance.Contrast(imgry)#对比度增强
    sharp_img = sharpness.enhance(2.0)

    sharp_img.save(&quot;C:\\van\\image2.jpg&quot;)

    #http://www.cnblogs.com/txw1958/archive/2012/02/21/2361330.html

    #imgry.show()#这是分布测试时候用的，整个程序使用需要注释掉
    #imgry.save(&quot;E:\\image_code.jpg&quot;)
    im=Image.open(&quot;C:\\van\\image2.jpg&quot;)
    code = pytesseract.image_to_string(im)#code即为识别出的图片数字str类型
    print(code)
    #打印code观察是否识别正确

    #-------------------------------------------------------------------
    code_input = browser.find_element_by_xpath(&quot;//*[@id=\&quot;txtCheckCode\&quot;]&quot;).send_keys(code)
    # login
    browser.find_element_by_xpath(&quot;//*[@id=\&quot;Button1\&quot;]&quot;).click()
    print(&quot;fished,%d&quot;%i)
    browser.quit()
</code></pre><p>7、程序分析：</p>
<ul>
<li>虽然使用的截屏然后识别验证码的方式，也许不是最优雅，不过可可以通过元素的imgelement.location 来获取验证码x,y轴坐标，从而可以得到精确的验证码截图区域，否则人工去调试也不是不行，但需要在画图板用鼠标尽可能准确的定位。</li>
<li>增加了图片增加识别技术，加大了识别验证码的概率。</li>
<li>这段代码的不足之处是没有检测验证码识别提交后，是否失败的判断，这主要是测试的网站标的，实在做的太烂了，点了二维码不会立刻提示错误与否，而是卡机。</li>
</ul>
<p>8、总结：有较多的注释，记录了一些操作思路。学习了验证码的初级识别技术。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/21/IP池的建立/" itemprop="url">
                  IP池的建立
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-09-21T22:20:28+08:00" content="2016-09-21">
              2016-09-21
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介：-今天测试百度api，遇到bug验证半天，最后发现是ip被墙，。所以寻找ip池方法"><a href="#简介：-今天测试百度api，遇到bug验证半天，最后发现是ip被墙，。所以寻找ip池方法" class="headerlink" title="简介： 今天测试百度api，遇到bug验证半天，最后发现是ip被墙，。所以寻找ip池方法"></a>简介： 今天测试百度api，遇到bug验证半天，最后发现是ip被墙，。所以寻找ip池方法</h1><p>1、由于已经有人写了相关的代码，因此只需要用来对照使用即可。</p>
<p>2、仍然记录一些细节，该程序的运行不是直接点main.py的run就完事了， 而是需要在cmd下额外输入命令。</p>
<p>3、 检测ok的ip会自动保存到mongodb，但中间因为软件兼容问题，可能遇到bson模块异常，记得升级mongoengine到最新。</p>
<p>4、不过抓了400个ip，只有10个返回ok，</p>
<p>参考  <a href="http://www.cnblogs.com/qiyeboy/p/5517271.html" target="_blank" rel="external">Scrapy爬取美女图片第三集 代理ip(上) (原创)
</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/21/bson模块丢失，原来是mongoengine坑-/" itemprop="url">
                  bson模块丢失，原来是mongoengine坑-
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-09-21T21:20:28+08:00" content="2016-09-21">
              2016-09-21
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介：-运行别人的一个程序，提示缺少Bson模块，自然去安装，却发现没有名下的code模块"><a href="#简介：-运行别人的一个程序，提示缺少Bson模块，自然去安装，却发现没有名下的code模块" class="headerlink" title="简介： 运行别人的一个程序，提示缺少Bson模块，自然去安装，却发现没有名下的code模块"></a>简介： 运行别人的一个程序，提示缺少Bson模块，自然去安装，却发现没有名下的code模块</h1><p>1、原来这个模块是和mongodb相关的，当安装了bson模块，因版本问题，会引起一些文件缺失，</p>
<p>2、而mongodb官网上，也不建议外装bson：</p>
<p>到pymongo官方文档里查，第一句就是：<br>Warning Do not install the “bson” package. PyMongo comes with its own bson package; doing “pip install bson” or “easy_install bson” installs a third-party package that is incompatible with PyMongo.<br>PyMongo has no required dependencies.</p>
<p>3、还好最后安装最新的mongoengine，解决了这个问题。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/20/豆瓣电影的检索爬虫【python】/" itemprop="url">
                  豆瓣电影的检索爬虫【python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-09-20T14:20:28+08:00" content="2016-09-20">
              2016-09-20
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介：-豆瓣网的电影分类比较清晰，比较了音乐板块，还是感觉电影板块用来做爬虫比较合适"><a href="#简介：-豆瓣网的电影分类比较清晰，比较了音乐板块，还是感觉电影板块用来做爬虫比较合适" class="headerlink" title="简介： 豆瓣网的电影分类比较清晰，比较了音乐板块，还是感觉电影板块用来做爬虫比较合适"></a>简介： 豆瓣网的电影分类比较清晰，比较了音乐板块，还是感觉电影板块用来做爬虫比较合适</h1><p>1、在参考他文的基础上，进行了学习分析。本文将记录和探讨细节部分。</p>
<p>2、url定义为电影板块： <a href="https://movie.douban.com/" target="_blank" rel="external">https://movie.douban.com/</a></p>
<p>3、遇到大型网站数据抓取，尤其是海外站点，因为延时造成的失败经常发生，遇到这样的情况，则建议用ui的加载until功能，在本测试案例中没有使用，因为测试结果响应较快。</p>
<p>4、因为要从大量的数据进行排序筛选，所以xpath的路径要尽可能的精确，如果直接用firebug的自带xpath地址，在排序检索，并提交内容时，可能因为路径有一个层级的差别导致失败报错。尽管很多时候，这个差别在图标点击上的效果一样。所以也是坑之一。</p>
<p>5、在运行程序前，看下内存使用率，如果较高就重启后再运行爬虫，否则由于selenium的加载浏览器比较消耗内存，很可能在此状态下，浏览器的响应延缓较大，因此，需要写好print信息，或者logging信息，以更明确程序执行点。</p>
<p>6、多选项排序的时候，建议做成gui，这是因为可以减少后续使用的重复输入。</p>
<p>7、一般来说，热评总是不缺，但是长评对于新电影是可能空缺的，为此，务必要加载try–except方式，来规避这样的情况。在本案例中，第六名的电影，正好没有长评，如果没有try except，则程序会在第六条就跳出终止了。</p>
<p>8、功能实现，为简单，只按照豆瓣电影默认的按照热门—-按热门排序，爬取了前20的电影的名字，网址，热评和长评信息，</p>
<p>9、代码如下：</p>
<pre><code># coding:utf-8
# 改编，精简版
# python 3.5.2
# 豆瓣网排名抓取和影评抓取V1.0

import time
from selenium import webdriver
import selenium.webdriver.support.ui as ui

url = &quot;https://movie.douban.com/&quot;
browser = webdriver.Firefox()
browser1 = webdriver.PhantomJS()
browser.get(url)

SUMRESOURCES = 0

# 热门
browser.find_element_by_xpath(&quot;//*[@id=\&quot;gaia_frm\&quot;]/div[1]/div[1]/label[1]&quot;).click()

# 按热度排序
browser.find_element_by_xpath(&quot;//*[@id=\&quot;gaia_frm\&quot;]/div[3]/div[1]/label[1]&quot;).click()

# 加载更多
browser.find_element_by_xpath(&quot;//*[@id=\&quot;gaia\&quot;]/div[4]/a&quot;).click()
time.sleep(2)

def get_title():

    global SUMRESOURCES
    # 定义抓top 20的电影
    num = 20
    # 定义抓长评
    long = 1
    for i in range(1, num+1):
            try:
                # 抓第i个图的基本信息
                title_list = browser.find_element_by_xpath(&quot;//*[@id=\&quot;gaia\&quot;]/div[4]/div/a[%d]&quot;%i)
                print(&apos;------------------NO--&apos;+ &apos;&apos;+str(SUMRESOURCES+1) +&apos;--------------------&apos;)
                print()
                print(&apos;电影名字:&apos;, title_list.text)
                film_link = title_list.get_attribute(&apos;href&apos;)
                print(&apos;电影链接:&apos;, film_link)
                SUMRESOURCES += 1
                get_detail(film_link,long)
            except:
                print(&apos;不能抓到影视信息&apos;)


def get_detail(url,long=0):
    browser1.get(url)

    # 简介内容
    jian_jie = browser1.find_element_by_xpath(&quot;/html/body/div[3]/div[1]/div/div[1]/div[3]/div/span[1]&quot;).text
    print(&apos;电影简介：&apos;, jian_jie)

    # 热门评论
    browser1.find_element_by_xpath(&quot;//*[@id=\&quot;hot-comments-tab\&quot;]&quot;).click()
    for i in range(1, 5):
        try:

            re_ping = browser1.find_element_by_xpath(&quot;//*[@id=\&quot;hot-comments\&quot;]/div[%d]/div/p&quot;%i).text
            print(&apos;-----&apos;+&apos;热评:&apos;+&apos;------&apos;)
            print(u&apos;最新热评:&apos;+ re_ping)
        except:
            print(&apos;抓取热评失败&apos;)



    if long == 1:
        try:
            # 点开下拉三角，展开长评
            # 使用对应img里自带的class
            browser1.find_element_by_xpath(&quot;//img[@class=&apos;bn-arrow&apos;]&quot;).click()
            time.sleep(1)

            long_get = browser1.find_element_by_xpath(&quot;//div[@class=&apos;review-bd&apos;]/div[2]/div&quot;)

            if long_get.text.encode(&apos;utf-8&apos;)==&apos;提示: 这篇影评可能有剧透&apos;:

                print(&apos;发现恶心的剧透！将跳过！&apos;)
                long_ping = browser1.find_element_by_xpath(&quot;//div[@class=&apos;review-bd&apos;]/div[2]/div[2]&quot;)
            else:
                long_ping = long_get
            print(&apos;----------------------------------------&apos;+&apos;长评:&apos;+&apos;----------------------------------------&apos;)
            print(&apos;长评:&apos;, long_ping.text)
        except:
            print(&apos;抓取长评失败&apos;)



if __name__==&quot;__main__&quot;:
    get_title()
</code></pre><p>10、参考： <a href="http://www.jianshu.com/p/bb4f2f7c62ed" target="_blank" rel="external">Python自定义豆瓣电影种类，排行，点评的爬取与存储（进阶上</a></p>
<p>11、前20个热门影评带长评，看了下很长,只保留了1和6的电影信息，有兴趣的就看看，没兴趣就忽略：</p>
<p>D:\Anaconda3\python.exe C:/Users/Administrator/PycharmProjects/untitled1/test/blog.py<br>——————NO–1——————–</p>
<p>电影名字: 釜山行 8.3<br>电影链接: <a href="https://movie.douban.com/subject/25986180/?tag=%E7%83%AD%E9%97%A8&amp;from=gaia" target="_blank" rel="external">https://movie.douban.com/subject/25986180/?tag=%E7%83%AD%E9%97%A8&amp;from=gaia</a><br>电影简介： 证券公司基金管理人石宇（孔侑 饰）光鲜精干，却也是个重利轻义之徒。妻子为此与之决裂，女儿秀安（金秀安 饰）则对如此自私的父亲越来越失望，决定前往釜山和母亲生活。在秀安生日这天，石宇抽出时间陪伴女儿登上开往釜山的特快列车。而与此同时，城市四处出现了极为可疑的暴动事件。政府极力洗白无法掩盖丧尸肆虐的事实，即便懵然无知的列车乘客也因为不速之客的到来而堕入恐慌绝望的地狱中。开车的刹那，一名感染者冲入车厢，而她很快尸变并对目光所及之处的健康人展开血腥屠杀。未过多久，丧尸便呈几何数爆发性地增长。石宇被迫和幸存者的乘客们在逼仄的空间中奋力求生。<br>通往釜山的遥遥旅途布满杀机，危难时刻每个幸存者的人性也承受巨大的考验……<br>—–热评:——<br>最新热评:一切灾难皆人性，唉，最后那一枪要是开了，就是神作了。<br>—–热评:——<br>最新热评:套路很深，煽情很猛！据说这部电影耗资100亿韩元，其中90亿用于几百名群演的霹雳舞教学费用。哦，对了，还要唱好歌，关键时候保命就靠他了。<br>—–热评:——<br>最新热评:僵尸进攻的部分比较过瘾，火车拖着一尾巴僵尸的部分视觉效果很有趣；人文部分十分韩剧，社会讽刺过于直接而显得无趣了，男主那洗衣液CF般的闪回、洗手间哭泣都太cheesy，其实马东锡才是英雄，只是被塑造得不壮烈罢了；镜头感、节奏感so so，演员们演得不够害怕，有的部分特别明显。拜托，是僵尸也！<br>—–热评:——<br>最新热评:比预想的好，《僵尸世界大战》的僵尸模式，虽然不可避免的出现了很多套路与恶意煽情的东西，但是，惊悚的氛围把握还是挺准确的<br>—————————————-长评:—————————————-<br>长评: 我记得好久以前，在我上次回国以前吧，悉尼的电影行业某朋友跟我提过她的老板投了一个韩国僵尸片，我当时就觉得投这个干嘛啦韩国拍的僵尸片必须没什么好看的嘛，毕竟“僵尸片是欧美的类型片”这个印象已经根深蒂固了。<br>后来《釜山行》出来，被各种好评，我挺惊讶。前两天看了个微博Po的推荐终于忍不住，今天约了朋友去看掉了。看完以后到现在三个小时了，我还感觉闷闷的，一面觉得“真好看呀”一面为我们中国电影被韩国电影抛在后面的、越来越遥远的距离感到焦虑。<br>《釜山行》就是一个典型的僵尸片，和我们看过的所有僵尸电影拥有完全一样的套路，有封闭空间，有感染有逃命，有对抗有小聪明，有煽情有生死，这里有的《行尸走肉》呀《僵尸肖恩》啊它们都有过。但是《釜山行》是真正意义上的属于亚洲的僵尸片，它充满了身为亚洲人会各种共鸣而欧美人绝对想不到用的元素与梗：亚洲社会独一份儿的伦理道德、人情世故、因果报应……全都被调进了故事里。<br>看一个僵尸片到最后不止被圆满地吓了一圈，还感动得五体投地，哭得稀里哗啦。我好几次以为自己扛过了哭点，没想到最后还是败给了一段父女的对话。眼泪止也止不住。<br>这个片子在你以为充满希望的时候突然就绝望了，又在你终于绝望以后留了一点希望。<br>剧本是工工整整的好莱坞商业大片的模式，第几分钟出现几个事件几个转折几个主要角色几对人物关系—-全部是教科书的模版，以最快速度发展故事，让每一分钟的情节都饱满生动（用饺子比喻的话就是塞满了肉馅），丝毫不用一点闲话家常来浪费镜头时间。<br>知道如何利用一个满是缺点的主角的成长与改变让观众代入角色（少年漫画的套路），知道怎么运用人气角色的命运来影响观众情绪，知道留一个情节上的“关键道具”（儿歌）并在正确的位置使用了三次……两个小时里十几个人物全部立住了，观众能清晰地分辨他们记住他们并对他们拥有不同的解读—-就人设这一点，多成功啊。从好莱坞学到的，已经完全变成自己的了。</p>
<p>几年前上学的时候，我的澳洲电影老师专门开了一节课讲韩国电影的崛起与风格，讲朴赞郁讲《老男孩》，当年让我一个对“韩国电影”四个字充满鄙视的无知少女差点跪着出了教室。我那时候觉得中韩两国电影的差距至少有10年那么多吧。<br>如今，这些年过去，我隐约觉得中国电影多少也有了一丢丢进步，结果看完《釜山行》，人家他妈的又一下子甩开了我们十多年。</p>
<p>怎么追啊。继续追吧。心累累的，哎。</p>
<p>——————NO–6——————–</p>
<p>电影名字: 我们这种叛徒 6.3<br>电影链接: <a href="https://movie.douban.com/subject/10461676/?tag=%E7%83%AD%E9%97%A8&amp;from=gaia" target="_blank" rel="external">https://movie.douban.com/subject/10461676/?tag=%E7%83%AD%E9%97%A8&amp;from=gaia</a><br>电影简介： 牛津大学导师佩里和女友嘉儿在怡人的安提瓜岛上享受美妙的假期时，偶然结识了俄国富豪迪马——一场精彩的网球比赛让佩里和迪马的人生轨迹有了交集。谁料，迪马竟是俄国犯罪组织的洗钱专家，组织内部斗争的残酷令迪马萌生去意，于是他希望通过佩里向英国情报部门传达寻求政治庇护的请求……<br>自此，佩里和嘉儿渐渐脱离了正常的生活轨道，一系列政治阴谋、间谍行动扑面而来，就此开启了一场惊心动魄的跨国逃亡之旅：从法国巴黎到瑞士阿尔卑斯山，再到伦敦城里黑暗的走廊，哪里才是安全港湾？谁才是真正的叛徒？<br>—–热评:——<br>最新热评:点解会拣你？因为当时没有其他人啊。没得拣的情况下可以得到的最好结果。伊万最近几年都不行。<br>—–热评:——<br>最新热评:一万同志从角色设定到演技都毫无吸引力啊，四哥她爹演技还是有功底的（里面这女儿真是坑爹没商量），全部注意力都被Brody的fashion show吸引去了，玳瑁镜、围巾、风衣、三件套、居家服简直英国范儿到不行。剧情一般般啦，勒卡雷叔叔的水平应该不是这个level的吧……<br>—–热评:——<br>最新热评:比老婆收入低形象倒是挺符合，但是真的不适合长发。剧情没兴趣看。<br>—–热评:——<br>最新热评:3.5/5 摄影大加分！想金盆洗手奈何身不由己。Dima人物塑造得不错。<br><strong>抓取长评失败</strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/20/163和qq邮箱的自动登录--selenium【python】/" itemprop="url">
                  163和qq邮箱的自动登录--selenium【python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-09-20T10:20:28+08:00" content="2016-09-20">
              2016-09-20
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介：-之前直接测试mail-q63-com-以及-mail-qq-com的selenium登录都受阻，网站采用了较强的反爬技术，如动态id等，故用规避方法登陆"><a href="#简介：-之前直接测试mail-q63-com-以及-mail-qq-com的selenium登录都受阻，网站采用了较强的反爬技术，如动态id等，故用规避方法登陆" class="headerlink" title="简介： 之前直接测试mail.q63.com 以及 mail.qq.com的selenium登录都受阻，网站采用了较强的反爬技术，如动态id等，故用规避方法登陆"></a>简介： 之前直接测试mail.q63.com 以及 mail.qq.com的selenium登录都受阻，网站采用了较强的反爬技术，如动态id等，故用规避方法登陆</h1><p>1、在参考他文的基础上，做了代码重构。QQ邮箱在右上角有“基本版”登录，没有做加强反爬处理，而163的，则是通过www.163.com去找邮箱，发现接口是email.163.com，注意多了一个字母e，是较早的登录接口。</p>
<p>2、代码(请把你的帐号密码代替xxxx)，增加了自动判断输入是否正确：</p>
<pre><code># coding:utf-8
# python 3.5.2
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
import selenium.webdriver.support.ui as ui
import time

# 选择QQ还是163邮箱
email_type = input(&quot;1-QQ免费邮箱\n2-163免费邮箱\n请输入对应数字：&quot;)

def run():
    global email_type
    if email_type != str(1) or email_type != str(2):
        print (&quot;输入错误，请重新输入 :)&quot;)
        email_type = input(&quot;1-QQ免费邮箱\n2-163免费邮箱\n请输入对应数字：&quot;)

    if email_type == str(1):
        url = &quot;https://ui.ptlogin2.qq.com/cgi-bin/login?style=9&amp;appid=522005705&amp;daid=4&amp;s_url=https%3A%2F%2Fw.mail.qq.com%2Fcgi-bin%2Flogin%3Fvt%3Dpassport%26vm%3Dwsk%26delegate_url%3D%26f%3Dxhtml%26target%3D&amp;hln_css=http%3A%2F%2Fmail.qq.com%2Fzh_CN%2Fhtmledition%2Fimages%2Flogo%2Fqqmail%2Fqqmail_logo_default_200h.png&amp;low_login=1&amp;hln_autologin=%E8%AE%B0%E4%BD%8F%E7%99%BB%E5%BD%95%E7%8A%B6%E6%80%81&amp;pt_no_onekey=1&quot;
        driver = webdriver.Firefox()
        driver.get(url)
        time.sleep(2)
        driver.find_element_by_xpath(&quot;/html/body/div[1]/div[2]/div[4]/ul/li[1]/input&quot;).send_keys(&quot;xxxx&quot;)
        driver.find_element_by_xpath(&quot;/html/body/div[1]/div[2]/div[4]/ul/li[2]/input&quot;).send_keys(&quot;xxxx&quot;)
        driver.find_element_by_xpath(&quot;//html/body/div[1]/div[2]/div[4]/div[2]&quot;).click()
        print(&apos;--------------Log In------------&apos;)
        time.sleep(1)


    elif email_type == str(2):
        url = &quot;http://email.163.com/&quot;

        driver = webdriver.Firefox()
        driver.get(url)
        time.sleep(2)
        driver.find_element_by_xpath(&quot;/html/body/div[1]/div[1]/div/div[2]/div[2]/div/form/div[1]/label&quot;).send_keys(&quot;xxxx&quot;)
        driver.find_element_by_xpath(&quot;/html/body/div[1]/div[1]/div/div[2]/div[2]/div/form/div[2]/label&quot;).send_keys(&quot;xxxx&quot;)
        driver.find_element_by_xpath(&quot;/html/body/div[1]/div[1]/div/div[2]/div[2]/div/form/div[2]/button&quot;).click()
        print(&apos;--------------Log In------------&apos;)
        time.sleep(1)


run()
</code></pre><p>3、pycharm输出：</p>
<p>1-QQ免费邮箱<br>2-163免费邮箱<br>请输入对应数字：4<br>输入错误，请重新输入 :)<br>1-QQ免费邮箱<br>2-163免费邮箱<br>请输入对应数字：2<br>————–Log In————</p>
<p>Process finished with exit code 0</p>
<p>4、参考：</p>
<p>  <a href="http://www.jianshu.com/p/a78b6bb95543" target="_blank" rel="external">【伪】解决动态id元素Selenium无法捕捉自动登录问题</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Van" />
          <p class="site-author-name" itemprop="name">Van</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">59</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          

          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Van</span>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  




  
  

  

  

  

</body>
</html>
