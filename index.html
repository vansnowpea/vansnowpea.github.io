<!doctype html>



  


<html class="theme-next muse use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta property="og:type" content="website">
<meta property="og:title" content="A Song of Python and Anaconda">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="A Song of Python and Anaconda">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Song of Python and Anaconda">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: 'Author'
    }
  };
</script>




  <link rel="canonical" href="http://yoursite.com/"/>

  <title> A Song of Python and Anaconda </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">A Song of Python and Anaconda</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archiv
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/08/数据分析的参考书集锦/" itemprop="url">
                  数据分析的参考书集锦【Python】+【R】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-08T20:59:28+08:00" content="2016-10-08">
              2016-10-08
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="数据分析的参考书集锦，先保存过来，省的一不小心丢了。"><a href="#数据分析的参考书集锦，先保存过来，省的一不小心丢了。" class="headerlink" title="数据分析的参考书集锦，先保存过来，省的一不小心丢了。"></a>数据分析的参考书集锦，先保存过来，省的一不小心丢了。</h1><p>原文： <a href="http://bbs.pinggu.org/thread-3116701-1-1.html" target="_blank" rel="external">http://bbs.pinggu.org/thread-3116701-1-1.html</a></p>
<p>入门读物：</p>
<p>深入浅出数据分析 这书挺简单的，基本的内容都涉及了，说得也比较清楚，最后谈到了 R 是大加分。难易程度：非常易。<br>啤酒与尿布 通过案例来说事情，而且是最经典的例子。难易程度：非常易。<br>数据之美 一本介绍性的书籍，每章都解决一个具体的问题，甚至还有代码，对理解数据分析的应用领域和做法非常有帮助。难易程度：易。<br>数学之美 这本书非常棒啦，入门读起来很不错！<br>      下载地址：深入浅出数据分析、啤酒与尿布、数据之美、数学之美。</p>
<p>数据分析：</p>
<p>SciPy and NumPy 这本书可以归类为数据分析书吧，因为 numpy 和 scipy 真的是非常强大啊。<br>Python for Data Analysis 作者是 Pandas 包的作者，看过他在 Scipy 会议上的演讲，实例非常强！<br>Bad Data Handbook 很好玩的书，作者的角度很不同。<br>       下载地址：SciPy and NumPy、Python for Data Analysis、Bad Data Handbook<br>适合入门的教程：</p>
<p>集体智慧编程 学习数据分析、数据挖掘、机器学习人员应该仔细阅读的第一本书。作者通过实际例子介绍了机器学习和数据挖掘中的算法，浅显易懂，还有可执行的 Python 代码。难易程度：中。<br>Machine Learning in Action 用人话把复杂难懂的机器学习算法解释清楚了，其中有零星的数学公式，但是是以解释清楚为目的的。而且有 Python 代码，大赞！目前中科院的王斌老师（微博： 王斌_ICTIR）已经翻译这本书了 机器学习实战 。这本书本身质量就很高，王老师的翻译质量也很高。难易程度：中。我带的研究生入门必看数目之一！<br>Building Machine Learning Systems with Python 虽然是英文的，但是由于写得很简单，比较理解，又有 Python 代码跟着，辅助理解。<br>数据挖掘导论 最近几年数据挖掘教材中比较好的一本书，被美国诸多大学的数据挖掘课作为教材，没有推荐 Jiawei Han 老师的那本书，因为个人觉得那本书对于初学者来说不太容易读懂。难易程度：中上。<br>Machine Learning for Hackers 也是通过实例讲解机器学习算法，用 R 实现的，可以一边学习机器学习一边学习 R。<br>       下载地址：集体智慧编程+源代码、Machine Learning in Action、Building Machine Learning Systems with Python、                            数据挖掘导论、Machine Learning for Hackers</p>
<p>稍微专业些的：</p>
<p>Introduction to Semi-Supervised Learning 半监督学习必读必看的书。<br>Learning to Rank for Information Retrieval 微软亚院刘铁岩老师关于 LTR 的著作，啥都不说了，推荐！<br>Learning to Rank for Information Retrieval and Natural Language Processing 李航老师关于 LTR 的书，也是当时他在微软亚院时候的书，可见微软亚院对 LTR 的研究之深，贡献之大。<br>推荐系统实践 这本书不用说了，研究推荐系统必须要读的书，而且是第一本要读的书。<br>Graphical Models, Exponential Families, and Variational Inference 这个是 Jordan 老爷子和他的得意门徒 Martin J Wainwright 在 Foundation of Machine Learning Research 上的创刊号，可以免费下载，比较难懂，但是一旦读通了，graphical model 的相关内容就可以踏平了。<br>Natural Language Processing with Python NLP 经典，其实主要是讲 NLTK 这个包，但是啊，NLTK 这个包几乎涵盖了 NLP 的很多内容了啊！<br>   下载地址：Introduction to Semi-Supervised Learning、Learning to Rank for Information Retrieval、                           Learning to Rank for Information Retrieval and Natural Language Proces、推荐系统实践</p>
<p>机器学习教材：<br>The Elements of Statistical Learning 这本书有对应的中文版：统计学习基础 。书中配有 R 包，非常赞！可以参照着代码学习算法。<br>统计学习方法 李航老师的扛鼎之作，强烈推荐。难易程度：难。<br>Machine Learning 去年出版的新书，作者 Kevin Murrphy 教授是机器学习领域中年少有为的代表。这书是他的集大成之作，写完之后，就去 Google 了，产学研结合，没有比这个更好的了。<br>Machine Learning 这书和上面的书不是一本！这书叫：Machine Learning: An Algorithmic Perspective 之前做过我带的研究生教材，由于配有代码，所以理解起来比较容易。<br>Pattern Recognition And Machine Learning 经典中的经典。<br>Bayesian Reasoning and Machine Learning 看名字就知道了，彻彻底底的 Bayesian 学派的书，里面的内容非常多，有一张图将机器学习中设计算法的关系总结了一下，很棒。<br>Probabilistic Graphical Models 鸿篇巨制，这书谁要是读完了告诉我一声。<br>Convex Optimization 凸优化中最好的教材，没有之一了。课程也非常棒，Stephen 老师拿着纸一步一步推到，图一点一点画，太棒了。<br>下载地址：The Elements of Statistical Learning、统计学习方法、Machine Learning: An Algorithmic Perspective、<br>                            Pattern Recognition and Machine Learning+答案、Bayesian Reasoning and Machine Learning、                                                   Probabilistic Graphical Models、Convexity and Optimization</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/07/下载最新电影的爬虫/" itemprop="url">
                  下载最新电影的爬虫---Xpath读取文本，链接，标题等的操作【Python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-07T23:59:28+08:00" content="2016-10-07">
              2016-10-07
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="下载最新电影的爬虫"><a href="#下载最新电影的爬虫" class="headerlink" title="下载最新电影的爬虫"></a>下载最新电影的爬虫</h1><p>1、使用：</p>
<ul>
<li>lxml.etree</li>
<li>requests</li>
</ul>
<p>2、代码：</p>
<pre><code># -*- coding:utf-8 -*-
import requests
from lxml import etree


url = &apos;http://www.ygdy8.net/html/gndy/dyzz/index.html&apos;  #这是电影最新电影的网站
# r = requests.get(url).content
# print(r.encoding）
# &gt;&gt;&gt; ISO-8859-1
html = requests.get(url).content
# html = requests.get(url).content.decode(&apos;ISO-8859-1&apos;).encode(&apos;utf-8&apos;)

selector = etree.HTML(html)

# //*[@id=&quot;content&quot;]/div/div[1]/ol/li[1]/div/div[2]/div[2]/p[1]
# get rid of the : /tbody
biaoti = selector.xpath(&apos;//*[@id=&quot;header&quot;]/div/div[3]/div[3]/div[2]/div[2]/div[2]/ul//tr[2]/td[2]/b/a/text()&apos;)


# get rid of the : /tbody
jianjie = selector.xpath(&apos;/html/body/div/div/div[3]/div[3]/div[2]/div[2]/div[2]/ul//tr[4]/td/text()&apos;)
wangzhi = selector.xpath(&apos;//*[@id=&quot;header&quot;]/div/div[3]/div[3]/div[2]/div[2]/div[2]/ul//tr[2]/td[2]/b/a/@href&apos;)

for b,j,k in zip(biaoti,jianjie,wangzhi):
    print(b+&apos;\n&apos;+j+&apos;\n&apos;+&apos;www.ygdy8.net&apos;+k+&apos;\n&apos;)
</code></pre><p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-08/015240484.png" alt="">    </p>
<p>3、分析：主要和上一篇的接近，但是这一篇还有读取网址等操作，注意格式上和读取内容text有差别的。<br>总结如下：</p>
<pre><code>获取到标签后我们可以获取标签中的属性值
tree.xpath(&quot;//div[@class=&apos;sec_blk mrg_b_30&apos;]/ul/li[1]/a/text()&quot;)     #获取a的文本，li标号是从1开始，而不是从0开始
tree.xpath(&quot;//div[@class=&apos;sec_blk mrg_b_30&apos;]/ul/li[1]/a/@href&quot;)   #获取a的链接地址

当然还有其他类似的xpath例子：
&quot;//input[@id=&apos;city&apos;]/@value&quot;
&quot;//div[@class=&apos;venueDetal&apos;]/p/img[@class=&apos;img&apos;]/@src&quot;
&quot;//div[@class=&apos;detail_info_title&apos;]//a[@class=&apos;hotel_star&apos;]/@title&quot;
</code></pre><p>4、参考： <a href="http://blog.chinaunix.net/uid-13869856-id-5747494.html" target="_blank" rel="external">python+lxml xpath获取数据 </a></p>
<p>5、可补充点： 自动提取直接下载链接，看是否能导入到迅雷等工具。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/07/东方财富网cpi数据的抓取/" itemprop="url">
                  东方财富网cpi数据的抓取【Python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-07T22:59:28+08:00" content="2016-10-07">
              2016-10-07
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="东方财富网cpi数据的抓取"><a href="#东方财富网cpi数据的抓取" class="headerlink" title="东方财富网cpi数据的抓取"></a>东方财富网cpi数据的抓取</h1><p>1、使用：</p>
<ul>
<li>lxml.etree</li>
<li>requests</li>
</ul>
<p>2、代码：</p>
<pre><code>from lxml import etree
import requests

url = &apos;http://data.eastmoney.com/cjsj/cpi.html&apos;
content = requests.get(url).content

html = etree.HTML(content)
content1 = html.xpath(&apos;//*[@id=&quot;tb&quot;]/tr[3]/td[2]/text()&apos;)

print(content1[0].strip().replace(&apos;\n\r&apos;, &apos;&apos;))

# for txt in html.iterfind(&apos;.//*[@id=&quot;tb&quot;]/tr[3]/td&apos;):
#     print(txt.text)
</code></pre><p>3、分析：requests+lxml来分析和提取数据比较简单，可以尽可能的规避使用RE的复杂性以及可能产生的编码问题。要注意的是提取文本内容的时候要在xpath地址后面加上/text()<br>不过这个案例中，需要把xpath的/tbody去掉，这是因为有的浏览器加上去的，否则不能识别需要的文字部分。<br>另外，默认的结果因为有很多的空格和\n\r，所以需要做数据清洗，就本例，加一句content1[0].strip().replace(‘\n\r’, ‘’)即可。</p>
<p>4、没有执行的代码，表示读取2016年08月份 “全国”，“城市”，“农村”各自的cpi数据。<br>要注意的是：这属于ElementPath，一共4个种类，分别如下：</p>
<ul>
<li></li>
</ul>
<ol>
<li>iterfind()</li>
<li>findall()</li>
<li>find()</li>
<li>findtext()</li>
</ol>
<p>千万注意的是：ElementPath不能直接使用绝对路径，需要在前面加一个.符号。暂时感觉这个使用的不太多。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/05/tensorflow 初步学习/" itemprop="url">
                  begin to learn TensorFlow
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-05T16:20:28+08:00" content="2016-10-05">
              2016-10-05
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-05/163346079.png" alt=""></p>
<h1 id="Introduction-begin-to-learn-Machine-Learning-and-find-Google’s-open-source-technology-TensorFlow"><a href="#Introduction-begin-to-learn-Machine-Learning-and-find-Google’s-open-source-technology-TensorFlow" class="headerlink" title="Introduction: begin to learn Machine Learning, and find Google’s open source technology: TensorFlow."></a>Introduction: begin to learn Machine Learning, and find Google’s open source technology: TensorFlow.</h1><p>1、It seems TF only support Linux by official , but I try to install also on Win 10, so try :： <a href="http://wiki.jikexueyuan.com/project/tensorflow-zh/" target="_blank" rel="external">http://wiki.jikexueyuan.com/project/tensorflow-zh/</a>：<br>though some guy reported successed on win, but I failed as can not download the big file no matter with USA IP, anyway , I record the method.</p>
<pre><code>捣鼓好了windows docker安装，参考了楼上的许多信息。
1. 安装docker
2. 点开Docker Quickstart Terminal， 打开成功后：
    docker is configured to use the default machine with IP 192.168.99.100
3. 安装tensorflow： docker run -d -p 8888:8888 -v /notebook:/notebook xblaster/tensorflow-jupyter
4. 运行tensorflow-jupyter: docker run xblaster/tensorflow-jupyter
     会提示running at: http://0.0.0.0:8888，不知道为什么会是这个IP地址，用浏览器打开不了。然后替换成docker打开时的IP，http://192.168.99.100:8888就可以打开了。
5. 运行example code，mnist参考资料：1, tensorflow官方文档；2，http://blog.csdn.net/yhl_leo/article/details/50614444 及其mnist的github：https://github.com/yhlleo/mnist，github中有input_data.py这个很重要的文件。
</code></pre><p>2、 I run it on Ubuntu and test an easy exmaple which is :</p>
<pre><code>y =0.1*x +0.3
</code></pre><p>and after 200 times of calculating , get result :</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-05/235616627.png" alt=""> </p>
<p>from the result : after 40 times calculating , the result closes to 0.1*x + 0.3 already , no matter how AlphaGo is so strong.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/02/numpy和pandas的初步学习/" itemprop="url">
                  numpy和pandas的初步学习以及6本数据分析必读书和2份英文教程
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-02T14:20:28+08:00" content="2016-10-02">
              2016-10-02
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-02/235644734.png" alt=""></p>
<h1 id="简介：-今天把cmder的配色研究下，找了个nice的shell版，赞一个，另外，英文是绕不过去的，最后总会发现想要的资料只有英文的。-：）"><a href="#简介：-今天把cmder的配色研究下，找了个nice的shell版，赞一个，另外，英文是绕不过去的，最后总会发现想要的资料只有英文的。-：）" class="headerlink" title="简介： 今天把cmder的配色研究下，找了个nice的shell版，赞一个，另外，英文是绕不过去的，最后总会发现想要的资料只有英文的。 ：）"></a>简介： 今天把cmder的配色研究下，找了个nice的shell版，赞一个，另外，英文是绕不过去的，最后总会发现想要的资料只有英文的。 ：）</h1><p>1、这几天抽空看了下《利用python进行数据分析》的几个章节，其中pandas部分看了2遍，熟悉了一些命令和用法，</p>
<p>2、国外一个朋友的对某个问题的建议是使用JS， 首先我是按照这个网页的心得：不过我找了一本JS的入门书，发现内容不是兴趣所在，所以暂时先记录之。</p>
<p><a href="http://kb.cnblogs.com/page/191787/" target="_blank" rel="external">http://kb.cnblogs.com/page/191787/</a></p>
<p>3、另搜资料的时候，找了一个国外的网址，介绍了数据分析几本不错的书，<br><a href="https://www.analyticsvidhya.com/blog/2014/06/books-data-scientists-or-aspiring-ones/" target="_blank" rel="external"><br>Must have books for data scientists (or aspiring ones)</a></p>
<p>4、在上述链接中，是6本书的英文介绍，貌似R的数量更多，并且有一本是R的，但有第三方给出了Python代码，（注意有的文字因粘贴丢失了超链接）：</p>
<pre><code>1. R Cookbook by Paul Teetor

This is simply the best book to start your journey with R. It contains tons of examples and practical advice on a wide range of topics like file input / output, data manipulations, merging and sorting to building a regression model. For a starter in R, this book becomes your best pal during the initial testing time.

While the book is aimed towards starters, it still remains a prominent feature of the library of any data scientist.



2. Machine Learning for Hackers by Drew Conway &amp; John Myles White

I think this book actually has a wrong title. I dropped purchasing it twice before giving it a shot (which happened only because of a recommendation from a close friend). This book is meant for data scientists and not hackers. I don’t know why the title says so. A very practical manual for learning machine learning, it comes with good visuals and you can get a copy of codes in Python (original book is based on R).



3. R graphics cookbook by Winston Chang

You can’t be a good data scientist unless you master the graphics in R! There is no better way for visualization, but to learn ggplot2. Sadly, learning ggplot2 might seem like learning a completely new language in itself. This is where this “cookbook” comes to rescue. The recipes from Winston are short, sweet and to the point. Buy this and it is bound to end up as one of the most referred book in your library.



4. Programming Collective Intelligence by Toby Segaran (popularly referred as PCI)

If there is one book you want to choose, out of this selection (for learning machine learning) – it is this one. I haven’t met a data scientist yet who has read this book and does not recommend to keep it on your bookshelf. A lot of them have re-read this book multiple times. The book was written long before data science and machine learning acquired the cult status they have today – but the topics and chapters are entirely relevant even today! Some of the topics covered in the book are collaborative filtering techniques, search engine features, Bayesian filtering and Support vector machines. If you don’t have a copy of this book – order it as soon as you finish reading this article! The book uses Python to deliver machine learning in a fascinating manner.



5. Python for Data Analysis by Wes McKinney

Written by Wes McKinney, this book teaches you everything you need about Pandas. For the starters (not sure why you are still reading this article), pandas are Python’s way to handle data structures. Except for the title of the book (which I find misleading), I like everything else about this book. It contains ample codes and examples to leave you capable of performing any operation / transformation on a dataframe in Python (using pandas).

For the advanced users, if you already know pandas, you should look at this presentation from Wes on what are the shortcomings of pandas.



6. Agile data science by Russell Jurney

A recent addition by O’Reilly, this book looks like a must read for data scientists. The focus is on using “light” tools, which are easy to use and still get the work done. This is currently on my reading list and I’ll update more details once I have read it.



These are the 6 must have books, if you are serious about being a data scientist. There are a couple of additional Python books, which you can consider – Natural Language processing with Python by Steven Bird et al and Mining the social web by Matthew A. Russell. The reason I have not kept them in the list is because you can find a lot of the information in these books easily on the web.
</code></pre><p>5、另外，还有2篇不错的英文的基于python-pandas的数据分析教程：</p>
<p><a href="https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/" target="_blank" rel="external">A Complete Tutorial to Learn Data Science with Python from Scratch</a></p>
<p>以及这个：</p>
<p><a href="https://www.analyticsvidhya.com/blog/2014/09/data-munging-python-using-pandas-baby-steps-python/" target="_blank" rel="external">Data Munging in Python (using Pandas) – Baby steps in Python</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/27/收到《Python for data analysis》作者的邮件回复/" itemprop="url">
                  收到《Python for data analysis》作者的邮件回复
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-09-27T14:20:28+08:00" content="2016-09-27">
              2016-09-27
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-27/150628293.jpg" alt=""></p>
<h1 id="简介：-收到《Python-for-data-analysis》作者的邮件回复-：）"><a href="#简介：-收到《Python-for-data-analysis》作者的邮件回复-：）" class="headerlink" title="简介： 收到《Python for data analysis》作者的邮件回复 ：）"></a>简介： 收到《Python for data analysis》作者的邮件回复 ：）</h1><p>1、上次给他写了一个邮件，建议用Anaconda来写下一版本，虽然过了几天还是收到了回复，看样子他也意识到Anaconda更好点，也表示第二版会采用：</p>
<pre><code>try

from matplotlib.pyplot import *

and running

%matplotlib

I am creating a 2nd edition of the book, and it will use Anaconda
instead of Canopy in the instructions.

Thanks!
</code></pre><p>2、然后我去Python中文社区问了几个人，表示有兴趣翻译，由于第一版是机械工业出版社搞的中译版，发了一个email咨询是否将来打算出第二版的中译，但是还没得到回复，想了下，如果他们不翻译，就召集社区的小伙伴们来翻译吧。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/27/matplotlib中文显示乱码的解决办法/" itemprop="url">
                  matplotlib中文显示乱码的解决办法
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-09-27T13:20:28+08:00" content="2016-09-27">
              2016-09-27
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介：-matplotlib中文显示乱码的解决办法-：）"><a href="#简介：-matplotlib中文显示乱码的解决办法-：）" class="headerlink" title="简介： matplotlib中文显示乱码的解决办法 ：）"></a>简介： matplotlib中文显示乱码的解决办法 ：）</h1><p>1、在源代码开头加入以下几行：</p>
<pre><code>from pylab import *
mpl.rcParams[&apos;font.sans-serif&apos;] = [&apos;SimHei&apos;] #指定默认字体

mpl.rcParams[&apos;axes.unicode_minus&apos;] = False #解决保存图像是负号&apos;-&apos;显示为方块的问题
</code></pre><p>2、上述就针对单个py文件，如果想全部的，可以这么操作：</p>
<ul>
<li>\Lib\site-packages\matplotlib\mpl-data\matplotlibrc    用任意文本编辑器打开。（最好先备份一下）<br>找到第129行：#font.family， 将其注释去掉，冒号后面的值改为Microsoft YaHei</li>
<li>找到第141行：#font.sans-serif， 将其注释去掉，并将Microsoft YaHei添加到冒号后面的最前面，注意还要再加一个英文逗号（,）</li>
<li>并设置axes.unicode_minus = False #解决保存图像是负号’-‘显示为方块的问题</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/25/《利用Python进行数据分析》如何把kindle的电子书转成pdf的教程/" itemprop="url">
                  如何把kindle的电子书转成word等格式的教程
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-09-25T23:20:28+08:00" content="2016-09-25">
              2016-09-25
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介：-如何把kindle的电子书转成word等格式的教程-：）"><a href="#简介：-如何把kindle的电子书转成word等格式的教程-：）" class="headerlink" title="简介： 如何把kindle的电子书转成word等格式的教程 ：）"></a>简介： 如何把kindle的电子书转成word等格式的教程 ：）</h1><p>1、参考知乎的步骤， <a href="http://www.zhihu.com/question/38451995" target="_blank" rel="external">http://www.zhihu.com/question/38451995</a></p>
<p>2、下载去除DRM的破解版本，不然只能破解3本书，参考此网址： <a href="http://www.d9soft.com/soft/102882.htm" target="_blank" rel="external">http://www.d9soft.com/soft/102882.htm</a></p>
<p>3、使用该网站，进行pdf转换： <a href="http://www.epubconverter.com/azw-to-pdf-converter/" target="_blank" rel="external">http://www.epubconverter.com/azw-to-pdf-converter/</a></p>
<p>4、成功把《利用Python进行数据分析》转成了pdf，当然我事先花销了巨额的0.1元注册了一个Kindle Unlimited  帐号</p>
<p>5、为了方便复制书中的代码实例，继续用calibre 软件进行转换成docx格式，不用对着那些网上的扫描版，或者纸质书，坑爹的挨个自己输入命令了有木有， </p>
<p>6、示范图： </p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-26/001138836.png" alt=""></p>
<p>7、我已经为偷懒的你，上传了本书，可以直接下载word版本啦。请点击<a href="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-26/001313882.docx" target="_blank" rel="external">【下载点我】</a></p>
<p>8、记得重命名，方便以后查找。</p>
<p>9、第八章spx指数的举例，代码我修正到pycharm里：</p>
<pre><code>import matplotlib.pyplot as plt
from datetime import datetime
import pandas as pd
fig = plt.figure()
ax = fig.add_subplot(1, 1, 1)
data = pd.read_csv(&apos;D:\mine\pydata-book-master\ch08/spx.csv&apos;, index_col=0, parse_dates=True)
spx = data[&apos;SPX&apos;]
spx.plot(ax=ax, style=&apos;k-&apos;)
crisis_data = [      (datetime(2007, 10, 11), &apos;Peak of bull market&apos;),      (datetime(2008, 3, 12), &apos;Bear Stearns Fails&apos;),      (datetime(2008, 9, 15), &apos;Lehman Bankruptcy&apos;) ]
for date, label in crisis_data:
    ax.annotate(label, xy=(date, spx.asof(date) + 50),                 xytext=(date, spx.asof(date) + 200),                 arrowprops=dict(facecolor=&apos;black&apos;),                 horizontalalignment=&apos;left&apos;, verticalalignment=&apos;top&apos;)
# 放大到2007-2010
    ax.set_xlim([&apos;1/1/2007&apos;, &apos;1/1/2011&apos;])
    ax.set_ylim([600, 1800])
    ax.set_title(&apos;Important dates in 2008-2009 financial crisis&apos;)

plt.show()
</code></pre><p>结果图，有木有一点专业的味道？<br> <img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-26/105503895.png" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/23/数值分析和一个bug解决记录/" itemprop="url">
                  数值分析和一个bug解决记录【python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-09-23T23:20:28+08:00" content="2016-09-23">
              2016-09-23
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介：-数值分析和一个bug解决记录-：）"><a href="#简介：-数值分析和一个bug解决记录-：）" class="headerlink" title="简介： 数值分析和一个bug解决记录 ：）"></a>简介： 数值分析和一个bug解决记录 ：）</h1><p>1、这个bug是在使用python3.5.2的时候发生的，由于同时安装anaconda  有时候因为一些测试python2的代码 也安装卸载 最终出现了： Fatal error in launcher: Unable to create process using ‘“‘</p>
<p>2、解决方案，控制面板卸载后，再到python3 的安装路径把文件夹都删除，此时，保留anaconda版本，在cmder输入ipython就可以正常运行了。</p>
<p>3、说到数值分析，感觉还是要先阅读下相关书籍，虽然以前matlab接触过一些。首先看的就是评价还不错的《利用python进行数值分析》，但是发现了一个问题，所以马上给作者写了一个email如下图：</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-24/235703049.png" alt=""></p>
<p>4、</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/23/豆瓣电影TOP250的爬取和作图分析/" itemprop="url">
                  《利用Python进行数据分析》豆瓣电影TOP250的爬取和作图分析【python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-09-23T23:20:28+08:00" content="2016-09-23">
              2016-09-23
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介：-又回到豆瓣了，这是多适合爬虫的网站-：）"><a href="#简介：-又回到豆瓣了，这是多适合爬虫的网站-：）" class="headerlink" title="简介： 又回到豆瓣了，这是多适合爬虫的网站 ：）"></a>简介： 又回到豆瓣了，这是多适合爬虫的网站 ：）</h1><p>1、这次的对象是top 250 ， 网址：  <a href="https://movie.douban.com/top250" target="_blank" rel="external">https://movie.douban.com/top250</a> 目的是对这250部电影的分类做一个统计。</p>
<p>2、实际有其他人做了分析，正好看到，发现其代码比较漂亮，所以研读，顺便复习检阅自己学习成果。秉承一贯的作风，做一定的细节分析。先看下原文代码：</p>
<pre><code># -*- coding: utf-8 -*-
# !/usr/bin/env python

from lxml import etree
import requests
import pymysql
import matplotlib.pyplot as plt
from pylab import *
import numpy as np

# 连接mysql数据库
conn = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;, passwd = &apos;54545454&apos;, db = &apos;douban&apos;, charset = &apos;utf8&apos;)
cur = conn.cursor()
cur.execute(&apos;use douban&apos;)

def get_page(i):
    url = &apos;https://movie.douban.com/top250?start={}&amp;filter=&apos;.format(i)

    html = requests.get(url).content.decode(&apos;utf-8&apos;)

    selector = etree.HTML(html)
    # //*[@id=&quot;content&quot;]/div/div[1]/ol/li[1]/div/div[2]/div[2]/p[1]
    content = selector.xpath(&apos;//div[@class=&quot;info&quot;]/div[@class=&quot;bd&quot;]/p/text()&apos;)
    print(content)

    for i in content[1::2]:
        print(str(i).strip().replace(&apos;\n\r&apos;, &apos;&apos;))
        # print(str(i).split(&apos;/&apos;))
        i = str(i).split(&apos;/&apos;)
        i = i[len(i) - 1]
        # print(&apos;zhe&apos; +ｉ)
        # print(i.strip())
        # print(i.strip().split(&apos; &apos;))
        key = i.strip().replace(&apos;\n&apos;, &apos;&apos;).split(&apos; &apos;)
        print(key)
        for i in key:
            if i not in douban.keys():
                douban[i] = 1
            else:
                douban[i] += 1

def save_mysql():
    print(douban)
    for key in douban:
        print(key)
        print(douban[key])
        if key != &apos;&apos;:
            try:
                sql = &apos;insert douban(类别, 数量) value(&apos; + &quot;\&apos;&quot; + key + &quot;\&apos;,&quot; + &quot;\&apos;&quot; + str(douban[key]) + &quot;\&apos;&quot; + &apos;);&apos;
                cur.execute(sql)
                conn.commit()
            except:
                print(&apos;插入失败&apos;)
                conn.rollback()


def pylot_show():
    sql = &apos;select * from douban;&apos;
    cur.execute(sql)
    rows = cur.fetchall()
    count = []
    category = []

    for row in rows:
        count.append(int(row[2]))
        category.append(row[1])
    print(count)
    y_pos = np.arange(len(category))
    print(y_pos)
    print(category)
    colors = np.random.rand(len(count))
    plt.barh()
    plt.barh(y_pos, count, align=&apos;center&apos;, alpha=0.4)
    plt.yticks(y_pos, category)
    for count, y_pos in zip(count, y_pos):
        plt.text(count, y_pos, count,  horizontalalignment=&apos;center&apos;, verticalalignment=&apos;center&apos;, weight=&apos;bold&apos;)
    plt.ylim(+28.0, -1.0)
    plt.title(u&apos;豆瓣电影250&apos;)
    plt.ylabel(u&apos;电影分类&apos;)
    plt.subplots_adjust(bottom = 0.15)
    plt.xlabel(u&apos;分类出现次数&apos;)
    plt.savefig(&apos;douban.png&apos;)


if __name__ == &apos;__main__&apos;:
    douban = {}
    for i in range(0, 250, 25):
        get_page(i)
    save_mysql()
    pylot_show()
    cur.close()
    conn.close()
</code></pre><p>3、首先是他用了selector = etree.HTML(html)  而我用的比较多的是bs4，应该是殊途同归。他的xpath路径是：</p>
<pre><code>content = selector.xpath(&apos;//div[@class=&quot;info&quot;]/div[@class=&quot;bd&quot;]/p/text()&apos;) 
</code></pre><p>而我用的偷懒模式：直接浏览器找到的： </p>
<pre><code>selector.xpath(&apos;//*[@id=&quot;content&quot;]/div/div[1]/ol/li[1]/div/div[2]/div[2]/p[1]/text()&apos;)
</code></pre><p>注意，默认到P[1]的路径，因为是需要读取里面的文本部分，所以加入/text()</p>
<p>4、这样就得到了第一页的影视信息的文本，不过如果用ipthon分步操作查看， 那简直是逆天的格式，如图：</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-23/225057825.png" alt=""></p>
<p>5、必须进行文字提取处理了。 </p>
<p>首先，这一大坨的，为了简单，我们用单元测试的思想，先调试第一页第一个，这里之前已经设置从：</p>
<pre><code>url = &apos;https://movie.douban.com/top250?start={}&amp;filter=&apos;.format(i)
</code></pre><p>修改为：</p>
<pre><code>url = &apos;https://movie.douban.com/top250?start={1}&amp;filter=&apos;
</code></pre><p>同时，观察整个循环输出的格式是一个列表，每个元素是一个字符串，那么第一个电影的电影信息对应的字符串是：</p>
<pre><code>&apos;\n                            导演: 弗兰克·德拉邦特 Frank Darabont\xa0\xa0\xa0主演: 蒂姆·罗宾斯 Tim Robbins /...&apos;, &apos;\n                            1994\xa0/\xa0美国\xa0/\xa0犯罪 剧情\n                        &apos;
</code></pre><p>和原始网页的信息对照，实际就是第一部分包含导演主演信息，第二部分是年份国家和剧种， 就本文，我们需要的是第二部分的内容，也就是“1994 / 美国 / 犯罪 剧情”这部分内容。然后呢，因为整个content 包含了25部电影的文本， 这些都保存在列表里，并且我们需要进一步处理的，都在对应坐标1、3、5、、这样的奇数里。因为列表第一个是从0开始的。这就是第一个for循环的意义所在，用到了python的切片知识第二个冒号，表示从下表1的元素开始检索，并且隔开2个元素为下一次检索：</p>
<pre><code>for i in content[1::2]:
</code></pre><p>查看了循环内的第一句为，注意这只是print，没有运行具体的代码影响原来的字符串：</p>
<pre><code>print(str(i).strip().replace(&apos;\n\r&apos;, &apos;&apos;))
</code></pre><p>这句的意思就是得到整个content列表中，下标为1、3、5。。。。的元素，并通过strip（）来进行去掉首尾的多余的空格，,随后使用replace函数，把’\n\r’替换为空字符。我们可以在ipython中验证下：</p>
<p>记录：aa = conntent[1]：  </p>
<pre><code>aa =  &apos;\n                            1994\xa0/\xa0美国\xa0/\xa0犯罪 剧情\n                        &apos;
</code></pre><p>执行：aa.strip()，得到：</p>
<pre><code>In [19]: aa.strip()
Out[19]: &apos;1994\xa0/\xa0美国\xa0/\xa0犯罪 剧情&apos;

In [20]: aa.strip().replace(&apos;\n\r&apos;, &apos;&apos;)
Out[20]: &apos;1994\xa0/\xa0美国\xa0/\xa0犯罪 剧情&apos;
</code></pre><p>发现上述的replace函数似乎没起作用，那是这里正好没有’\n\r’，同时你可以发现，这里怎么有4个地方有\xa0 ？ 这是什么呢？ 原来是：转义字符，”\x”后接数字（两位）代表16进制数，这玩意牵涉编码的问题，打印的时候是一个空格。</p>
<p>然后循环里面的开始执行的命令都是为了去除\n和空格这些没有的东西，i = str(i).split(‘/‘)就是把去除空格和\n的字符串通过‘/’分隔在列表里。</p>
<pre><code>In [35]: aa =  &apos;\n                            1994\xa0/\xa0美国\xa0/\xa0犯罪 剧情\n                        &apos;

In [36]: aa = aa.split(&apos;/&apos;)

In [37]: aa = aa(len(aa)-1)
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-37-06f75198160a&gt; in &lt;module&gt;()
----&gt; 1 aa = aa(len(aa)-1)

TypeError: &apos;list&apos; object is not callable

In [38]: aa = aa[len(aa)-1]

In [39]: aa
Out[39]: &apos;\xa0犯罪 剧情\n
</code></pre><p>随后，通过</p>
<pre><code>In [40]: key = aa.strip().replace(&apos;\n&apos;, &apos;&apos;).split(&apos; &apos;)

In [41]: key
Out[41]: [&apos;犯罪&apos;, &apos;剧情&apos;]
</code></pre><p>发现，已经把\xa0当作左侧的空格给替换掉了，实际他显示出来就是一个空格的。然后通过中间的空格再劈开，得到了2个元素的字符串的列表。<br>这样就清洗出了所需要的数据。</p>
<p>下面的代码紧跟了一个针对key的for循环，是用来构建一个名为douban的字典dict，后续会把他的值再导入到数据库中。</p>
<pre><code>for i in key:
    if i not in douban.keys():
        douban[i] = 1
    else:
        douban[i] += 1
</code></pre><p>里面的含义是：如果一个电影的分类关键词，在douban字典中（此时数据还没导入到数据库）不存在，那么新建一个对应名字的键值（keys），数值为1.否则如果是已经存在的，那么累加1.</p>
<p>5、 第二个函数是def save_mysql():作用是把提取的数据加载到数据库中去。<br>其中insert的那一行命令写的有点个性，但因为用到了过多的引号，所以我不是很推荐，一般的写法是： %s + 变量名</p>
<p>6、最后一个函数是用来画图的， 这块后续要配合nunpy，pandas等一直在加强下学习。</p>
<p>统计结果显示，绝大部分的好电影都是通过剧情抓住人心的：</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-27/144837956.png" alt=""></p>
<p>7、 参考： <a href="http://www.jianshu.com/p/ef242e025cdf" target="_blank" rel="external">爬取豆瓣电影top250提取电影分类进行数据分析</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Van" />
          <p class="site-author-name" itemprop="name">Van</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">54</span>
              <span class="site-state-item-name">Artikel</span>
            </a>
          </div>

          

          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Van</span>
</div>

<div class="powered-by">
  Erstellt mit  <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  




  
  

  

  

  

</body>
</html>
