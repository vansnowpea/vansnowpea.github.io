<!doctype html>



  


<html class="theme-next muse use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta property="og:type" content="website">
<meta property="og:title" content="A Song of Python and Anaconda">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="A Song of Python and Anaconda">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Song of Python and Anaconda">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: 'Author'
    }
  };
</script>




  <link rel="canonical" href="http://yoursite.com/"/>

  <title> A Song of Python and Anaconda </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">A Song of Python and Anaconda</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/07/下载最新电影的爬虫/" itemprop="url">
                  下载最新电影的爬虫【Python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-10-07T23:59:28+08:00" content="2016-10-07">
              2016-10-07
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="下载最新电影的爬虫"><a href="#下载最新电影的爬虫" class="headerlink" title="下载最新电影的爬虫"></a>下载最新电影的爬虫</h1><p>1、使用：</p>
<ul>
<li>lxml.etree</li>
<li>requests</li>
</ul>
<p>2、代码：</p>
<pre><code># -*- coding:utf-8 -*-
import requests
from lxml import etree


url = &apos;http://www.ygdy8.net/html/gndy/dyzz/index.html&apos;  #这是电影天堂最新电影的网站
# r = requests.get(url).content
# print(r.encoding）
# &gt;&gt;&gt; ISO-8859-1
html = requests.get(url).content
# html = requests.get(url).content.decode(&apos;ISO-8859-1&apos;).encode(&apos;utf-8&apos;)

selector = etree.HTML(html)

# //*[@id=&quot;content&quot;]/div/div[1]/ol/li[1]/div/div[2]/div[2]/p[1]
# get rid of the : /tbody
biaoti = selector.xpath(&apos;//*[@id=&quot;header&quot;]/div/div[3]/div[3]/div[2]/div[2]/div[2]/ul//tr[2]/td[2]/b/a/text()&apos;)


# get rid of the : /tbody
jianjie = selector.xpath(&apos;/html/body/div/div/div[3]/div[3]/div[2]/div[2]/div[2]/ul//tr[4]/td/text()&apos;)
wangzhi = selector.xpath(&apos;//*[@id=&quot;header&quot;]/div/div[3]/div[3]/div[2]/div[2]/div[2]/ul//tr[2]/td[2]/b/a/@href&apos;)

for b,j,k in zip(biaoti,jianjie,wangzhi):
    print(b+&apos;\n&apos;+j+&apos;\n&apos;+&apos;www.ygdy8.net&apos;+k+&apos;\n&apos;)
</code></pre><p>3、分析：主要和上一篇的接近，但是这一篇还有读取网址等操作，注意格式上和读取内容text有差别的。<br>总结如下：</p>
<pre><code>获取到标签后我们可以获取标签中的属性值
tree.xpath(&quot;//div[@class=&apos;sec_blk mrg_b_30&apos;]/ul/li[1]/a/text()&quot;)     #获取a的文本，li标号是从1开始，而不是从0开始
tree.xpath(&quot;//div[@class=&apos;sec_blk mrg_b_30&apos;]/ul/li[1]/a/@href&quot;)   #获取a的链接地址

当然还有其他类似的xpath例子：
&quot;//input[@id=&apos;city&apos;]/@value&quot;
&quot;//div[@class=&apos;venueDetal&apos;]/p/img[@class=&apos;img&apos;]/@src&quot;
&quot;//div[@class=&apos;detail_info_title&apos;]//a[@class=&apos;hotel_star&apos;]/@title&quot;
</code></pre><p>4、参考： <a href="http://blog.chinaunix.net/uid-13869856-id-5747494.html" target="_blank" rel="external">python+lxml xpath获取数据 </a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/07/东方财富网cpi数据的抓取/" itemprop="url">
                  东方财富网cpi数据的抓取【Python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-10-07T22:59:28+08:00" content="2016-10-07">
              2016-10-07
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="东方财富网cpi数据的抓取"><a href="#东方财富网cpi数据的抓取" class="headerlink" title="东方财富网cpi数据的抓取"></a>东方财富网cpi数据的抓取</h1><p>1、使用：</p>
<ul>
<li>lxml.etree</li>
<li>requests</li>
</ul>
<p>2、代码：</p>
<pre><code>from lxml import etree
import requests

url = &apos;http://data.eastmoney.com/cjsj/cpi.html&apos;
content = requests.get(url).content

html = etree.HTML(content)
content1 = html.xpath(&apos;//*[@id=&quot;tb&quot;]/tr[3]/td[2]/text()&apos;)

print(content1[0].strip().replace(&apos;\n\r&apos;, &apos;&apos;))

# for txt in html.iterfind(&apos;.//*[@id=&quot;tb&quot;]/tr[3]/td&apos;):
#     print(txt.text)
</code></pre><p>3、分析：requests+lxml来分析和提取数据比较简单，可以尽可能的规避使用RE的复杂性以及可能产生的编码问题。要注意的是提取文本内容的时候要在xpath地址后面加上/text()<br>不过这个案例中，需要把xpath的/tbody去掉，这是因为有的浏览器加上去的，否则不能识别需要的文字部分。<br>另外，默认的结果因为有很多的空格和\n\r，所以需要做数据清洗，就本例，加一句content1[0].strip().replace(‘\n\r’, ‘’)即可。</p>
<p>4、没有执行的代码，表示读取2016年08月份 “全国”，“城市”，“农村”各自的cpi数据。<br>要注意的是：这属于ElementPath，一共4个种类，分别如下：</p>
<ul>
<li></li>
</ul>
<ol>
<li>iterfind()</li>
<li>findall()</li>
<li>find()</li>
<li>findtext()</li>
</ol>
<p>千万注意的是：ElementPath不能直接使用绝对路径，需要在前面加一个.符号。暂时感觉这个使用的不太多。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/05/tensorflow 初步学习/" itemprop="url">
                  begin to learn TensorFlow
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-10-05T16:20:28+08:00" content="2016-10-05">
              2016-10-05
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-05/163346079.png" alt=""></p>
<h1 id="Introduction-begin-to-learn-Machine-Learning-and-find-Google’s-open-source-technology-TensorFlow"><a href="#Introduction-begin-to-learn-Machine-Learning-and-find-Google’s-open-source-technology-TensorFlow" class="headerlink" title="Introduction: begin to learn Machine Learning, and find Google’s open source technology: TensorFlow."></a>Introduction: begin to learn Machine Learning, and find Google’s open source technology: TensorFlow.</h1><p>1、It seems TF only support Linux by official , but I try to install also on Win 10, so try :： <a href="http://wiki.jikexueyuan.com/project/tensorflow-zh/" target="_blank" rel="external">http://wiki.jikexueyuan.com/project/tensorflow-zh/</a>：<br>though some guy reported successed on win, but I failed as can not download the big file no matter with USA IP, anyway , I record the method.</p>
<pre><code>捣鼓好了windows docker安装，参考了楼上的许多信息。
1. 安装docker
2. 点开Docker Quickstart Terminal， 打开成功后：
    docker is configured to use the default machine with IP 192.168.99.100
3. 安装tensorflow： docker run -d -p 8888:8888 -v /notebook:/notebook xblaster/tensorflow-jupyter
4. 运行tensorflow-jupyter: docker run xblaster/tensorflow-jupyter
     会提示running at: http://0.0.0.0:8888，不知道为什么会是这个IP地址，用浏览器打开不了。然后替换成docker打开时的IP，http://192.168.99.100:8888就可以打开了。
5. 运行example code，mnist参考资料：1, tensorflow官方文档；2，http://blog.csdn.net/yhl_leo/article/details/50614444 及其mnist的github：https://github.com/yhlleo/mnist，github中有input_data.py这个很重要的文件。
</code></pre><p>2、 I run it on Ubuntu and test an easy exmaple which is :</p>
<pre><code>y =0.1*x +0.3
</code></pre><p>and after 200 times of calculating , get result :</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-05/235616627.png" alt=""> </p>
<p>from the result : after 40 times calculating , the result closes to 0.1*x + 0.3 already , no matter how AlphaGo is so strong.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/02/numpy和pandas的初步学习/" itemprop="url">
                  numpy和pandas的初步学习以及6本数据分析必读书和2份英文教程
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-10-02T14:20:28+08:00" content="2016-10-02">
              2016-10-02
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-02/235644734.png" alt=""></p>
<h1 id="简介：-今天把cmder的配色研究下，找了个nice的shell版，赞一个，另外，英文是绕不过去的，最后总会发现想要的资料只有英文的。-：）"><a href="#简介：-今天把cmder的配色研究下，找了个nice的shell版，赞一个，另外，英文是绕不过去的，最后总会发现想要的资料只有英文的。-：）" class="headerlink" title="简介： 今天把cmder的配色研究下，找了个nice的shell版，赞一个，另外，英文是绕不过去的，最后总会发现想要的资料只有英文的。 ：）"></a>简介： 今天把cmder的配色研究下，找了个nice的shell版，赞一个，另外，英文是绕不过去的，最后总会发现想要的资料只有英文的。 ：）</h1><p>1、这几天抽空看了下《利用python进行数据分析》的几个章节，其中pandas部分看了2遍，熟悉了一些命令和用法，</p>
<p>2、国外一个朋友的对某个问题的建议是使用JS， 首先我是按照这个网页的心得：不过我找了一本JS的入门书，发现内容不是兴趣所在，所以暂时先记录之。</p>
<p><a href="http://kb.cnblogs.com/page/191787/" target="_blank" rel="external">http://kb.cnblogs.com/page/191787/</a></p>
<p>3、另搜资料的时候，找了一个国外的网址，介绍了数据分析几本不错的书，<br><a href="https://www.analyticsvidhya.com/blog/2014/06/books-data-scientists-or-aspiring-ones/" target="_blank" rel="external"><br>Must have books for data scientists (or aspiring ones)</a></p>
<p>4、在上述链接中，是6本书的英文介绍，貌似R的数量更多，并且有一本是R的，但有第三方给出了Python代码，（注意有的文字因粘贴丢失了超链接）：</p>
<pre><code>1. R Cookbook by Paul Teetor

This is simply the best book to start your journey with R. It contains tons of examples and practical advice on a wide range of topics like file input / output, data manipulations, merging and sorting to building a regression model. For a starter in R, this book becomes your best pal during the initial testing time.

While the book is aimed towards starters, it still remains a prominent feature of the library of any data scientist.



2. Machine Learning for Hackers by Drew Conway &amp; John Myles White

I think this book actually has a wrong title. I dropped purchasing it twice before giving it a shot (which happened only because of a recommendation from a close friend). This book is meant for data scientists and not hackers. I don’t know why the title says so. A very practical manual for learning machine learning, it comes with good visuals and you can get a copy of codes in Python (original book is based on R).



3. R graphics cookbook by Winston Chang

You can’t be a good data scientist unless you master the graphics in R! There is no better way for visualization, but to learn ggplot2. Sadly, learning ggplot2 might seem like learning a completely new language in itself. This is where this “cookbook” comes to rescue. The recipes from Winston are short, sweet and to the point. Buy this and it is bound to end up as one of the most referred book in your library.



4. Programming Collective Intelligence by Toby Segaran (popularly referred as PCI)

If there is one book you want to choose, out of this selection (for learning machine learning) – it is this one. I haven’t met a data scientist yet who has read this book and does not recommend to keep it on your bookshelf. A lot of them have re-read this book multiple times. The book was written long before data science and machine learning acquired the cult status they have today – but the topics and chapters are entirely relevant even today! Some of the topics covered in the book are collaborative filtering techniques, search engine features, Bayesian filtering and Support vector machines. If you don’t have a copy of this book – order it as soon as you finish reading this article! The book uses Python to deliver machine learning in a fascinating manner.



5. Python for Data Analysis by Wes McKinney

Written by Wes McKinney, this book teaches you everything you need about Pandas. For the starters (not sure why you are still reading this article), pandas are Python’s way to handle data structures. Except for the title of the book (which I find misleading), I like everything else about this book. It contains ample codes and examples to leave you capable of performing any operation / transformation on a dataframe in Python (using pandas).

For the advanced users, if you already know pandas, you should look at this presentation from Wes on what are the shortcomings of pandas.



6. Agile data science by Russell Jurney

A recent addition by O’Reilly, this book looks like a must read for data scientists. The focus is on using “light” tools, which are easy to use and still get the work done. This is currently on my reading list and I’ll update more details once I have read it.



These are the 6 must have books, if you are serious about being a data scientist. There are a couple of additional Python books, which you can consider – Natural Language processing with Python by Steven Bird et al and Mining the social web by Matthew A. Russell. The reason I have not kept them in the list is because you can find a lot of the information in these books easily on the web.
</code></pre><p>5、另外，还有2篇不错的英文的基于python-pandas的数据分析教程：</p>
<p><a href="https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/" target="_blank" rel="external">A Complete Tutorial to Learn Data Science with Python from Scratch</a></p>
<p>以及这个：</p>
<p><a href="https://www.analyticsvidhya.com/blog/2014/09/data-munging-python-using-pandas-baby-steps-python/" target="_blank" rel="external">Data Munging in Python (using Pandas) – Baby steps in Python</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/27/收到《Python for data analysis》作者的邮件回复/" itemprop="url">
                  收到《Python for data analysis》作者的邮件回复
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-09-27T14:20:28+08:00" content="2016-09-27">
              2016-09-27
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-27/150628293.jpg" alt=""></p>
<h1 id="简介：-收到《Python-for-data-analysis》作者的邮件回复-：）"><a href="#简介：-收到《Python-for-data-analysis》作者的邮件回复-：）" class="headerlink" title="简介： 收到《Python for data analysis》作者的邮件回复 ：）"></a>简介： 收到《Python for data analysis》作者的邮件回复 ：）</h1><p>1、上次给他写了一个邮件，建议用Anaconda来写下一版本，虽然过了几天还是收到了回复，看样子他也意识到Anaconda更好点，也表示第二版会采用：</p>
<pre><code>try

from matplotlib.pyplot import *

and running

%matplotlib

I am creating a 2nd edition of the book, and it will use Anaconda
instead of Canopy in the instructions.

Thanks!
</code></pre><p>2、然后我去Python中文社区问了几个人，表示有兴趣翻译，由于第一版是机械工业出版社搞的中译版，发了一个email咨询是否将来打算出第二版的中译，但是还没得到回复，想了下，如果他们不翻译，就召集社区的小伙伴们来翻译吧。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/27/matplotlib中文显示乱码的解决办法/" itemprop="url">
                  matplotlib中文显示乱码的解决办法
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-09-27T13:20:28+08:00" content="2016-09-27">
              2016-09-27
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介：-matplotlib中文显示乱码的解决办法-：）"><a href="#简介：-matplotlib中文显示乱码的解决办法-：）" class="headerlink" title="简介： matplotlib中文显示乱码的解决办法 ：）"></a>简介： matplotlib中文显示乱码的解决办法 ：）</h1><p>1、在源代码开头加入以下几行：</p>
<pre><code>from pylab import *
mpl.rcParams[&apos;font.sans-serif&apos;] = [&apos;SimHei&apos;] #指定默认字体

mpl.rcParams[&apos;axes.unicode_minus&apos;] = False #解决保存图像是负号&apos;-&apos;显示为方块的问题
</code></pre><p>2、上述就针对单个py文件，如果想全部的，可以这么操作：</p>
<ul>
<li>\Lib\site-packages\matplotlib\mpl-data\matplotlibrc    用任意文本编辑器打开。（最好先备份一下）<br>找到第129行：#font.family， 将其注释去掉，冒号后面的值改为Microsoft YaHei</li>
<li>找到第141行：#font.sans-serif， 将其注释去掉，并将Microsoft YaHei添加到冒号后面的最前面，注意还要再加一个英文逗号（,）</li>
<li>并设置axes.unicode_minus = False #解决保存图像是负号’-‘显示为方块的问题</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/25/《利用Python进行数据分析》如何把kindle的电子书转成pdf的教程/" itemprop="url">
                  如何把kindle的电子书转成word等格式的教程
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-09-25T23:20:28+08:00" content="2016-09-25">
              2016-09-25
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介：-如何把kindle的电子书转成word等格式的教程-：）"><a href="#简介：-如何把kindle的电子书转成word等格式的教程-：）" class="headerlink" title="简介： 如何把kindle的电子书转成word等格式的教程 ：）"></a>简介： 如何把kindle的电子书转成word等格式的教程 ：）</h1><p>1、参考知乎的步骤， <a href="http://www.zhihu.com/question/38451995" target="_blank" rel="external">http://www.zhihu.com/question/38451995</a></p>
<p>2、下载去除DRM的破解版本，不然只能破解3本书，参考此网址： <a href="http://www.d9soft.com/soft/102882.htm" target="_blank" rel="external">http://www.d9soft.com/soft/102882.htm</a></p>
<p>3、使用该网站，进行pdf转换： <a href="http://www.epubconverter.com/azw-to-pdf-converter/" target="_blank" rel="external">http://www.epubconverter.com/azw-to-pdf-converter/</a></p>
<p>4、成功把《利用Python进行数据分析》转成了pdf，当然我事先花销了巨额的0.1元注册了一个Kindle Unlimited  帐号</p>
<p>5、为了方便复制书中的代码实例，继续用calibre 软件进行转换成docx格式，不用对着那些网上的扫描版，或者纸质书，坑爹的挨个自己输入命令了有木有， </p>
<p>6、示范图： </p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-26/001138836.png" alt=""></p>
<p>7、我已经为偷懒的你，上传了本书，可以直接下载word版本啦。请点击<a href="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-26/001313882.docx" target="_blank" rel="external">【下载点我】</a></p>
<p>8、记得重命名，方便以后查找。</p>
<p>9、第八章spx指数的举例，代码我修正到pycharm里：</p>
<pre><code>import matplotlib.pyplot as plt
from datetime import datetime
import pandas as pd
fig = plt.figure()
ax = fig.add_subplot(1, 1, 1)
data = pd.read_csv(&apos;D:\mine\pydata-book-master\ch08/spx.csv&apos;, index_col=0, parse_dates=True)
spx = data[&apos;SPX&apos;]
spx.plot(ax=ax, style=&apos;k-&apos;)
crisis_data = [      (datetime(2007, 10, 11), &apos;Peak of bull market&apos;),      (datetime(2008, 3, 12), &apos;Bear Stearns Fails&apos;),      (datetime(2008, 9, 15), &apos;Lehman Bankruptcy&apos;) ]
for date, label in crisis_data:
    ax.annotate(label, xy=(date, spx.asof(date) + 50),                 xytext=(date, spx.asof(date) + 200),                 arrowprops=dict(facecolor=&apos;black&apos;),                 horizontalalignment=&apos;left&apos;, verticalalignment=&apos;top&apos;)
# 放大到2007-2010
    ax.set_xlim([&apos;1/1/2007&apos;, &apos;1/1/2011&apos;])
    ax.set_ylim([600, 1800])
    ax.set_title(&apos;Important dates in 2008-2009 financial crisis&apos;)

plt.show()
</code></pre><p>结果图，有木有一点专业的味道？<br> <img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-26/105503895.png" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/23/豆瓣电影TOP250的爬取和作图分析/" itemprop="url">
                  《利用Python进行数据分析》豆瓣电影TOP250的爬取和作图分析【python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-09-23T23:20:28+08:00" content="2016-09-23">
              2016-09-23
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介：-又回到豆瓣了，这是多适合爬虫的网站-：）"><a href="#简介：-又回到豆瓣了，这是多适合爬虫的网站-：）" class="headerlink" title="简介： 又回到豆瓣了，这是多适合爬虫的网站 ：）"></a>简介： 又回到豆瓣了，这是多适合爬虫的网站 ：）</h1><p>1、这次的对象是top 250 ， 网址：  <a href="https://movie.douban.com/top250" target="_blank" rel="external">https://movie.douban.com/top250</a> 目的是对这250部电影的分类做一个统计。</p>
<p>2、实际有其他人做了分析，正好看到，发现其代码比较漂亮，所以研读，顺便复习检阅自己学习成果。秉承一贯的作风，做一定的细节分析。先看下原文代码：</p>
<pre><code># -*- coding: utf-8 -*-
# !/usr/bin/env python

from lxml import etree
import requests
import pymysql
import matplotlib.pyplot as plt
from pylab import *
import numpy as np

# 连接mysql数据库
conn = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;, passwd = &apos;54545454&apos;, db = &apos;douban&apos;, charset = &apos;utf8&apos;)
cur = conn.cursor()
cur.execute(&apos;use douban&apos;)

def get_page(i):
    url = &apos;https://movie.douban.com/top250?start={}&amp;filter=&apos;.format(i)

    html = requests.get(url).content.decode(&apos;utf-8&apos;)

    selector = etree.HTML(html)
    # //*[@id=&quot;content&quot;]/div/div[1]/ol/li[1]/div/div[2]/div[2]/p[1]
    content = selector.xpath(&apos;//div[@class=&quot;info&quot;]/div[@class=&quot;bd&quot;]/p/text()&apos;)
    print(content)

    for i in content[1::2]:
        print(str(i).strip().replace(&apos;\n\r&apos;, &apos;&apos;))
        # print(str(i).split(&apos;/&apos;))
        i = str(i).split(&apos;/&apos;)
        i = i[len(i) - 1]
        # print(&apos;zhe&apos; +ｉ)
        # print(i.strip())
        # print(i.strip().split(&apos; &apos;))
        key = i.strip().replace(&apos;\n&apos;, &apos;&apos;).split(&apos; &apos;)
        print(key)
        for i in key:
            if i not in douban.keys():
                douban[i] = 1
            else:
                douban[i] += 1

def save_mysql():
    print(douban)
    for key in douban:
        print(key)
        print(douban[key])
        if key != &apos;&apos;:
            try:
                sql = &apos;insert douban(类别, 数量) value(&apos; + &quot;\&apos;&quot; + key + &quot;\&apos;,&quot; + &quot;\&apos;&quot; + str(douban[key]) + &quot;\&apos;&quot; + &apos;);&apos;
                cur.execute(sql)
                conn.commit()
            except:
                print(&apos;插入失败&apos;)
                conn.rollback()


def pylot_show():
    sql = &apos;select * from douban;&apos;
    cur.execute(sql)
    rows = cur.fetchall()
    count = []
    category = []

    for row in rows:
        count.append(int(row[2]))
        category.append(row[1])
    print(count)
    y_pos = np.arange(len(category))
    print(y_pos)
    print(category)
    colors = np.random.rand(len(count))
    plt.barh()
    plt.barh(y_pos, count, align=&apos;center&apos;, alpha=0.4)
    plt.yticks(y_pos, category)
    for count, y_pos in zip(count, y_pos):
        plt.text(count, y_pos, count,  horizontalalignment=&apos;center&apos;, verticalalignment=&apos;center&apos;, weight=&apos;bold&apos;)
    plt.ylim(+28.0, -1.0)
    plt.title(u&apos;豆瓣电影250&apos;)
    plt.ylabel(u&apos;电影分类&apos;)
    plt.subplots_adjust(bottom = 0.15)
    plt.xlabel(u&apos;分类出现次数&apos;)
    plt.savefig(&apos;douban.png&apos;)


if __name__ == &apos;__main__&apos;:
    douban = {}
    for i in range(0, 250, 25):
        get_page(i)
    save_mysql()
    pylot_show()
    cur.close()
    conn.close()
</code></pre><p>3、首先是他用了selector = etree.HTML(html)  而我用的比较多的是bs4，应该是殊途同归。他的xpath路径是：</p>
<pre><code>content = selector.xpath(&apos;//div[@class=&quot;info&quot;]/div[@class=&quot;bd&quot;]/p/text()&apos;) 
</code></pre><p>而我用的偷懒模式：直接浏览器找到的： </p>
<pre><code>selector.xpath(&apos;//*[@id=&quot;content&quot;]/div/div[1]/ol/li[1]/div/div[2]/div[2]/p[1]/text()&apos;)
</code></pre><p>注意，默认到P[1]的路径，因为是需要读取里面的文本部分，所以加入/text()</p>
<p>4、这样就得到了第一页的影视信息的文本，不过如果用ipthon分步操作查看， 那简直是逆天的格式，如图：</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-23/225057825.png" alt=""></p>
<p>5、必须进行文字提取处理了。 </p>
<p>首先，这一大坨的，为了简单，我们用单元测试的思想，先调试第一页第一个，这里之前已经设置从：</p>
<pre><code>url = &apos;https://movie.douban.com/top250?start={}&amp;filter=&apos;.format(i)
</code></pre><p>修改为：</p>
<pre><code>url = &apos;https://movie.douban.com/top250?start={1}&amp;filter=&apos;
</code></pre><p>同时，观察整个循环输出的格式是一个列表，每个元素是一个字符串，那么第一个电影的电影信息对应的字符串是：</p>
<pre><code>&apos;\n                            导演: 弗兰克·德拉邦特 Frank Darabont\xa0\xa0\xa0主演: 蒂姆·罗宾斯 Tim Robbins /...&apos;, &apos;\n                            1994\xa0/\xa0美国\xa0/\xa0犯罪 剧情\n                        &apos;
</code></pre><p>和原始网页的信息对照，实际就是第一部分包含导演主演信息，第二部分是年份国家和剧种， 就本文，我们需要的是第二部分的内容，也就是“1994 / 美国 / 犯罪 剧情”这部分内容。然后呢，因为整个content 包含了25部电影的文本， 这些都保存在列表里，并且我们需要进一步处理的，都在对应坐标1、3、5、、这样的奇数里。因为列表第一个是从0开始的。这就是第一个for循环的意义所在，用到了python的切片知识第二个冒号，表示从下表1的元素开始检索，并且隔开2个元素为下一次检索：</p>
<pre><code>for i in content[1::2]:
</code></pre><p>查看了循环内的第一句为，注意这只是print，没有运行具体的代码影响原来的字符串：</p>
<pre><code>print(str(i).strip().replace(&apos;\n\r&apos;, &apos;&apos;))
</code></pre><p>这句的意思就是得到整个content列表中，下标为1、3、5。。。。的元素，并通过strip（）来进行去掉首尾的多余的空格，,随后使用replace函数，把’\n\r’替换为空字符。我们可以在ipython中验证下：</p>
<p>记录：aa = conntent[1]：  </p>
<pre><code>aa =  &apos;\n                            1994\xa0/\xa0美国\xa0/\xa0犯罪 剧情\n                        &apos;
</code></pre><p>执行：aa.strip()，得到：</p>
<pre><code>In [19]: aa.strip()
Out[19]: &apos;1994\xa0/\xa0美国\xa0/\xa0犯罪 剧情&apos;

In [20]: aa.strip().replace(&apos;\n\r&apos;, &apos;&apos;)
Out[20]: &apos;1994\xa0/\xa0美国\xa0/\xa0犯罪 剧情&apos;
</code></pre><p>发现上述的replace函数似乎没起作用，那是这里正好没有’\n\r’，同时你可以发现，这里怎么有4个地方有\xa0 ？ 这是什么呢？ 原来是：转义字符，”\x”后接数字（两位）代表16进制数，这玩意牵涉编码的问题，打印的时候是一个空格。</p>
<p>然后循环里面的开始执行的命令都是为了去除\n和空格这些没有的东西，i = str(i).split(‘/‘)就是把去除空格和\n的字符串通过‘/’分隔在列表里。</p>
<pre><code>In [35]: aa =  &apos;\n                            1994\xa0/\xa0美国\xa0/\xa0犯罪 剧情\n                        &apos;

In [36]: aa = aa.split(&apos;/&apos;)

In [37]: aa = aa(len(aa)-1)
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-37-06f75198160a&gt; in &lt;module&gt;()
----&gt; 1 aa = aa(len(aa)-1)

TypeError: &apos;list&apos; object is not callable

In [38]: aa = aa[len(aa)-1]

In [39]: aa
Out[39]: &apos;\xa0犯罪 剧情\n
</code></pre><p>随后，通过</p>
<pre><code>In [40]: key = aa.strip().replace(&apos;\n&apos;, &apos;&apos;).split(&apos; &apos;)

In [41]: key
Out[41]: [&apos;犯罪&apos;, &apos;剧情&apos;]
</code></pre><p>发现，已经把\xa0当作左侧的空格给替换掉了，实际他显示出来就是一个空格的。然后通过中间的空格再劈开，得到了2个元素的字符串的列表。<br>这样就清洗出了所需要的数据。</p>
<p>下面的代码紧跟了一个针对key的for循环，是用来构建一个名为douban的字典dict，后续会把他的值再导入到数据库中。</p>
<pre><code>for i in key:
    if i not in douban.keys():
        douban[i] = 1
    else:
        douban[i] += 1
</code></pre><p>里面的含义是：如果一个电影的分类关键词，在douban字典中（此时数据还没导入到数据库）不存在，那么新建一个对应名字的键值（keys），数值为1.否则如果是已经存在的，那么累加1.</p>
<p>5、 第二个函数是def save_mysql():作用是把提取的数据加载到数据库中去。<br>其中insert的那一行命令写的有点个性，但因为用到了过多的引号，所以我不是很推荐，一般的写法是： %s + 变量名</p>
<p>6、最后一个函数是用来画图的， 这块后续要配合nunpy，pandas等一直在加强下学习。</p>
<p>统计结果显示，绝大部分的好电影都是通过剧情抓住人心的：</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-27/144837956.png" alt=""></p>
<p>7、 参考： <a href="http://www.jianshu.com/p/ef242e025cdf" target="_blank" rel="external">爬取豆瓣电影top250提取电影分类进行数据分析</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/23/数值分析和一个bug解决记录/" itemprop="url">
                  数值分析和一个bug解决记录【python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-09-23T23:20:28+08:00" content="2016-09-23">
              2016-09-23
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介：-数值分析和一个bug解决记录-：）"><a href="#简介：-数值分析和一个bug解决记录-：）" class="headerlink" title="简介： 数值分析和一个bug解决记录 ：）"></a>简介： 数值分析和一个bug解决记录 ：）</h1><p>1、这个bug是在使用python3.5.2的时候发生的，由于同时安装anaconda  有时候因为一些测试python2的代码 也安装卸载 最终出现了： Fatal error in launcher: Unable to create process using ‘“‘</p>
<p>2、解决方案，控制面板卸载后，再到python3 的安装路径把文件夹都删除，此时，保留anaconda版本，在cmder输入ipython就可以正常运行了。</p>
<p>3、说到数值分析，感觉还是要先阅读下相关书籍，虽然以前matlab接触过一些。首先看的就是评价还不错的《利用python进行数值分析》，但是发现了一个问题，所以马上给作者写了一个email如下图：</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-24/235703049.png" alt=""></p>
<p>4、</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/22/验证码识别的测试/" itemprop="url">
                  验证码识别的测试【python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-09-22T14:20:28+08:00" content="2016-09-22">
              2016-09-22
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-23/012758858.jpg" alt=""></p>
<h1 id="简介：-验证码识别的测试，因故需做一个自动的多用户注册的脚本"><a href="#简介：-验证码识别的测试，因故需做一个自动的多用户注册的脚本" class="headerlink" title="简介： 验证码识别的测试，因故需做一个自动的多用户注册的脚本"></a>简介： 验证码识别的测试，因故需做一个自动的多用户注册的脚本</h1><p>1、查阅相关博客，建议使用的是Python+Selenium+PIL+Tesseract ，又有人推荐了Pytesser，不过这个Pytesser的安装还挺坑的。</p>
<p>2、开始参考的是：<br><a href="http://www.th7.cn/Program/Python/201602/768304.shtml" target="_blank" rel="external">http://www.th7.cn/Program/Python/201602/768304.shtml</a></p>
<p>以及这个</p>
<p><a href="http://blog.csdn.net/lanfan_11/article/details/45558573" target="_blank" rel="external">http://blog.csdn.net/lanfan_11/article/details/45558573</a></p>
<p>3、但测试了半天，无论我按照哪个方法，最终我都不能import pytesser ， 一开始以为成功了，原来是我按照他的例子直接在pytesseract-v0.0.1的文件夹测试的脚本，那自然可以了。</p>
<p>4、毕竟第一次遇到需要这么折腾的第三方库，而且还是好几年前就停止更新了，干脆就直接把需要编写的py文件丢到这个pytesser文件夹来规避。 </p>
<p>5、后来又发现有的博客推荐了pytesseract ，看名字应该是继承了pytesser，但是保持更新的，果然顺利安装，那么就是他了。那么更新下使用的工具组合为：Python+Selenium+PIL+pytesseract+Tesseract </p>
<p>6、剩下就是如何识别验证码的问题，由于测试的网站使用的.aspx的动态图，导致每次输入url得到不同的验证码。<br>所以一不做二不休，使用了截屏计算其验证码方位后单独识别的方案。(另外一个可操作方案是使用cookie)</p>
<p>过程：</p>
<pre><code># coding:utf-8
# python 3.5.2


from selenium.webdriver.support import ui as ui
from selenium.webdriver.common.keys import Keys #需要引入keys 包
from selenium.webdriver.common.action_chains import ActionChains
from selenium import webdriver
import pytesseract
import time
from PIL import Image,ImageEnhance

num = 400
# wait = ui.WebDriverWait(browser, 10)
# 已经人工测试了一个，所以从第二2个开始
for i in range(2, num+1):

    name_cn = &apos;aaa&apos;        
    browser = webdriver.PhantomJS()
    browser.maximize_window()
    url = &quot;http://www.wangzhi.com&quot;
    browser.get(url)
    wait = ui.WebDriverWait(browser, 20)
    wait.until(lambda browser:browser.find_element_by_xpath(&quot;//*[@id=\&quot;ussheng\&quot;]&quot;))
    shs1 = browser.find_element_by_xpath(&quot;//*[@id=\&quot;ussheng\&quot;]&quot;).send_keys(&quot;shengfen&quot;)
    shs2 = browser.find_element_by_xpath(&quot;//*[@id=\&quot;uscity\&quot;]&quot;).send_keys(&quot;xxshi&quot;)
    mhq = browser.find_element_by_xpath(&quot;//*[@id=\&quot;usxian\&quot;]&quot;).send_keys(&quot;yyqu&quot;)
    nling = browser.find_element_by_xpath(&quot;//*[@id=\&quot;inscage\&quot;]&quot;).send_keys(&quot;nianling&quot;)
    dwei = browser.find_element_by_xpath(&quot;//*[@id=\&quot;worker\&quot;]&quot;).send_keys(&quot;dizhi&quot;)
    name_input = browser.find_element_by_xpath(&quot;//*[@id=\&quot;ustruename\&quot;]&quot;).send_keys(name_cn + &apos;%d&apos;%i)

    # 选择性别，下拉框操作
    sex = browser.find_element_by_xpath(&quot;//*[@id=\&quot;DropDownList1\&quot;]&quot;)
    sex.find_element_by_xpath(&quot;//*[@id=\&quot;DropDownList1\&quot;]/option[2]&quot;).click()

    # 验证码识别，思路，右键保存验证码图片，识别数字或者字母。但是保存不能执行，失败
    ###############################################################################
    # # xpath： //*[@id=&quot;ValidImage&quot;]
    # shi_bie_ma = browser.find_element_by_xpath(&quot;//*[@id=\&quot;ValidImage\&quot;]&quot;)
    # action = ActionChains(browser).move_to_element(shi_bie_ma)
    # action.context_click(shi_bie_ma)
    # action.send_keys(Keys.ARROW_DOWN)
    # action.send_keys(&apos;v&apos;)
    # action.perform()
    ###############################################################################



    # 通过下载图片后识别，发现是aspx 每次打开url都更新识别码，所以失败。看来只好一开始就截屏啦。

    # 截屏
    browser.get_screenshot_as_file(&apos;C:\\van\\image1.jpg&apos;)#比较好理解

    # 检测识别码坐标
    imgelement = browser.find_element_by_xpath(&apos;//*[@id=&quot;ValidImage&quot;]&apos;) #定位验证码
    location = imgelement.location #获取验证码x,y轴坐标

    size=imgelement.size #获取验证码的长宽
    range=(int(location[&apos;x&apos;]),int(location[&apos;y&apos;]),int(location[&apos;x&apos;]+size[&apos;width&apos;]),int(location[&apos;y&apos;]+size[&apos;height&apos;])) #写成我们需要截取的位置坐标

    im =Image.open(&apos;C:\\van\\image1.jpg&apos;)
    # 设置要裁剪的区域
    region = im.crop(range)     #此时，region是一个新的图像对象。
    #region.show()#显示的话就会被占用，所以要注释掉
    region.save(&quot;C:\\van\\image2.jpg&quot;)


     #--------------------图片增强+自动识别简单验证码-----------------------------
    #time.sleep(3)防止由于网速，可能图片还没保存好，就开始识别

    im=Image.open(&quot;C:\\van\\image2.jpg&quot;)
    imgry = im.convert(&apos;L&apos;)#图像加强，二值化
    sharpness =ImageEnhance.Contrast(imgry)#对比度增强
    sharp_img = sharpness.enhance(2.0)

    sharp_img.save(&quot;C:\\van\\image2.jpg&quot;)

    #http://www.cnblogs.com/txw1958/archive/2012/02/21/2361330.html

    #imgry.show()#这是分布测试时候用的，整个程序使用需要注释掉
    #imgry.save(&quot;E:\\image_code.jpg&quot;)
    im=Image.open(&quot;C:\\van\\image2.jpg&quot;)
    code = pytesseract.image_to_string(im)#code即为识别出的图片数字str类型
    print(code)
    #打印code观察是否识别正确

    #-------------------------------------------------------------------
    code_input = browser.find_element_by_xpath(&quot;//*[@id=\&quot;txtCheckCode\&quot;]&quot;).send_keys(code)
    # login
    browser.find_element_by_xpath(&quot;//*[@id=\&quot;Button1\&quot;]&quot;).click()
    print(&quot;fished,%d&quot;%i)
    browser.quit()
</code></pre><p>7、程序分析：</p>
<ul>
<li>虽然使用的截屏然后识别验证码的方式，也许不是最优雅，不过可可以通过元素的imgelement.location 来获取验证码x,y轴坐标，从而可以得到精确的验证码截图区域，否则人工去调试也不是不行，但需要在画图板用鼠标尽可能准确的定位。</li>
<li>增加了图片增加识别技术，加大了识别验证码的概率。</li>
<li>这段代码的不足之处是没有检测验证码识别提交后，是否失败的判断，这主要是测试的网站标的，实在做的太烂了，点了二维码不会立刻提示错误与否，而是卡机。</li>
</ul>
<p>8、总结：有较多的注释，记录了一些操作思路。学习了验证码的初级识别技术。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Van" />
          <p class="site-author-name" itemprop="name">Van</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">53</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          

          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Van</span>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  




  
  

  

  

  

</body>
</html>
