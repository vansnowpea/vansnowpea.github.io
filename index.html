<!doctype html>



  


<html class="theme-next muse use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta property="og:type" content="website">
<meta property="og:title" content="A Song of Python and Anaconda">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="A Song of Python and Anaconda">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Song of Python and Anaconda">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: 'Author'
    }
  };
</script>




  <link rel="canonical" href="http://yoursite.com/"/>

  <title> A Song of Python and Anaconda </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">A Song of Python and Anaconda</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archiv
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/11/下载国外最新高清pdf的程序测试/" itemprop="url">
                  国外最新高清pdf寻找以及实现迅雷自动下载【Python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-11T20:59:28+08:00" content="2016-10-11">
              2016-10-11
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="国外最新高清pdf寻找以及实现迅雷自动下载"><a href="#国外最新高清pdf寻找以及实现迅雷自动下载" class="headerlink" title="国外最新高清pdf寻找以及实现迅雷自动下载"></a>国外最新高清pdf寻找以及实现迅雷自动下载</h1><p>1、今天意外发现国外某站，提供非常近期，甚至国内亚马逊还没上市的最新高清pdf，所以测试爬虫，看是否能自动下载。</p>
<p>2、</p>
<p>《OReilly.Introduction.to.Machine.Learning.with.Python.A.Guide.for.Data.Scientists.1449369413》  </p>
<p>一开始人工下载成功， 国内要月底才上线呢。</p>
<p>3、 随后测试程序是否可自动下载，第二本书的下载遇到了问题：总提示服务器维护，但更换了ip也这样的结果，后发现是对应网盘异常了。</p>
<p>4、代码：</p>
<pre><code># -*- coding: utf-8 -*-
# python 3.5.2
# 测试系统，Win10，Firefox V46
# Author:Van
# 实现自动下载高清最新pdf的实现
# V1.0 当前只针对效果还可以的国外zippyshare网盘
# 其他的网盘还没添加进判断语句，先共享如何迅雷下载等
# 如果您有经验优化，改进此脚本，请不吝指教
# QQ群： 206241755
# 简介：因下载最新高清pdf，正好发现www.foxebook.net提供
# 但是很多的广告，特烦人，所以尝试脚本，最后因下载需求，
# 加载了迅雷，这功能的实现小牛，不过也是网络别人共享的。。

from selenium import webdriver
import requests
from lxml import etree
import re
import os
from win32com.client import Dispatch



#test name of book : SciPy and NumPy
# book_name = input(&apos;Please input the book name in English:\n&apos;)
book_name = &apos;Introduction to Machine Learning with Python&apos;
print (&apos;begin to search book(s)...&apos;)
print (&apos;---------------------------------&apos;)
# search link is :http://www.foxebook.nethttp://www.foxebook.net/search/SciPy%20and%20NumPySciPy%20and%20NumPy
PostUrl = &quot;http://www.foxebook.net/search/&quot; + book_name
# print(PostUrl)
# get the content of html
html = requests.get(PostUrl).content

# use etree selector
selector = etree.HTML(html)

# /html/body/div/div/main/div[2]/div[2]/h3/a
# /html/body/div/div/main/div[3]/div[2]/h3/a
# above is two books&apos; xpath, so the right xpath for all book is :
# /html/body/div/div/main//div[2]/h3/a
# it can be confirmed by &apos;xpath checker&apos;
total_books = selector.xpath(&quot;/html/body/div/div/main//div[2]/h3/a/text()&quot;)
# print(&apos;total books from searching are:&apos;, total_books)

num1 = 0
link_address = []
real_address = []
def find_link():
    global num1
    # find the right book, put all links in a list of : link_address

    for i in total_books:
        num1 += 1
        if re.search(book_name,i):

            print(&apos;Congrdulations, we find the book(s):\n&apos;)
            print (&apos;**********************************&apos;)
            print(i)
            print (&apos;**********************************\n&apos;)
            href = &apos;http://www.foxebook.net&apos; + selector.xpath(&apos;//*[@id=&quot;content&quot;]/div/main/div[%d]/div[2]/h3/a/@href&apos;%num1)[0]
            # print(&apos;the book link is :&apos;, href)
            # print(&apos;will downloading...&apos;)
            html_new = requests.get(href).content
            selector_new = etree.HTML(html_new)
            link_new = selector_new.xpath(&apos;//*[@id=&quot;download&quot;]/div[2]/table/tbody/tr[1]/td[2]/a/@href&apos;)[0]
            # split the next link
            link_new = &apos;http:&apos;+link_new.split(&apos;:&apos;)[-1]
            link_address.append(link_new)
    print(&apos;download link is :&apos;, link_address)
    print(&apos;\n\n&apos;)

def real_book_link():
    # print(&apos;link_address is :&apos;, link_address)
    # dynamic on zippyshare
    for j in link_address:
        # 用浏览器实现访问

        driver = webdriver.Firefox()
        driver.maximize_window()
        driver.get(j)


        try:

            # find the download button
            title_list = driver.find_element_by_xpath(&apos;//*[@id=&quot;dlbutton&quot;]&apos;)
            film_link = title_list.get_attribute(&apos;href&apos;)
            real_address.append(film_link)

        except:
            print(&apos;can not download the book&apos;)

    print(&apos;real_book_link:&apos;, real_address)
    return real_address

def addTasktoXunlei(down_url,course_infos):
    flag = False
    o = Dispatch(&quot;ThunderAgent.Agent.1&quot;)
    if down_url:
        course_path = os.getcwd()
        try:
            #AddTask(&quot;下载地址&quot;, &quot;另存文件名&quot;, &quot;保存目录&quot;,&quot;任务注释&quot;,&quot;引用地址&quot;,&quot;开始模式&quot;, &quot;只从原始地址下载&quot;,&quot;从原始地址下载线程数&quot;)
            o.AddTask(down_url, &apos;&apos;, course_path, &quot;&quot;, &quot;&quot;, -1, 0, 5)
            o.CommitTasks()
            flag = True
        except Exception:

            print(Exception.message)
            print(&quot; AddTask is fail!&quot;)
    return flag

if __name__ == &apos;__main__&apos;:
    find_link()
    real_link = real_book_link()
    for i in real_link:
        addTasktoXunlei(i, course_infos=None)
</code></pre><p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-12/022803439.png" alt=""></p>
<p>5、第二天分析：<br>更换下载的书名为：《Introduction to Machine Learning with Python》</p>
<p>得到了2个有效的书籍目录，对比昨天的书籍名，发现提供的下载源是不同的国外网盘，而昨天的那个到今天一直打不开，而这本书的网址很快就打开了，网盘名字为： zippyshare.com </p>
<p>然后研究了下，此foxebook.net站点提供的一些网盘下载使用了多家国外网盘，并且各家的广告显示不尽相同，可靠性更是差别较大。</p>
<p>另外，发现，就SciPy and NumPy一书来说，他最后得到的地址有2个http，这应该是广告模式，而后者的http的内容是我们真实需要的，所以通过冒号：来切分a.split(‘:’)[-1]。</p>
<pre><code>In [10]: a = &apos;http://sh.st/st/7a45e8ed9f73a6a10e9a22b2d8783c44/http://www65.zippyshare.com/v/oFSWQWDk/file.html&apos;

In [11]: a
Out[11]: &apos;http://sh.st/st/7a45e8ed9f73a6a10e9a22b2d8783c44/http://www65.zippyshare.com/v/oFSWQWDk/file.html&apos;

In [12]: a.split(&apos;:&apos;)[-1]
Out[12]: &apos;//www65.zippyshare.com/v/oFSWQWDk/file.html&apos;
</code></pre><p>6、忘记说明下昨天的代码为何要用re.match （或者re.research）, 这是因为网站的关键词搜索引擎所使用的算法，我们是不知道的，但从搜索结果看，某关键词下，可能有不同的书籍，而我们是需要精确搜索，下图中实际出现了16本书，但针对SciPy and NumPy，我们要找的是第三个图对应的。因此，我们可以把显示的书名做一个match对照的循环，来实现精确匹配。而另外一方面，网站提供的书名还可能多了冒号，后面附加书名，这样的也符合我们的要求。后来发现用关键词 if xxx in yyy的方式更简便。</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-12/093157994.png" alt=""></p>
<p>7、昨天的代码一开始没有考虑到国外网盘下载异常失败的问题，并且有的搜索结果可能有多个网盘地址，而我只取了默认的第一个，考虑到下载的失败可能性，最好把所有下载地址都获取。所以代码需要修改。<br>由于：SciPy and NumPy 对应的网盘当机，选用：《Introduction to Machine Learning with Python》为例</p>
<p>经过对照，在最后的下载界面，是动态的，因此调用selenium+Firefox组合。最后终于得到了完整pdf队中的链接，但速度明显比较慢了，在本例中，是rar后缀的压缩包格式，里面含有pdf。</p>
<pre><code>download link is : [&apos;http://www78.zippyshare.com/v/hBU7JYZp/file.html&apos;, &apos;http://www65.zippyshare.com/v/oFSWQWDk/file.html&apos;]



content: 
book link: http://www78.zippyshare.com/d/hBU7JYZp/2248094/OReilly.Introduction.to.Machine.Learning.with.Python.A.Guide.for.Data.Scientists.1449369413.rar
content: 
book link: http://www65.zippyshare.com/d/oFSWQWDk/1124867/OReilly.Introduction.to.Machine.Learning.with.Python.1449369413_Early.Release.rar

Process finished with exit code 0
</code></pre><p>8、接下来的一个问题，怎么让程序自动下载这2个链接？群里有人推荐了一些别的软件，但是我想来想去因为以后总要面对下载速度的问题，还是选定了迅雷破解版吧，除非将来有其他更好的方案，好在有人共享了一个方案，还特别简单，不过据说只能支持http格式，BT格式的以后再想办法。</p>
<p>9：补充说明，在正文代码的第2个下载地址，是有问题的，差别在于地址点击后，前者可在浏览器或者迅雷直接下载，而后者浏览器没反映，迅雷里下载的是一个html。尽管2个链接的提取方法完全一样，但一个好使，一个异常，由于是同一本书的前后2个小版本，我也不管他了，但为了验证迅雷是否能同时下载5个（代码里设定同时下载的最大值，也是一般默认值） 我用额外的测试脚本加载了一个新的链接，是证明可同时下载的，如图：</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-12/203618609.png" alt=""> </p>
<p>9、参考：</p>
<p><a href="http://neue.v2ex.com/t/275703" target="_blank" rel="external">http://neue.v2ex.com/t/275703</a></p>
<p>10、github对应仓库：</p>
<p><a href="https://github.com/vansnowpea/download-pdf-with-Xunlei" target="_blank" rel="external">https://github.com/vansnowpea/download-pdf-with-Xunlei</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/10/用户细分精准营销--聚类/" itemprop="url">
                  用户细分精准营销--聚类　以及　机器学习典型应用【Python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-10T13:59:28+08:00" content="2016-10-10">
              2016-10-10
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="用户细分精准营销–聚类"><a href="#用户细分精准营销–聚类" class="headerlink" title="用户细分精准营销–聚类"></a>用户细分精准营销–聚类</h1><p>1、中国移动的各个手机套餐之间的分类为例：</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-10/132655994.png" alt=""></p>
<ul>
<li>动感地带： 目标群：在校学生，短信需求旺盛，短信费用低。</li>
</ul>
<ul>
<li>神州大众卡：目标群：更多客户，四川移动推出：最让消费者动心的是没有月租费的日子里接听网内来电20元包完。</li>
</ul>
<ul>
<li>全球通： 目标群：全球飞的高端上午人群，不是很在乎话费，却关心品牌的增值服务，如vip候机厅等。</li>
</ul>
<ul>
<li>神州行： 目标群：普通务工人员，电话需求较多，通话费用低。</li>
</ul>
<p>那么在那个还没有智能机的年代，他们是怎么想到这些分类方法或者区分客户群的呢？回头想来客户群的区分有相当比例是由客户自己定义使用哪个套餐的。当然，以现在的技术用计算机AI可以相对容易的来进行聚类区分了。</p>
<hr>
<p>反垃圾邮件：　    朴素贝叶斯 </p>
<p>信贷风险控制：　  决策树</p>
<p>互联网广告：　    ctr预估-线性逻辑回归 </p>
<p>推荐系统：　     协同过滤 </p>
<p>自然语言处理：　  情感分析，实体识别 </p>
<p>图像识别：　     深度学习 </p>
<p>其他 </p>
<hr>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-10/135019916.png" alt=""></p>
<h1 id="一些常用的算法分类表："><a href="#一些常用的算法分类表：" class="headerlink" title="一些常用的算法分类表："></a>一些常用的算法分类表：</h1><p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-10/143149096.png" alt=""></p>
<ul>
<li>C4.5 是决策树算法，可以解决分类和回归问题，又属于有监督算法</li>
</ul>
<ul>
<li>K-Means 是聚类算法，无监督。</li>
<li>SVM： 基于统计学，有完整理论。</li>
<li>PageRank：谷歌的算法 </li>
</ul>
<h1 id="机器学习的框架"><a href="#机器学习的框架" class="headerlink" title="机器学习的框架"></a>机器学习的框架</h1><h2 id="训练模型："><a href="#训练模型：" class="headerlink" title="训练模型："></a>训练模型：</h2><p>1、定义模型</p>
<p>2、定义损失函数</p>
<p>3、优化算法</p>
<h2 id="模型评估："><a href="#模型评估：" class="headerlink" title="模型评估："></a>模型评估：</h2><p>1、交易验证</p>
<p>2、效果评估</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/08/数据分析的参考书集锦/" itemprop="url">
                  数据分析的参考书集锦【Python】+【R】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-08T20:59:28+08:00" content="2016-10-08">
              2016-10-08
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="数据分析的参考书集锦，先保存过来再说。"><a href="#数据分析的参考书集锦，先保存过来再说。" class="headerlink" title="数据分析的参考书集锦，先保存过来再说。"></a>数据分析的参考书集锦，先保存过来再说。</h1><p>原文： <a href="http://bbs.pinggu.org/thread-3116701-1-1.html" target="_blank" rel="external">http://bbs.pinggu.org/thread-3116701-1-1.html</a></p>
<h1 id="入门读物："><a href="#入门读物：" class="headerlink" title="入门读物："></a>入门读物：</h1><p>深入浅出数据分析 这书挺简单的，基本的内容都涉及了，说得也比较清楚，最后谈到了 R 是大加分。难易程度：非常易。<br>啤酒与尿布 通过案例来说事情，而且是最经典的例子。难易程度：非常易。<br>数据之美 一本介绍性的书籍，每章都解决一个具体的问题，甚至还有代码，对理解数据分析的应用领域和做法非常有帮助。难易程度：易。<br>数学之美 这本书非常棒啦，入门读起来很不错！<br>      下载地址：深入浅出数据分析、啤酒与尿布、数据之美、数学之美。</p>
<p>数据分析：</p>
<p>SciPy and NumPy 这本书可以归类为数据分析书吧，因为 numpy 和 scipy 真的是非常强大啊。<br>Python for Data Analysis 作者是 Pandas 包的作者，看过他在 Scipy 会议上的演讲，实例非常强！<br>Bad Data Handbook 很好玩的书，作者的角度很不同。<br>       下载地址：SciPy and NumPy、Python for Data Analysis、Bad Data Handbook</p>
<h1 id="适合入门的教程："><a href="#适合入门的教程：" class="headerlink" title="适合入门的教程："></a>适合入门的教程：</h1><p>集体智慧编程 学习数据分析、数据挖掘、机器学习人员应该仔细阅读的第一本书。作者通过实际例子介绍了机器学习和数据挖掘中的算法，浅显易懂，还有可执行的 Python 代码。难易程度：中。<br>Machine Learning in Action 用人话把复杂难懂的机器学习算法解释清楚了，其中有零星的数学公式，但是是以解释清楚为目的的。而且有 Python 代码，大赞！目前中科院的王斌老师（微博： 王斌_ICTIR）已经翻译这本书了 机器学习实战 。这本书本身质量就很高，王老师的翻译质量也很高。难易程度：中。我带的研究生入门必看数目之一！<br>Building Machine Learning Systems with Python 虽然是英文的，但是由于写得很简单，比较理解，又有 Python 代码跟着，辅助理解。<br>数据挖掘导论 最近几年数据挖掘教材中比较好的一本书，被美国诸多大学的数据挖掘课作为教材，没有推荐 Jiawei Han 老师的那本书，因为个人觉得那本书对于初学者来说不太容易读懂。难易程度：中上。<br>Machine Learning for Hackers 也是通过实例讲解机器学习算法，用 R 实现的，可以一边学习机器学习一边学习 R。<br>       下载地址：集体智慧编程+源代码、Machine Learning in Action、Building Machine Learning Systems with Python、                            数据挖掘导论、Machine Learning for Hackers</p>
<h1 id="稍微专业些的："><a href="#稍微专业些的：" class="headerlink" title="稍微专业些的："></a>稍微专业些的：</h1><p>Introduction to Semi-Supervised Learning 半监督学习必读必看的书。<br>Learning to Rank for Information Retrieval 微软亚院刘铁岩老师关于 LTR 的著作，啥都不说了，推荐！<br>Learning to Rank for Information Retrieval and Natural Language Processing 李航老师关于 LTR 的书，也是当时他在微软亚院时候的书，可见微软亚院对 LTR 的研究之深，贡献之大。<br>推荐系统实践 这本书不用说了，研究推荐系统必须要读的书，而且是第一本要读的书。<br>Graphical Models, Exponential Families, and Variational Inference 这个是 Jordan 老爷子和他的得意门徒 Martin J Wainwright 在 Foundation of Machine Learning Research 上的创刊号，可以免费下载，比较难懂，但是一旦读通了，graphical model 的相关内容就可以踏平了。<br>Natural Language Processing with Python NLP 经典，其实主要是讲 NLTK 这个包，但是啊，NLTK 这个包几乎涵盖了 NLP 的很多内容了啊！<br>   下载地址：Introduction to Semi-Supervised Learning、Learning to Rank for Information Retrieval、                           Learning to Rank for Information Retrieval and Natural Language Proces、推荐系统实践</p>
<p>机器学习教材：<br>The Elements of Statistical Learning 这本书有对应的中文版：统计学习基础 。书中配有 R 包，非常赞！可以参照着代码学习算法。<br>统计学习方法 李航老师的扛鼎之作，强烈推荐。难易程度：难。<br>Machine Learning 去年出版的新书，作者 Kevin Murrphy 教授是机器学习领域中年少有为的代表。这书是他的集大成之作，写完之后，就去 Google 了，产学研结合，没有比这个更好的了。<br>Machine Learning 这书和上面的书不是一本！这书叫：Machine Learning: An Algorithmic Perspective 之前做过我带的研究生教材，由于配有代码，所以理解起来比较容易。<br>Pattern Recognition And Machine Learning 经典中的经典。<br>Bayesian Reasoning and Machine Learning 看名字就知道了，彻彻底底的 Bayesian 学派的书，里面的内容非常多，有一张图将机器学习中设计算法的关系总结了一下，很棒。<br>Probabilistic Graphical Models 鸿篇巨制，这书谁要是读完了告诉我一声。<br>Convex Optimization 凸优化中最好的教材，没有之一了。课程也非常棒，Stephen 老师拿着纸一步一步推到，图一点一点画，太棒了。<br>下载地址：The Elements of Statistical Learning、统计学习方法、Machine Learning: An Algorithmic Perspective、<br>                            Pattern Recognition and Machine Learning+答案、Bayesian Reasoning and Machine Learning、                                                   Probabilistic Graphical Models、Convexity and Optimization</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/07/下载最新电影的爬虫/" itemprop="url">
                  下载最新电影的爬虫---Xpath读取文本，链接，标题等的操作【Python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-07T23:59:28+08:00" content="2016-10-07">
              2016-10-07
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="下载最新电影的爬虫"><a href="#下载最新电影的爬虫" class="headerlink" title="下载最新电影的爬虫"></a>下载最新电影的爬虫</h1><p>1、使用：</p>
<ul>
<li>lxml.etree</li>
<li>requests</li>
</ul>
<p>2、代码：</p>
<pre><code># -*- coding:utf-8 -*-
import requests
from lxml import etree


url = &apos;http://www.ygdy8.net/html/gndy/dyzz/index.html&apos;  #这是电影最新电影的网站
# r = requests.get(url).content
# print(r.encoding）
# &gt;&gt;&gt; ISO-8859-1
html = requests.get(url).content
# html = requests.get(url).content.decode(&apos;ISO-8859-1&apos;).encode(&apos;utf-8&apos;)

selector = etree.HTML(html)

# //*[@id=&quot;content&quot;]/div/div[1]/ol/li[1]/div/div[2]/div[2]/p[1]
# get rid of the : /tbody
biaoti = selector.xpath(&apos;//*[@id=&quot;header&quot;]/div/div[3]/div[3]/div[2]/div[2]/div[2]/ul//tr[2]/td[2]/b/a/text()&apos;)


# get rid of the : /tbody
jianjie = selector.xpath(&apos;/html/body/div/div/div[3]/div[3]/div[2]/div[2]/div[2]/ul//tr[4]/td/text()&apos;)
wangzhi = selector.xpath(&apos;//*[@id=&quot;header&quot;]/div/div[3]/div[3]/div[2]/div[2]/div[2]/ul//tr[2]/td[2]/b/a/@href&apos;)

for b,j,k in zip(biaoti,jianjie,wangzhi):
    print(b+&apos;\n&apos;+j+&apos;\n&apos;+&apos;www.ygdy8.net&apos;+k+&apos;\n&apos;)
</code></pre><p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-08/015240484.png" alt="">    </p>
<p>3、分析：主要和上一篇的接近，但是这一篇还有读取网址等操作，注意格式上和读取内容text有差别的。<br>总结如下：</p>
<pre><code>获取到标签后我们可以获取标签中的属性值
tree.xpath(&quot;//div[@class=&apos;sec_blk mrg_b_30&apos;]/ul/li[1]/a/text()&quot;)     #获取a的文本，li标号是从1开始，而不是从0开始
tree.xpath(&quot;//div[@class=&apos;sec_blk mrg_b_30&apos;]/ul/li[1]/a/@href&quot;)   #获取a的链接地址

当然还有其他类似的xpath例子：
&quot;//input[@id=&apos;city&apos;]/@value&quot;
&quot;//div[@class=&apos;venueDetal&apos;]/p/img[@class=&apos;img&apos;]/@src&quot;
&quot;//div[@class=&apos;detail_info_title&apos;]//a[@class=&apos;hotel_star&apos;]/@title&quot;
</code></pre><p>4、参考： <a href="http://blog.chinaunix.net/uid-13869856-id-5747494.html" target="_blank" rel="external">python+lxml xpath获取数据 </a></p>
<p>5、可补充点： 自动提取直接下载链接，看是否能导入到迅雷等工具。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/07/东方财富网cpi数据的抓取/" itemprop="url">
                  东方财富网cpi数据的抓取【Python】
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-07T22:59:28+08:00" content="2016-10-07">
              2016-10-07
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="东方财富网cpi数据的抓取"><a href="#东方财富网cpi数据的抓取" class="headerlink" title="东方财富网cpi数据的抓取"></a>东方财富网cpi数据的抓取</h1><p>1、使用：</p>
<ul>
<li>lxml.etree</li>
<li>requests</li>
</ul>
<p>2、代码：</p>
<pre><code>from lxml import etree
import requests

url = &apos;http://data.eastmoney.com/cjsj/cpi.html&apos;
content = requests.get(url).content

html = etree.HTML(content)
content1 = html.xpath(&apos;//*[@id=&quot;tb&quot;]/tr[3]/td[2]/text()&apos;)

print(content1[0].strip().replace(&apos;\n\r&apos;, &apos;&apos;))

# for txt in html.iterfind(&apos;.//*[@id=&quot;tb&quot;]/tr[3]/td&apos;):
#     print(txt.text)
</code></pre><p>3、分析：requests+lxml来分析和提取数据比较简单，可以尽可能的规避使用RE的复杂性以及可能产生的编码问题。要注意的是提取文本内容的时候要在xpath地址后面加上/text()<br>不过这个案例中，需要把xpath的/tbody去掉，这是因为有的浏览器加上去的，否则不能识别需要的文字部分。<br>另外，默认的结果因为有很多的空格和\n\r，所以需要做数据清洗，就本例，加一句content1[0].strip().replace(‘\n\r’, ‘’)即可。</p>
<p>4、没有执行的代码，表示读取2016年08月份 “全国”，“城市”，“农村”各自的cpi数据。<br>要注意的是：这属于ElementPath，一共4个种类，分别如下：</p>
<ul>
<li></li>
</ul>
<ol>
<li>iterfind()</li>
<li>findall()</li>
<li>find()</li>
<li>findtext()</li>
</ol>
<p>千万注意的是：ElementPath不能直接使用绝对路径，需要在前面加一个.符号。暂时感觉这个使用的不太多。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/05/tensorflow 初步学习/" itemprop="url">
                  begin to learn TensorFlow
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-05T16:20:28+08:00" content="2016-10-05">
              2016-10-05
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-05/163346079.png" alt=""></p>
<h1 id="Introduction-begin-to-learn-Machine-Learning-and-find-Google’s-open-source-technology-TensorFlow"><a href="#Introduction-begin-to-learn-Machine-Learning-and-find-Google’s-open-source-technology-TensorFlow" class="headerlink" title="Introduction: begin to learn Machine Learning, and find Google’s open source technology: TensorFlow."></a>Introduction: begin to learn Machine Learning, and find Google’s open source technology: TensorFlow.</h1><p>1、It seems TF only support Linux by official , but I try to install also on Win 10, so try :： <a href="http://wiki.jikexueyuan.com/project/tensorflow-zh/" target="_blank" rel="external">http://wiki.jikexueyuan.com/project/tensorflow-zh/</a>：<br>though some guy reported successed on win, but I failed as can not download the big file no matter with USA IP, anyway , I record the method.</p>
<pre><code>捣鼓好了windows docker安装，参考了楼上的许多信息。
1. 安装docker
2. 点开Docker Quickstart Terminal， 打开成功后：
    docker is configured to use the default machine with IP 192.168.99.100
3. 安装tensorflow： docker run -d -p 8888:8888 -v /notebook:/notebook xblaster/tensorflow-jupyter
4. 运行tensorflow-jupyter: docker run xblaster/tensorflow-jupyter
     会提示running at: http://0.0.0.0:8888，不知道为什么会是这个IP地址，用浏览器打开不了。然后替换成docker打开时的IP，http://192.168.99.100:8888就可以打开了。
5. 运行example code，mnist参考资料：1, tensorflow官方文档；2，http://blog.csdn.net/yhl_leo/article/details/50614444 及其mnist的github：https://github.com/yhlleo/mnist，github中有input_data.py这个很重要的文件。
</code></pre><p>2、 I run it on Ubuntu and test an easy exmaple which is :</p>
<pre><code>y =0.1*x +0.3
</code></pre><p>and after 200 times of calculating , get result :</p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-05/235616627.png" alt=""> </p>
<p>from the result : after 40 times calculating , the result closes to 0.1*x + 0.3 already , no matter how AlphaGo is so strong.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/02/numpy和pandas的初步学习/" itemprop="url">
                  numpy和pandas的初步学习以及6本数据分析必读书和2份英文教程
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-10-02T14:20:28+08:00" content="2016-10-02">
              2016-10-02
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-10-02/235644734.png" alt=""></p>
<h1 id="简介：-今天把cmder的配色研究下，找了个nice的shell版，赞一个，另外，英文是绕不过去的，最后总会发现想要的资料只有英文的。-：）"><a href="#简介：-今天把cmder的配色研究下，找了个nice的shell版，赞一个，另外，英文是绕不过去的，最后总会发现想要的资料只有英文的。-：）" class="headerlink" title="简介： 今天把cmder的配色研究下，找了个nice的shell版，赞一个，另外，英文是绕不过去的，最后总会发现想要的资料只有英文的。 ：）"></a>简介： 今天把cmder的配色研究下，找了个nice的shell版，赞一个，另外，英文是绕不过去的，最后总会发现想要的资料只有英文的。 ：）</h1><p>1、这几天抽空看了下《利用python进行数据分析》的几个章节，其中pandas部分看了2遍，熟悉了一些命令和用法，</p>
<p>2、国外一个朋友的对某个问题的建议是使用JS， 首先我是按照这个网页的心得：不过我找了一本JS的入门书，发现内容不是兴趣所在，所以暂时先记录之。</p>
<p><a href="http://kb.cnblogs.com/page/191787/" target="_blank" rel="external">http://kb.cnblogs.com/page/191787/</a></p>
<p>3、另搜资料的时候，找了一个国外的网址，介绍了数据分析几本不错的书，<br><a href="https://www.analyticsvidhya.com/blog/2014/06/books-data-scientists-or-aspiring-ones/" target="_blank" rel="external"><br>Must have books for data scientists (or aspiring ones)</a></p>
<p>4、在上述链接中，是6本书的英文介绍，貌似R的数量更多，并且有一本是R的，但有第三方给出了Python代码，（注意有的文字因粘贴丢失了超链接）：</p>
<pre><code>1. R Cookbook by Paul Teetor

This is simply the best book to start your journey with R. It contains tons of examples and practical advice on a wide range of topics like file input / output, data manipulations, merging and sorting to building a regression model. For a starter in R, this book becomes your best pal during the initial testing time.

While the book is aimed towards starters, it still remains a prominent feature of the library of any data scientist.



2. Machine Learning for Hackers by Drew Conway &amp; John Myles White

I think this book actually has a wrong title. I dropped purchasing it twice before giving it a shot (which happened only because of a recommendation from a close friend). This book is meant for data scientists and not hackers. I don’t know why the title says so. A very practical manual for learning machine learning, it comes with good visuals and you can get a copy of codes in Python (original book is based on R).



3. R graphics cookbook by Winston Chang

You can’t be a good data scientist unless you master the graphics in R! There is no better way for visualization, but to learn ggplot2. Sadly, learning ggplot2 might seem like learning a completely new language in itself. This is where this “cookbook” comes to rescue. The recipes from Winston are short, sweet and to the point. Buy this and it is bound to end up as one of the most referred book in your library.



4. Programming Collective Intelligence by Toby Segaran (popularly referred as PCI)

If there is one book you want to choose, out of this selection (for learning machine learning) – it is this one. I haven’t met a data scientist yet who has read this book and does not recommend to keep it on your bookshelf. A lot of them have re-read this book multiple times. The book was written long before data science and machine learning acquired the cult status they have today – but the topics and chapters are entirely relevant even today! Some of the topics covered in the book are collaborative filtering techniques, search engine features, Bayesian filtering and Support vector machines. If you don’t have a copy of this book – order it as soon as you finish reading this article! The book uses Python to deliver machine learning in a fascinating manner.



5. Python for Data Analysis by Wes McKinney

Written by Wes McKinney, this book teaches you everything you need about Pandas. For the starters (not sure why you are still reading this article), pandas are Python’s way to handle data structures. Except for the title of the book (which I find misleading), I like everything else about this book. It contains ample codes and examples to leave you capable of performing any operation / transformation on a dataframe in Python (using pandas).

For the advanced users, if you already know pandas, you should look at this presentation from Wes on what are the shortcomings of pandas.



6. Agile data science by Russell Jurney

A recent addition by O’Reilly, this book looks like a must read for data scientists. The focus is on using “light” tools, which are easy to use and still get the work done. This is currently on my reading list and I’ll update more details once I have read it.



These are the 6 must have books, if you are serious about being a data scientist. There are a couple of additional Python books, which you can consider – Natural Language processing with Python by Steven Bird et al and Mining the social web by Matthew A. Russell. The reason I have not kept them in the list is because you can find a lot of the information in these books easily on the web.
</code></pre><p>5、另外，还有2篇不错的英文的基于python-pandas的数据分析教程：</p>
<p><a href="https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/" target="_blank" rel="external">A Complete Tutorial to Learn Data Science with Python from Scratch</a></p>
<p>以及这个：</p>
<p><a href="https://www.analyticsvidhya.com/blog/2014/09/data-munging-python-using-pandas-baby-steps-python/" target="_blank" rel="external">Data Munging in Python (using Pandas) – Baby steps in Python</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/27/收到《Python for data analysis》作者的邮件回复/" itemprop="url">
                  收到《Python for data analysis》作者的邮件回复
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-09-27T14:20:28+08:00" content="2016-09-27">
              2016-09-27
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-27/150628293.jpg" alt=""></p>
<h1 id="简介：-收到《Python-for-data-analysis》作者的邮件回复-：）"><a href="#简介：-收到《Python-for-data-analysis》作者的邮件回复-：）" class="headerlink" title="简介： 收到《Python for data analysis》作者的邮件回复 ：）"></a>简介： 收到《Python for data analysis》作者的邮件回复 ：）</h1><p>1、上次给他写了一个邮件，建议用Anaconda来写下一版本，虽然过了几天还是收到了回复，看样子他也意识到Anaconda更好点，也表示第二版会采用：</p>
<pre><code>try

from matplotlib.pyplot import *

and running

%matplotlib

I am creating a 2nd edition of the book, and it will use Anaconda
instead of Canopy in the instructions.

Thanks!
</code></pre><p>2、然后我去Python中文社区问了几个人，表示有兴趣翻译，由于第一版是机械工业出版社搞的中译版，发了一个email咨询是否将来打算出第二版的中译，但是还没得到回复，想了下，如果他们不翻译，就召集社区的小伙伴们来翻译吧。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/27/matplotlib中文显示乱码的解决办法/" itemprop="url">
                  matplotlib中文显示乱码的解决办法
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-09-27T13:20:28+08:00" content="2016-09-27">
              2016-09-27
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介：-matplotlib中文显示乱码的解决办法-：）"><a href="#简介：-matplotlib中文显示乱码的解决办法-：）" class="headerlink" title="简介： matplotlib中文显示乱码的解决办法 ：）"></a>简介： matplotlib中文显示乱码的解决办法 ：）</h1><p>1、在源代码开头加入以下几行：</p>
<pre><code>from pylab import *
mpl.rcParams[&apos;font.sans-serif&apos;] = [&apos;SimHei&apos;] #指定默认字体

mpl.rcParams[&apos;axes.unicode_minus&apos;] = False #解决保存图像是负号&apos;-&apos;显示为方块的问题
</code></pre><p>2、上述就针对单个py文件，如果想全部的，可以这么操作：</p>
<ul>
<li>\Lib\site-packages\matplotlib\mpl-data\matplotlibrc    用任意文本编辑器打开。（最好先备份一下）<br>找到第129行：#font.family， 将其注释去掉，冒号后面的值改为Microsoft YaHei</li>
<li>找到第141行：#font.sans-serif， 将其注释去掉，并将Microsoft YaHei添加到冒号后面的最前面，注意还要再加一个英文逗号（,）</li>
<li>并设置axes.unicode_minus = False #解决保存图像是负号’-‘显示为方块的问题</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/25/《利用Python进行数据分析》如何把kindle的电子书转成pdf的教程/" itemprop="url">
                  如何把kindle的电子书转成word等格式的教程
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Veröffentlicht am</span>
            <time itemprop="dateCreated" datetime="2016-09-25T23:20:28+08:00" content="2016-09-25">
              2016-09-25
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介：-如何把kindle的电子书转成word等格式的教程-：）"><a href="#简介：-如何把kindle的电子书转成word等格式的教程-：）" class="headerlink" title="简介： 如何把kindle的电子书转成word等格式的教程 ：）"></a>简介： 如何把kindle的电子书转成word等格式的教程 ：）</h1><p>1、参考知乎的步骤， <a href="http://www.zhihu.com/question/38451995" target="_blank" rel="external">http://www.zhihu.com/question/38451995</a></p>
<p>2、下载去除DRM的破解版本，不然只能破解3本书，参考此网址： <a href="http://www.d9soft.com/soft/102882.htm" target="_blank" rel="external">http://www.d9soft.com/soft/102882.htm</a></p>
<p>3、使用该网站，进行pdf转换： <a href="http://www.epubconverter.com/azw-to-pdf-converter/" target="_blank" rel="external">http://www.epubconverter.com/azw-to-pdf-converter/</a></p>
<p>4、成功把《利用Python进行数据分析》转成了pdf，当然我事先花销了巨额的0.1元注册了一个Kindle Unlimited  帐号</p>
<p>5、为了方便复制书中的代码实例，继续用calibre 软件进行转换成docx格式，不用对着那些网上的扫描版，或者纸质书，坑爹的挨个自己输入命令了有木有， </p>
<p>6、示范图： </p>
<p><img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-26/001138836.png" alt=""></p>
<p>7、我已经为偷懒的你，上传了本书，可以直接下载word版本啦。请点击<a href="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-26/001313882.docx" target="_blank" rel="external">【下载点我】</a></p>
<p>8、记得重命名，方便以后查找。</p>
<p>9、第八章spx指数的举例，代码我修正到pycharm里：</p>
<pre><code>import matplotlib.pyplot as plt
from datetime import datetime
import pandas as pd
fig = plt.figure()
ax = fig.add_subplot(1, 1, 1)
data = pd.read_csv(&apos;D:\mine\pydata-book-master\ch08/spx.csv&apos;, index_col=0, parse_dates=True)
spx = data[&apos;SPX&apos;]
spx.plot(ax=ax, style=&apos;k-&apos;)
crisis_data = [      (datetime(2007, 10, 11), &apos;Peak of bull market&apos;),      (datetime(2008, 3, 12), &apos;Bear Stearns Fails&apos;),      (datetime(2008, 9, 15), &apos;Lehman Bankruptcy&apos;) ]
for date, label in crisis_data:
    ax.annotate(label, xy=(date, spx.asof(date) + 50),                 xytext=(date, spx.asof(date) + 200),                 arrowprops=dict(facecolor=&apos;black&apos;),                 horizontalalignment=&apos;left&apos;, verticalalignment=&apos;top&apos;)
# 放大到2007-2010
    ax.set_xlim([&apos;1/1/2007&apos;, &apos;1/1/2011&apos;])
    ax.set_ylim([600, 1800])
    ax.set_title(&apos;Important dates in 2008-2009 financial crisis&apos;)

plt.show()
</code></pre><p>结果图，有木有一点专业的味道？<br> <img src="http://ocg7i7pt6.bkt.clouddn.com/blog/2016-09-26/105503895.png" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Van" />
          <p class="site-author-name" itemprop="name">Van</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">56</span>
              <span class="site-state-item-name">Artikel</span>
            </a>
          </div>

          

          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Van</span>
</div>

<div class="powered-by">
  Erstellt mit  <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  




  
  

  

  

  

</body>
</html>
